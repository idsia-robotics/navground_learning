Search.setIndex({"alltitles": {"A single group": [[24, "A-single-group"]], "Acknowledgement and disclaimer": [[4, "acknowledgement-and-disclaimer"]], "Actions": [[5, "actions"]], "Alternate Action and Communication training": [[43, "Alternate-Action-and-Communication-training"], [48, "Alternate-Action-and-Communication-training"]], "Base class": [[5, "base-class"], [5, "id3"], [5, "id4"], [9, "base-class"]], "Basics": [[26, null]], "Behavior Cloning": [[9, "behavior-cloning"], [32, "Behavior-Cloning"], [33, "Behavior-Cloning"]], "Behavior Modulation": [[5, "behavior-modulation"]], "Behaviors": [[13, "behaviors"]], "BenchMARL": [[20, "benchmarl"], [49, null], [52, null]], "Binary message, with reward sharing": [[46, "Binary-message,-with-reward-sharing"]], "Centralized policy trained with SAC": [[40, null]], "Centralized training": [[50, "centralized-training"]], "Centralized training with communication (SAC)": [[16, "centralized-training-with-communication-sac"]], "Communication": [[5, "communication"]], "Comparision with HL": [[27, "Comparision-with-HL"]], "Configuration": [[5, null]], "Configurations": [[0, "configurations"]], "Contents:": [[1, null], [2, null]], "Continous actions": [[61, null]], "Continuos actions with MASAC": [[52, "Continuos-actions-with-MASAC"]], "Continuous": [[5, "continuous"], [5, "id1"]], "Continuous actions using split MLP": [[43, null]], "Continuous actions with MLP": [[41, null]], "Convert from a Gymnasium Env": [[24, "Convert-from-a-Gymnasium-Env"]], "Converto to a Gymansium environement": [[24, "Converto-to-a-Gymansium-environement"]], "Corridor": [[8, "corridor"]], "Corridor with obstacle": [[29, null]], "CorridorWithObstacle": [[13, "corridorwithobstacle"]], "Creating an enviroment": [[35, "Creating-an-enviroment"]], "Crossing": [[8, "crossing"], [34, null]], "DAgger": [[9, "dagger"], [32, "DAgger"], [33, "DAgger"]], "Default": [[5, "default"], [5, "id5"]], "Defining a scenario": [[35, "Defining-a-scenario"]], "Different speeds": [[65, null]], "Discrete": [[5, "discrete"], [5, "id2"]], "Discrete action space": [[62, "Discrete-action-space"]], "Discrete actions": [[42, null], [62, null]], "Displaying the policies": [[35, "Displaying-the-policies"]], "Distributed policy": [[58, null]], "Distributed policy with comm trained using parallel SAC: split model": [[48, null]], "Distributed policy with comm, trained centrally": [[47, null]], "Distributed policy with communication": [[50, null]], "Efficacy": [[18, "efficacy"]], "Empty environment": [[37, null]], "End-to-end": [[5, "end-to-end"]], "Environment": [[32, "Environment"], [33, "Environment"], [65, "Environment"], [66, "Environment"]], "Environments": [[8, "environments"]], "Evaluating the policies": [[35, "Evaluating-the-policies"]], "Evaluation": [[4, "evaluation"], [7, null], [36, "Evaluation"], [53, "Evaluation"], [54, "Evaluation"], [55, "Evaluation"], [56, "Evaluation"], [57, "Evaluation"]], "Examples": [[8, null]], "Exclusive crossing on a pad": [[64, null]], "Experiments": [[7, "experiments"]], "Exporting": [[14, "exporting"]], "Exporting the policies": [[35, "Exporting-the-policies"]], "Final video": [[30, "Final-video"]], "Fixed": [[18, "fixed"]], "Floating-point message, with reward sharing": [[46, "Floating-point-message,-with-reward-sharing"]], "Floating-point message, without reward sharing": [[46, "Floating-point-message,-without-reward-sharing"]], "Forward": [[13, "forward"]], "Group": [[5, "group"]], "GroupedPolicyBehavior": [[13, "groupedpolicybehavior"]], "Guides": [[1, null]], "Gymnasium": [[4, "gymnasium"], [23, null]], "How to extend": [[0, null]], "Human-like behavior": [[33, "Human-like-behavior"]], "Imitation Learning": [[4, "imitation-learning"], [9, null], [35, "Imitation-Learning"]], "Imitation Learning with Behavior Cloning": [[27, "Imitation-Learning-with-Behavior-Cloning"]], "Imitation learning with DAgger": [[27, "Imitation-learning-with-DAgger"]], "Indices": [[11, null]], "Indices and tables": [[2, "indices-and-tables"]], "Inference": [[14, "inference"]], "Info": [[16, "info"]], "Instability": [[50, "instability"]], "Installation": [[3, null]], "Introduction": [[4, null]], "Joint Environement": [[24, "Joint-Environement"]], "Learn to follow a direction.": [[35, null]], "Learn to reach a pose": [[36, null]], "Learning": [[27, null]], "Logging": [[7, "logging"]], "MAPPO": [[41, "MAPPO"], [42, "MAPPO"], [52, "MAPPO"]], "MAPPO starting from opposite sides": [[52, "MAPPO-starting-from-opposite-sides"]], "MASAC": [[41, "MASAC"], [42, "MASAC"], [43, "MASAC"]], "MASAC with discrete actions": [[52, "MASAC-with-discrete-actions"]], "MASAC with global state critic": [[52, "MASAC-with-global-state-critic"]], "Model-based behaviors": [[39, null]], "More agents following the policy": [[31, "More-agents-following-the-policy"]], "Multi-agent Pettingzoo Environment": [[15, null]], "Multi-agent Reinforcement Learning with BenchMARL": [[4, "multi-agent-reinforcement-learning-with-benchmarl"]], "Multi-binary action space": [[62, "Multi-binary-action-space"]], "Navground": [[4, "navground"]], "Navground Components": [[0, "navground-components"], [13, null]], "Navground Gymnasium Environment": [[4, "navground-gymnasium-environment"]], "Navground policy": [[7, "navground-policy"], [23, "Navground-policy"]], "Navground-Gymnasium integration": [[4, "navground-gymnasium-integration"]], "Null": [[16, "null"], [18, "null"]], "Observations": [[5, "observations"]], "One agent following the policy": [[31, "One-agent-following-the-policy"]], "Onnx": [[14, null]], "Ordering-invariant extractor": [[16, "ordering-invariant-extractor"]], "PPO": [[61, "PPO"]], "PPO trained on starting from opposing sides": [[61, "PPO-trained-on-starting-from-opposing-sides"]], "Pad": [[8, "module-navground.learning.examples.pad"], [13, "pad"], [13, "id1"]], "Parallel Multi-agent Learning": [[4, "parallel-multi-agent-learning"]], "Parallel PPO with discrete actions": [[54, null]], "Parallel PPO with discrete actions and MLP": [[45, null]], "Parallel SAC": [[51, null], [59, null]], "Parallel SAC with MLP": [[46, null]], "Perceiving neighbor position and speed": [[56, null]], "Perceiving only neighbor position": [[55, null]], "Perceiving only neighbor speed": [[57, null]], "Performance of policies trained in multi-agent environment": [[30, null]], "Performance of policies trained in single-agent environment": [[31, null]], "Periodic Crossing": [[67, null]], "PettingZoo": [[4, "pettingzoo"], [24, null]], "PettingZoo Navground Environment": [[4, "pettingzoo-navground-environment"]], "Plotting": [[20, "plotting"]], "Policies": [[7, "policies"], [16, null], [64, "policies"]], "Policy": [[7, "policy"], [40, "Policy"]], "PolicyBehavior": [[13, "policybehavior"]], "Pre-trained SA policies": [[32, "Pre-trained-SA-policies"]], "Probes": [[13, "probes"]], "Random": [[16, "random"]], "Reference": [[10, null]], "Register": [[17, null]], "Reinforcement Learning": [[4, "reinforcement-learning"], [35, "Reinforcement-Learning"]], "Reinforcement learning with SAC": [[27, "Reinforcement-learning-with-SAC"]], "Rendering": [[23, "Rendering"]], "Reward": [[8, "reward"], [30, "Reward"]], "Reward starting from opposing sides": [[39, "Reward-starting-from-opposing-sides"]], "Reward starting uniformly along the corridor": [[39, "Reward-starting-uniformly-along-the-corridor"]], "Rewards functions": [[18, null]], "SAC": [[32, "SAC"], [33, "SAC"], [61, "SAC"]], "Saving and Loading": [[12, null]], "Saving and loading": [[23, "Saving-and-loading"], [24, "Saving-and-loading"]], "Scenario": [[28, null], [33, "Scenario"], [60, null], [65, "Scenario"], [66, "Scenario"]], "Scenarios": [[7, "scenarios"], [13, "scenarios"]], "Sensor": [[28, "Sensor"]], "Sensors": [[8, "sensors"]], "Single ML agent meets Dummy agent": [[63, null]], "Single-agent Gymnasium Environment": [[6, null]], "Social": [[18, "social"]], "Split MLP Policy (SAC)": [[16, "split-mlp-policy-sac"]], "Split Models": [[50, "split-models"]], "StableBaseLine3": [[20, "stablebaseline3"]], "State": [[5, "state"], [24, "State"]], "State Estimations": [[13, "state-estimations"]], "Summary": [[32, "Summary"], [33, "Summary"], [46, "Summary"]], "The environment": [[36, "The-environment"]], "The scenario": [[36, "The-scenario"]], "Title": [[5, "id6"], [5, "id7"]], "TorchRL": [[4, "torchrl"], [25, null]], "TorchRL Navground Environment": [[4, "torchrl-navground-environment"]], "Train ML policies in navground": [[4, "train-ml-policies-in-navground"]], "Training": [[32, "Training"], [33, "Training"], [36, "Training"], [53, "Training"], [54, "Training"], [55, "Training"], [56, "Training"], [57, "Training"], [65, "Training"], [66, "Training"]], "Training agents among peers": [[32, null]], "Training one agent among many agents": [[33, null]], "Training policies": [[35, "Training-policies"]], "Tutorials": [[38, null]], "Two groups": [[24, "Two-groups"]], "Types": [[19, null]], "Unidirection communication": [[44, null]], "Uniform speeds": [[66, null]], "Use ML policies in navground": [[4, "use-ml-policies-in-navground"]], "Using a ML policy in Navground": [[22, null]], "Using the policies in navground": [[35, "Using-the-policies-in-navground"]], "Utilities": [[9, "utilities"]], "Utils": [[20, null]], "Varying target speed at runtime": [[65, "Varying-target-speed-at-runtime"]], "Vectorized Environement": [[24, "Vectorized-Environement"]], "Vectorized environments": [[23, "Vectorized-environments"]], "Video": [[7, "video"], [30, "Video"]], "Welcome to navground_learning\u2019s documentation!": [[2, null]], "Without perceiving neighbors": [[53, null]], "Wrappers": [[21, null], [23, "Wrappers"]], "[Multi-]Binary": [[5, "multi-binary"]]}, "docnames": ["guides/extend", "guides/index", "index", "installation", "introduction", "reference/config", "reference/env", "reference/evaluation", "reference/examples", "reference/il", "reference/index", "reference/indices", "reference/io", "reference/navground", "reference/onnx", "reference/parallel_env", "reference/policies", "reference/register", "reference/rewards", "reference/types", "reference/utils", "reference/wrappers", "tutorials/basics/Behavior", "tutorials/basics/Gymnasium", "tutorials/basics/PettingZoo", "tutorials/basics/TorchRL", "tutorials/basics/index", "tutorials/corridor_with_obstacle/Learning", "tutorials/corridor_with_obstacle/Scenario", "tutorials/corridor_with_obstacle/index", "tutorials/crossing/Analysis-MA", "tutorials/crossing/Analysis-SA", "tutorials/crossing/Training-MA", "tutorials/crossing/Training-SA", "tutorials/crossing/index", "tutorials/empty/Direction", "tutorials/empty/Pose", "tutorials/empty/index", "tutorials/index", "tutorials/pad/Behaviors", "tutorials/pad/Centralized/Centralized", "tutorials/pad/Communication/Comm-BenchMARL", "tutorials/pad/Communication/Comm-BenchMARL-Discrete", "tutorials/pad/Communication/Comm-BenchMARL-Split", "tutorials/pad/Communication/Comm-BenchMARL-Unidirectional", "tutorials/pad/Communication/Comm-PPO-Discrete", "tutorials/pad/Communication/Comm-SAC", "tutorials/pad/Communication/Comm-SAC-CentralizedTraining", "tutorials/pad/Communication/Comm-SAC-Split", "tutorials/pad/Communication/benchmarl", "tutorials/pad/Communication/index", "tutorials/pad/Communication/parallel_sac", "tutorials/pad/Distributed/Distributed-BenchMARL", "tutorials/pad/Distributed/Distributed-Blind-SAC", "tutorials/pad/Distributed/Distributed-Discrete-PPO", "tutorials/pad/Distributed/Distributed-Position-SAC", "tutorials/pad/Distributed/Distributed-SAC", "tutorials/pad/Distributed/Distributed-Speed-SAC", "tutorials/pad/Distributed/index", "tutorials/pad/Distributed/parallel_sac", "tutorials/pad/Scenario", "tutorials/pad/SingleAgent/Dummy-Continuos", "tutorials/pad/SingleAgent/Dummy-Discrete", "tutorials/pad/SingleAgent/index", "tutorials/pad/index", "tutorials/periodic_crossing/DifferentSpeed", "tutorials/periodic_crossing/SameSpeed", "tutorials/periodic_crossing/index"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["guides/extend.rst", "guides/index.rst", "index.rst", "installation.rst", "introduction.rst", "reference/config.rst", "reference/env.rst", "reference/evaluation.rst", "reference/examples.rst", "reference/il.rst", "reference/index.rst", "reference/indices.rst", "reference/io.rst", "reference/navground.rst", "reference/onnx.rst", "reference/parallel_env.rst", "reference/policies.rst", "reference/register.rst", "reference/rewards.rst", "reference/types.rst", "reference/utils.rst", "reference/wrappers.rst", "tutorials/basics/Behavior.ipynb", "tutorials/basics/Gymnasium.ipynb", "tutorials/basics/PettingZoo.ipynb", "tutorials/basics/TorchRL.ipynb", "tutorials/basics/index.rst", "tutorials/corridor_with_obstacle/Learning.ipynb", "tutorials/corridor_with_obstacle/Scenario.ipynb", "tutorials/corridor_with_obstacle/index.rst", "tutorials/crossing/Analysis-MA.ipynb", "tutorials/crossing/Analysis-SA.ipynb", "tutorials/crossing/Training-MA.ipynb", "tutorials/crossing/Training-SA.ipynb", "tutorials/crossing/index.rst", "tutorials/empty/Direction.ipynb", "tutorials/empty/Pose.ipynb", "tutorials/empty/index.rst", "tutorials/index.rst", "tutorials/pad/Behaviors.ipynb", "tutorials/pad/Centralized/Centralized.ipynb", "tutorials/pad/Communication/Comm-BenchMARL.ipynb", "tutorials/pad/Communication/Comm-BenchMARL-Discrete.ipynb", "tutorials/pad/Communication/Comm-BenchMARL-Split.ipynb", "tutorials/pad/Communication/Comm-BenchMARL-Unidirectional.ipynb", "tutorials/pad/Communication/Comm-PPO-Discrete.ipynb", "tutorials/pad/Communication/Comm-SAC.ipynb", "tutorials/pad/Communication/Comm-SAC-CentralizedTraining.ipynb", "tutorials/pad/Communication/Comm-SAC-Split.ipynb", "tutorials/pad/Communication/benchmarl.rst", "tutorials/pad/Communication/index.rst", "tutorials/pad/Communication/parallel_sac.rst", "tutorials/pad/Distributed/Distributed-BenchMARL.ipynb", "tutorials/pad/Distributed/Distributed-Blind-SAC.ipynb", "tutorials/pad/Distributed/Distributed-Discrete-PPO.ipynb", "tutorials/pad/Distributed/Distributed-Position-SAC.ipynb", "tutorials/pad/Distributed/Distributed-SAC.ipynb", "tutorials/pad/Distributed/Distributed-Speed-SAC.ipynb", "tutorials/pad/Distributed/index.rst", "tutorials/pad/Distributed/parallel_sac.rst", "tutorials/pad/Scenario.ipynb", "tutorials/pad/SingleAgent/Dummy-Continuos.ipynb", "tutorials/pad/SingleAgent/Dummy-Discrete.ipynb", "tutorials/pad/SingleAgent/index.rst", "tutorials/pad/index.rst", "tutorials/periodic_crossing/DifferentSpeed.ipynb", "tutorials/periodic_crossing/SameSpeed.ipynb", "tutorials/periodic_crossing/index.rst"], "indexentries": {"__call__() (pytorchpolicy method)": [[19, "navground.learning.types.PyTorchPolicy.__call__", false]], "__call__() (reward method)": [[19, "navground.learning.types.Reward.__call__", false]], "_get_dict() (registrable method)": [[17, "navground.learning.register.Registrable._get_dict", false]], "_make_from_dict() (registrable class method)": [[17, "navground.learning.register.Registrable._make_from_dict", false]], "accept_info() (in module navground.learning.types)": [[19, "navground.learning.types.accept_info", false]], "action (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.action", false]], "action (in module navground.learning.types)": [[19, "navground.learning.types.Action", false]], "action_config() (multiagentnavgroundenv method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.action_config", false]], "action_config() (navgroundenv method)": [[6, "navground.learning.env.NavgroundEnv.action_config", false]], "action_size (controlactionconfig property)": [[5, "navground.learning.config.ControlActionConfig.action_size", false]], "action_space (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.action_space", false]], "action_space (onnxpolicy property)": [[14, "navground.learning.onnx.OnnxPolicy.action_space", false]], "action_space() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.action_space", false]], "actionconfig (class in navground.learning.config)": [[5, "navground.learning.config.ActionConfig", false]], "actorspec (in module navground.learning.policies.split_sac_policy)": [[16, "navground.learning.policies.split_sac_policy.ActorSpec", false]], "actuate() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.actuate", false]], "actuate() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.actuate", false]], "actuated_twist (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.actuated_twist", false]], "actuated_twist (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.actuated_twist", false]], "actuated_wheel_speeds (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.actuated_wheel_speeds", false]], "actuated_wheel_speeds (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.actuated_wheel_speeds", false]], "add_modulation() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.add_modulation", false]], "add_modulation() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.add_modulation", false]], "all() (indices class method)": [[11, "navground.learning.indices.Indices.all", false]], "alternateactorcallback (class in navground.learning.policies.split_sac_policy)": [[16, "navground.learning.policies.split_sac_policy.AlternateActorCallback", false]], "alternateactorcallback (class in navground.learning.utils.benchmarl)": [[20, "navground.learning.utils.benchmarl.AlternateActorCallback", false]], "angular_speed (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.angular_speed", false]], "angular_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.angular_speed", false]], "anypolicy (in module navground.learning.il)": [[9, "navground.learning.il.AnyPolicy", false]], "anypolicypredictor (in module navground.learning.types)": [[19, "navground.learning.types.AnyPolicyPredictor", false]], "array (in module navground.learning.types)": [[19, "navground.learning.types.Array", false]], "as_set() (indices method)": [[11, "navground.learning.indices.Indices.as_set", false]], "asdict (controlactionconfig property)": [[5, "navground.learning.config.ControlActionConfig.asdict", false]], "asdict (defaultobservationconfig property)": [[5, "navground.learning.config.DefaultObservationConfig.asdict", false]], "asdict (defaultstateconfig property)": [[5, "navground.learning.config.DefaultStateConfig.asdict", false]], "asdict (groupconfig property)": [[5, "navground.learning.config.GroupConfig.asdict", false]], "asdict (indices property)": [[11, "navground.learning.indices.Indices.asdict", false]], "asdict (multiagentnavgroundenv property)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.asdict", false]], "asdict (navgroundenv property)": [[6, "navground.learning.env.NavgroundEnv.asdict", false]], "asdict (registrable property)": [[17, "navground.learning.register.Registrable.asdict", false]], "assume_cmd_is_actuated (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.assume_cmd_is_actuated", false]], "assume_cmd_is_actuated (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.assume_cmd_is_actuated", false]], "baseenv (in module navground.learning.env)": [[6, "navground.learning.env.BaseEnv", false]], "baseilalgorithm (class in navground.learning.il)": [[9, "navground.learning.il.BaseILAlgorithm", false]], "baseparallelenv (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.BaseParallelEnv", false]], "bc (class in navground.learning.il)": [[9, "navground.learning.il.BC", false]], "binarycontrolactionconfig (class in navground.learning.config)": [[5, "navground.learning.config.BinaryControlActionConfig", false]], "bounds (in module navground.learning.types)": [[19, "navground.learning.types.Bounds", false]], "centralizedpadbehavior (class in navground.learning.behaviors.pad)": [[13, "navground.learning.behaviors.pad.CentralizedPadBehavior", false]], "check_if_target_satisfied() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.check_if_target_satisfied", false]], "check_if_target_satisfied() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.check_if_target_satisfied", false]], "clear_modulations() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.clear_modulations", false]], "clear_modulations() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.clear_modulations", false]], "clone() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.clone", false]], "clone() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.clone", false]], "clone_behavior() (groupedpolicybehavior class method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.clone_behavior", false]], "clone_behavior() (policybehavior class method)": [[13, "navground.learning.behaviors.PolicyBehavior.clone_behavior", false]], "close() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.close", false]], "cmd_twist_along_path() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.cmd_twist_along_path", false]], "cmd_twist_along_path() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.cmd_twist_along_path", false]], "cmd_twist_towards_angular_speed() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.cmd_twist_towards_angular_speed", false]], "cmd_twist_towards_angular_speed() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.cmd_twist_towards_angular_speed", false]], "cmd_twist_towards_orientation() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.cmd_twist_towards_orientation", false]], "cmd_twist_towards_orientation() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.cmd_twist_towards_orientation", false]], "cmd_twist_towards_point() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.cmd_twist_towards_point", false]], "cmd_twist_towards_point() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.cmd_twist_towards_point", false]], "cmd_twist_towards_pose() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.cmd_twist_towards_pose", false]], "cmd_twist_towards_pose() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.cmd_twist_towards_pose", false]], "cmd_twist_towards_stopping() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.cmd_twist_towards_stopping", false]], "cmd_twist_towards_stopping() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.cmd_twist_towards_stopping", false]], "cmd_twist_towards_velocity() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.cmd_twist_towards_velocity", false]], "cmd_twist_towards_velocity() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.cmd_twist_towards_velocity", false]], "collect_runs() (bc method)": [[9, "navground.learning.il.BC.collect_runs", false]], "color (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.color", false]], "comm() (in module navground.learning.examples.pad)": [[8, "navground.learning.examples.pad.comm", false]], "comm_size (controlactionwithcommconfig attribute)": [[5, "navground.learning.config.ControlActionWithCommConfig.comm_size", false]], "comm_size (discretecontrolactionwithcommconfig attribute)": [[5, "navground.learning.config.DiscreteControlActionWithCommConfig.comm_size", false]], "comm_space (controlactionwithcommconfig property)": [[5, "navground.learning.config.ControlActionWithCommConfig.comm_space", false]], "comm_space (discretecontrolactionwithcommconfig property)": [[5, "navground.learning.config.DiscreteControlActionWithCommConfig.comm_space", false]], "commprobe (class in navground.learning.probes)": [[13, "navground.learning.probes.CommProbe", false]], "commsensor (class in navground.learning.state_estimations)": [[13, "navground.learning.state_estimations.CommSensor", false]], "compute_cmd() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.compute_cmd", false]], "compute_cmd() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.compute_cmd", false]], "compute_cmd_internal() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.compute_cmd_internal", false]], "config_eval_log() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.config_eval_log", false]], "configure() (actionconfig method)": [[5, "navground.learning.config.ActionConfig.configure", false]], "configure() (observationconfig method)": [[5, "navground.learning.config.ObservationConfig.configure", false]], "configure_kinematics() (controlactionconfig method)": [[5, "navground.learning.config.ControlActionConfig.configure_kinematics", false]], "configure_kinematics() (defaultobservationconfig method)": [[5, "navground.learning.config.DefaultObservationConfig.configure_kinematics", false]], "controlactionconfig (class in navground.learning.config)": [[5, "navground.learning.config.ControlActionConfig", false]], "controlactionwithcommconfig (class in navground.learning.config)": [[5, "navground.learning.config.ControlActionWithCommConfig", false]], "corridorwithobstacle (class in navground.learning.scenarios)": [[13, "navground.learning.scenarios.CorridorWithObstacle", false]], "dagger (class in navground.learning.il)": [[9, "navground.learning.il.DAgger", false]], "defaultobservationconfig (class in navground.learning.config)": [[5, "navground.learning.config.DefaultObservationConfig", false]], "defaultstateconfig (class in navground.learning.config)": [[5, "navground.learning.config.DefaultStateConfig", false]], "desired_velocity (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.desired_velocity", false]], "desired_velocity (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.desired_velocity", false]], "desired_velocity_towards_point() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.desired_velocity_towards_point", false]], "desired_velocity_towards_point() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.desired_velocity_towards_point", false]], "desired_velocity_towards_velocity() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.desired_velocity_towards_velocity", false]], "desired_velocity_towards_velocity() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.desired_velocity_towards_velocity", false]], "deterministic (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.deterministic", false]], "deterministic (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.deterministic", false]], "deterministic (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.deterministic", false]], "discretecontrolactionconfig (class in navground.learning.config)": [[5, "navground.learning.config.DiscreteControlActionConfig", false]], "discretecontrolactionwithcommconfig (class in navground.learning.config)": [[5, "navground.learning.config.DiscreteControlActionWithCommConfig", false]], "display_episode_video() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.display_episode_video", false]], "display_run_video() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.display_run_video", false]], "distributedcommpolicy (class in navground.learning.policies.centralized_policy_with_comm)": [[16, "navground.learning.policies.centralized_policy_with_comm.DistributedCommPolicy", false]], "distributedpadbehavior (class in navground.learning.behaviors.pad)": [[13, "navground.learning.behaviors.pad.DistributedPadBehavior", false]], "dtype (commprobe attribute)": [[13, "navground.learning.probes.CommProbe.dtype", false]], "dtype (rewardprobe attribute)": [[13, "navground.learning.probes.RewardProbe.dtype", false]], "dtype (successprobe attribute)": [[13, "navground.learning.probes.SuccessProbe.dtype", false]], "dump() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.dump", false]], "dump() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.dump", false]], "efficacy (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.efficacy", false]], "efficacy (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.efficacy", false]], "efficacyreward (class in navground.learning.rewards)": [[18, "navground.learning.rewards.EfficacyReward", false]], "env (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.env", false]], "environment_state (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.environment_state", false]], "environment_state (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.environment_state", false]], "episodestart (in module navground.learning.types)": [[19, "navground.learning.types.EpisodeStart", false]], "estimate_time_until_target_satisfied() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.estimate_time_until_target_satisfied", false]], "estimate_time_until_target_satisfied() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.estimate_time_until_target_satisfied", false]], "evaluate() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate", false]], "evaluate_policies() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate_policies", false]], "evaluate_policy() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate_policy", false]], "evaluate_policy() (in module navground.learning.utils.benchmarl)": [[20, "navground.learning.utils.benchmarl.evaluate_policy", false]], "evaluate_policy() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.evaluate_policy", false]], "evaluate_with_experiment() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate_with_experiment", false]], "evaluate_with_experiment_and_env() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate_with_experiment_and_env", false]], "export() (in module navground.learning.onnx)": [[14, "navground.learning.onnx.export", false]], "export_behavior() (in module navground.learning.io)": [[12, "navground.learning.io.export_behavior", false]], "export_policies() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.export_policies", false]], "export_policy() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.export_policy", false]], "export_policy_as_behavior() (in module navground.learning.io)": [[12, "navground.learning.io.export_policy_as_behavior", false]], "exportonnxcallback (class in navground.learning.utils.sb3)": [[20, "navground.learning.utils.sb3.ExportOnnxCallback", false]], "exportpolicycallback (class in navground.learning.utils.benchmarl)": [[20, "navground.learning.utils.benchmarl.ExportPolicyCallback", false]], "failure_condition (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.failure_condition", false]], "feasible_angular_speed() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.feasible_angular_speed", false]], "feasible_angular_speed() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.feasible_angular_speed", false]], "feasible_speed() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.feasible_speed", false]], "feasible_speed() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.feasible_speed", false]], "feasible_twist() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.feasible_twist", false]], "feasible_twist() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.feasible_twist", false]], "feasible_twist_from_current() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.feasible_twist_from_current", false]], "feasible_twist_from_current() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.feasible_twist_from_current", false]], "fix_orientation (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.fix_orientation", false]], "fix_orientation (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.fix_orientation", false]], "fix_orientation (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.fix_orientation", false]], "fixedreward (class in navground.learning.rewards)": [[18, "navground.learning.rewards.FixedReward", false]], "flat (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.flat", false]], "flat (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.flat", false]], "flat (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.flat", false]], "flat_values (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.flat_values", false]], "forward() (pytorchpolicy method)": [[19, "navground.learning.types.PyTorchPolicy.forward", false]], "forwardscenario (class in navground.learning.scenarios)": [[13, "navground.learning.scenarios.ForwardScenario", false]], "from_dict() (controlactionconfig class method)": [[5, "navground.learning.config.ControlActionConfig.from_dict", false]], "from_dict() (defaultobservationconfig class method)": [[5, "navground.learning.config.DefaultObservationConfig.from_dict", false]], "from_dict() (defaultstateconfig class method)": [[5, "navground.learning.config.DefaultStateConfig.from_dict", false]], "from_dict() (indices class method)": [[11, "navground.learning.indices.Indices.from_dict", false]], "from_dict() (modulationactionconfig class method)": [[5, "navground.learning.config.ModulationActionConfig.from_dict", false]], "from_dict() (multiagentnavgroundenv class method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.from_dict", false]], "from_dict() (navgroundenv class method)": [[6, "navground.learning.env.NavgroundEnv.from_dict", false]], "from_dict() (registrable class method)": [[17, "navground.learning.register.Registrable.from_dict", false]], "generate_trajectories() (in module navground.learning.il.rollout)": [[9, "navground.learning.il.rollout.generate_trajectories", false]], "get() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get", false]], "get() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get", false]], "get_action() (actionconfig method)": [[5, "navground.learning.config.ActionConfig.get_action", false]], "get_actuated_twist() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_actuated_twist", false]], "get_actuated_twist() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_actuated_twist", false]], "get_cmd_from_action() (actionconfig method)": [[5, "navground.learning.config.ActionConfig.get_cmd_from_action", false]], "get_cmd_from_action() (multiagentnavgroundenv method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.get_cmd_from_action", false]], "get_cmd_from_action() (navgroundenv method)": [[6, "navground.learning.env.NavgroundEnv.get_cmd_from_action", false]], "get_env() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.get_env", false]], "get_env() (in module navground.learning.examples.corridor_with_obstacle)": [[8, "navground.learning.examples.corridor_with_obstacle.get_env", false]], "get_env() (in module navground.learning.examples.cross)": [[8, "navground.learning.examples.cross.get_env", false]], "get_env() (in module navground.learning.examples.pad)": [[8, "navground.learning.examples.pad.get_env", false]], "get_indices() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.get_indices", false]], "get_policy() (multiagentnavgroundenv method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.get_policy", false]], "get_property_type_name() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_property_type_name", false]], "get_property_type_name() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_property_type_name", false]], "get_single_agent_policies() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.get_single_agent_policies", false]], "get_single_agent_policy() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.get_single_agent_policy", false]], "get_space() (stateconfig method)": [[5, "navground.learning.config.StateConfig.get_space", false]], "get_state() (stateconfig method)": [[5, "navground.learning.config.StateConfig.get_state", false]], "get_target_angular_direction() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_angular_direction", false]], "get_target_angular_direction() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_angular_direction", false]], "get_target_angular_distance() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_angular_distance", false]], "get_target_angular_distance() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_angular_distance", false]], "get_target_angular_speed() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_angular_speed", false]], "get_target_angular_speed() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_angular_speed", false]], "get_target_angular_velocity() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_angular_velocity", false]], "get_target_angular_velocity() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_angular_velocity", false]], "get_target_direction() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_direction", false]], "get_target_direction() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_direction", false]], "get_target_distance() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_distance", false]], "get_target_distance() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_distance", false]], "get_target_orientation() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_orientation", false]], "get_target_orientation() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_orientation", false]], "get_target_pose() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_pose", false]], "get_target_pose() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_pose", false]], "get_target_position() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_position", false]], "get_target_position() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_position", false]], "get_target_speed() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_speed", false]], "get_target_speed() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_speed", false]], "get_target_twist() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_twist", false]], "get_target_twist() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_twist", false]], "get_target_velocity() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_target_velocity", false]], "get_target_velocity() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_target_velocity", false]], "get_twist() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_twist", false]], "get_twist() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_twist", false]], "get_velocity() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.get_velocity", false]], "get_velocity() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.get_velocity", false]], "groupconfig (class in navground.learning.config)": [[5, "navground.learning.config.GroupConfig", false]], "groupedpolicybehavior (class in navground.learning.behaviors)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior", false]], "groupedpolicybehavior.heading (class in navground.learning.behaviors)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.Heading", false]], "gymprobe (class in navground.learning.probes)": [[13, "navground.learning.probes.GymProbe", false]], "has() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.has", false]], "has() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.has", false]], "has_target (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.has_target", false]], "has_target (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.has_target", false]], "has_type() (groupedpolicybehavior static method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.has_type", false]], "has_type() (policybehavior static method)": [[13, "navground.learning.behaviors.PolicyBehavior.has_type", false]], "has_wheels (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.has_wheels", false]], "heading_behavior (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.heading_behavior", false]], "heading_behavior (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.heading_behavior", false]], "history (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.history", false]], "history (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.history", false]], "history (observationconfig property)": [[5, "navground.learning.config.ObservationConfig.history", false]], "history (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.history", false]], "horizon (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.horizon", false]], "horizon (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.horizon", false]], "ignore_keys (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.ignore_keys", false]], "include_all (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_all", false]], "include_angular_speed (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_angular_speed", false]], "include_angular_speed (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_angular_speed", false]], "include_angular_speed (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.include_angular_speed", false]], "include_angular_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_angular_speed", false]], "include_orientation (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_orientation", false]], "include_orientation (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_orientation", false]], "include_position (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_position", false]], "include_position (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_position", false]], "include_radius (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_radius", false]], "include_radius (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_radius", false]], "include_radius (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.include_radius", false]], "include_radius (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_radius", false]], "include_target_angular_speed (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_angular_speed", false]], "include_target_angular_speed (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_target_angular_speed", false]], "include_target_angular_speed (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.include_target_angular_speed", false]], "include_target_angular_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_angular_speed", false]], "include_target_direction (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_direction", false]], "include_target_direction (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_target_direction", false]], "include_target_direction (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.include_target_direction", false]], "include_target_direction (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_direction", false]], "include_target_direction_validity (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_direction_validity", false]], "include_target_direction_validity (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_target_direction_validity", false]], "include_target_direction_validity (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.include_target_direction_validity", false]], "include_target_direction_validity (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_direction_validity", false]], "include_target_distance (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_distance", false]], "include_target_distance (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_target_distance", false]], "include_target_distance (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.include_target_distance", false]], "include_target_distance (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_distance", false]], "include_target_distance_validity (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_distance_validity", false]], "include_target_distance_validity (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_target_distance_validity", false]], "include_target_distance_validity (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.include_target_distance_validity", false]], "include_target_distance_validity (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_distance_validity", false]], "include_target_orientation (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_orientation", false]], "include_target_orientation (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_target_orientation", false]], "include_target_orientation_validity (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_orientation_validity", false]], "include_target_orientation_validity (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_target_orientation_validity", false]], "include_target_speed (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_speed", false]], "include_target_speed (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_target_speed", false]], "include_target_speed (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.include_target_speed", false]], "include_target_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_speed", false]], "include_velocity (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_velocity", false]], "include_velocity (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_velocity", false]], "include_velocity (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.include_velocity", false]], "include_velocity (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_velocity", false]], "include_x (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_x", false]], "include_y (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.include_y", false]], "indices (class in navground.learning.indices)": [[11, "navground.learning.indices.Indices", false]], "indices (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.indices", false]], "indiceslike (in module navground.learning.indices)": [[19, "navground.learning.indices.IndicesLike", false]], "info (in module navground.learning.types)": [[19, "navground.learning.types.Info", false]], "infopolicy (class in navground.learning.policies.info_predictor)": [[16, "navground.learning.policies.info_predictor.InfoPolicy", false]], "init_args (multiagentnavgroundenv property)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.init_args", false]], "init_args (navgroundenv property)": [[6, "navground.learning.env.NavgroundEnv.init_args", false]], "init_policy() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.init_policy", false]], "init_policy() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.init_policy", false]], "init_world() (corridorwithobstacle method)": [[13, "navground.learning.scenarios.CorridorWithObstacle.init_world", false]], "init_world() (forwardscenario method)": [[13, "navground.learning.scenarios.ForwardScenario.init_world", false]], "initpolicybehavior (class in navground.learning.evaluation)": [[7, "navground.learning.evaluation.InitPolicyBehavior", false]], "inputspec (in module navground.learning.policies.split_sac_policy)": [[16, "navground.learning.policies.split_sac_policy.InputSpec", false]], "intersect() (indices method)": [[11, "navground.learning.indices.Indices.intersect", false]], "is_configured() (actionconfig method)": [[5, "navground.learning.config.ActionConfig.is_configured", false]], "is_configured() (observationconfig method)": [[5, "navground.learning.config.ObservationConfig.is_configured", false]], "is_stopped() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.is_stopped", false]], "is_stopped() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.is_stopped", false]], "is_stuck (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.is_stuck", false]], "is_stuck (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.is_stuck", false]], "join_indices() (in module navground.learning.indices)": [[11, "navground.learning.indices.join_indices", false]], "jointenv (class in navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.JointEnv", false]], "keys (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.keys", false]], "kinematics (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.kinematics", false]], "kinematics (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.kinematics", false]], "learn() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.learn", false]], "length (corridorwithobstacle property)": [[13, "navground.learning.scenarios.CorridorWithObstacle.length", false]], "load() (baseilalgorithm class method)": [[9, "navground.learning.il.BaseILAlgorithm.load", false]], "load() (groupedpolicybehavior static method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.load", false]], "load() (policybehavior static method)": [[13, "navground.learning.behaviors.PolicyBehavior.load", false]], "load_behavior() (in module navground.learning.io)": [[12, "navground.learning.io.load_behavior", false]], "load_env() (in module navground.learning.io)": [[12, "navground.learning.io.load_env", false]], "load_eval_logs() (in module navground.learning.utils.sb3)": [[20, "navground.learning.utils.sb3.load_eval_logs", false]], "load_log() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.load_log", false]], "load_policies() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.load_policies", false]], "load_policy() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.load_policy", false]], "log_directory (navgroundexperiment property)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.log_directory", false]], "logfield (class in navground.learning.utils.plot)": [[20, "navground.learning.utils.plot.LogField", false]], "logger (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.logger", false]], "lowest (indices property)": [[11, "navground.learning.indices.Indices.lowest", false]], "make_env() (in module navground.learning.utils.benchmarl)": [[20, "navground.learning.utils.benchmarl.make_env", false]], "make_experiment() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.make_experiment", false]], "make_experiment_with_env() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.make_experiment_with_env", false]], "make_order_invariant_flatten_extractor() (in module navground.learning.policies.order_invariant)": [[16, "navground.learning.policies.order_invariant.make_order_invariant_flatten_extractor", false]], "make_shared_parallel_env_with_env() (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.make_shared_parallel_env_with_env", false]], "make_type() (groupedpolicybehavior static method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.make_type", false]], "make_type() (policybehavior static method)": [[13, "navground.learning.behaviors.PolicyBehavior.make_type", false]], "make_vec_from_env() (in module navground.learning.il)": [[9, "navground.learning.il.make_vec_from_env", false]], "make_vec_from_penv() (in module navground.learning.il)": [[9, "navground.learning.il.make_vec_from_penv", false]], "make_vec_from_penv() (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.make_vec_from_penv", false]], "marker() (in module navground.learning.examples.pad)": [[8, "navground.learning.examples.pad.marker", false]], "maskwrapper (class in navground.learning.wrappers)": [[21, "navground.learning.wrappers.MaskWrapper", false]], "max_acceleration (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.max_acceleration", false]], "max_acceleration (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.max_acceleration", false]], "max_acceleration (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.max_acceleration", false]], "max_angular_acceleration (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.max_angular_acceleration", false]], "max_angular_acceleration (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.max_angular_acceleration", false]], "max_angular_acceleration (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.max_angular_acceleration", false]], "max_angular_speed (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.max_angular_speed", false]], "max_angular_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.max_angular_speed", false]], "max_radius (corridorwithobstacle property)": [[13, "navground.learning.scenarios.CorridorWithObstacle.max_radius", false]], "max_radius (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.max_radius", false]], "max_radius (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.max_radius", false]], "max_speed (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.max_speed", false]], "max_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.max_speed", false]], "max_target_distance (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.max_target_distance", false]], "max_target_distance (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.max_target_distance", false]], "max_x (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.max_x", false]], "max_y (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.max_y", false]], "merge_groups_configs() (in module navground.learning.config)": [[5, "navground.learning.config.merge_groups_configs", false]], "min_radius (corridorwithobstacle property)": [[13, "navground.learning.scenarios.CorridorWithObstacle.min_radius", false]], "min_x (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.min_x", false]], "min_y (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.min_y", false]], "modulationactionconfig (class in navground.learning.config)": [[5, "navground.learning.config.ModulationActionConfig", false]], "modulations (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.modulations", false]], "modulations (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.modulations", false]], "module": [[5, "module-navground.learning.config", false], [6, "module-navground.learning.env", false], [7, "module-navground.learning.evaluation", false], [8, "module-navground.learning.examples", false], [8, "module-navground.learning.examples.corridor_with_obstacle", false], [8, "module-navground.learning.examples.cross", false], [8, "module-navground.learning.examples.pad", false], [9, "module-navground.learning.il", false], [10, "module-navground.learning", false], [11, "module-navground.learning.indices", false], [12, "module-navground.learning.io", false], [13, "module-navground.learning.behaviors", false], [13, "module-navground.learning.behaviors.pad", false], [13, "module-navground.learning.probes", false], [13, "module-navground.learning.scenarios", false], [13, "module-navground.learning.state_estimations", false], [14, "module-navground.learning.onnx", false], [15, "module-navground.learning.parallel_env", false], [16, "module-navground.learning.policies", false], [17, "module-navground.learning.register", false], [19, "module-navground.learning.types", false], [20, "module-navground.learning.utils", false], [20, "module-navground.learning.utils.benchmarl", false], [20, "module-navground.learning.utils.plot", false], [20, "module-navground.learning.utils.sb3", false], [21, "module-navground.learning.wrappers", false]], "multiagentnavgroundenv (class in navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv", false]], "name (groupedpolicybehavior.heading property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.Heading.name", false]], "name (policybehavior.heading property)": [[13, "navground.learning.behaviors.PolicyBehavior.Heading.name", false]], "namewrapper (class in navground.learning.wrappers)": [[21, "navground.learning.wrappers.NameWrapper", false]], "navground.learning": [[10, "module-navground.learning", false]], "navground.learning.behaviors": [[13, "module-navground.learning.behaviors", false]], "navground.learning.behaviors.pad": [[13, "module-navground.learning.behaviors.pad", false]], "navground.learning.config": [[5, "module-navground.learning.config", false]], "navground.learning.env": [[6, "module-navground.learning.env", false]], "navground.learning.evaluation": [[7, "module-navground.learning.evaluation", false]], "navground.learning.examples": [[8, "module-navground.learning.examples", false]], "navground.learning.examples.corridor_with_obstacle": [[8, "module-navground.learning.examples.corridor_with_obstacle", false]], "navground.learning.examples.cross": [[8, "module-navground.learning.examples.cross", false]], "navground.learning.examples.pad": [[8, "module-navground.learning.examples.pad", false]], "navground.learning.il": [[9, "module-navground.learning.il", false]], "navground.learning.indices": [[11, "module-navground.learning.indices", false]], "navground.learning.io": [[12, "module-navground.learning.io", false]], "navground.learning.onnx": [[14, "module-navground.learning.onnx", false]], "navground.learning.parallel_env": [[15, "module-navground.learning.parallel_env", false]], "navground.learning.policies": [[16, "module-navground.learning.policies", false]], "navground.learning.probes": [[13, "module-navground.learning.probes", false]], "navground.learning.register": [[17, "module-navground.learning.register", false]], "navground.learning.scenarios": [[13, "module-navground.learning.scenarios", false]], "navground.learning.state_estimations": [[13, "module-navground.learning.state_estimations", false]], "navground.learning.types": [[19, "module-navground.learning.types", false]], "navground.learning.utils": [[20, "module-navground.learning.utils", false]], "navground.learning.utils.benchmarl": [[20, "module-navground.learning.utils.benchmarl", false]], "navground.learning.utils.plot": [[20, "module-navground.learning.utils.plot", false]], "navground.learning.utils.sb3": [[20, "module-navground.learning.utils.sb3", false]], "navground.learning.wrappers": [[21, "module-navground.learning.wrappers", false]], "navgroundenv (class in navground.learning.env)": [[6, "navground.learning.env.NavgroundEnv", false]], "navgroundexperiment (class in navground.learning.utils.benchmarl)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment", false]], "neighbor() (in module navground.learning.examples.pad)": [[8, "navground.learning.examples.pad.neighbor", false]], "netarch (in module navground.learning.policies.split_sac_policy)": [[16, "navground.learning.policies.split_sac_policy.NetArch", false]], "normalize (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.normalize", false]], "nullpolicy (class in navground.learning.policies.null_policy)": [[16, "navground.learning.policies.null_policy.NullPolicy", false]], "nullpredictor (class in navground.learning.policies.null_predictor)": [[16, "navground.learning.policies.null_predictor.NullPredictor", false]], "nullreward (class in navground.learning.rewards)": [[18, "navground.learning.rewards.NullReward", false]], "observation (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.observation", false]], "observation (in module navground.learning.types)": [[19, "navground.learning.types.Observation", false]], "observation_config() (multiagentnavgroundenv method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.observation_config", false]], "observation_config() (navgroundenv method)": [[6, "navground.learning.env.NavgroundEnv.observation_config", false]], "observation_space (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.observation_space", false]], "observation_space (onnxpolicy property)": [[14, "navground.learning.onnx.OnnxPolicy.observation_space", false]], "observation_space() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.observation_space", false]], "observationconfig (class in navground.learning.config)": [[5, "navground.learning.config.ObservationConfig", false]], "observationtransform (in module navground.learning.types)": [[19, "navground.learning.types.ObservationTransform", false]], "onnxpolicy (class in navground.learning.onnx)": [[14, "navground.learning.onnx.OnnxPolicy", false]], "optimal_angular_speed (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.optimal_angular_speed", false]], "optimal_angular_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.optimal_angular_speed", false]], "optimal_speed (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.optimal_speed", false]], "optimal_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.optimal_speed", false]], "orderinvariantcombinedextractor (class in navground.learning.policies.order_invariant)": [[16, "navground.learning.policies.order_invariant.OrderInvariantCombinedExtractor", false]], "orderinvariantflattenextractor (class in navground.learning.policies.order_invariant)": [[16, "navground.learning.policies.order_invariant.OrderInvariantFlattenExtractor", false]], "orientation (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.orientation", false]], "orientation (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.orientation", false]], "pad_width (distributedpadbehavior property)": [[13, "navground.learning.behaviors.pad.DistributedPadBehavior.pad_width", false]], "pad_width (stopatpadbehavior property)": [[13, "navground.learning.behaviors.pad.StopAtPadBehavior.pad_width", false]], "padreward (class in navground.learning.examples.pad)": [[8, "navground.learning.examples.pad.PadReward", false]], "padscenario (class in navground.learning.scenarios)": [[13, "navground.learning.scenarios.PadScenario", false]], "parallel_env() (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.parallel_env", false]], "params (modulationactionconfig attribute)": [[5, "navground.learning.config.ModulationActionConfig.params", false]], "path_look_ahead (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.path_look_ahead", false]], "path_look_ahead (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.path_look_ahead", false]], "path_tau (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.path_tau", false]], "path_tau (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.path_tau", false]], "pathlike (in module navground.learning.types)": [[19, "navground.learning.types.PathLike", false]], "plot_eval_logs() (in module navground.learning.utils.sb3)": [[20, "navground.learning.utils.sb3.plot_eval_logs", false]], "plot_eval_logs() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.plot_eval_logs", false]], "plot_logs() (in module navground.learning.utils.plot)": [[20, "navground.learning.utils.plot.plot_logs", false]], "plot_policy() (in module navground.learning.utils.plot)": [[20, "navground.learning.utils.plot.plot_policy", false]], "policy (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.policy", false]], "policy (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.policy", false]], "policy (navgroundenv property)": [[6, "navground.learning.env.NavgroundEnv.policy", false]], "policy_path (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.policy_path", false]], "policy_path (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.policy_path", false]], "policybehavior (class in navground.learning.behaviors)": [[13, "navground.learning.behaviors.PolicyBehavior", false]], "policybehavior.heading (class in navground.learning.behaviors)": [[13, "navground.learning.behaviors.PolicyBehavior.Heading", false]], "policycallable (in module navground.learning.il)": [[9, "navground.learning.il.PolicyCallable", false]], "policycallablewithinfo (in module navground.learning.il)": [[9, "navground.learning.il.PolicyCallableWithInfo", false]], "policypredictor (class in navground.learning.types)": [[19, "navground.learning.types.PolicyPredictor", false]], "policypredictorwithinfo (class in navground.learning.types)": [[19, "navground.learning.types.PolicyPredictorWithInfo", false]], "pose (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.pose", false]], "pose (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.pose", false]], "position (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.position", false]], "position (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.position", false]], "predict() (onnxpolicy method)": [[14, "navground.learning.onnx.OnnxPolicy.predict", false]], "predict() (policypredictor method)": [[19, "navground.learning.types.PolicyPredictor.predict", false]], "predict() (policypredictorwithinfo method)": [[19, "navground.learning.types.PolicyPredictorWithInfo.predict", false]], "progressbarwithrewardcallback (class in navground.learning.utils.sb3)": [[20, "navground.learning.utils.sb3.ProgressBarWithRewardCallback", false]], "properties (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.properties", false]], "properties (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.properties", false]], "pytorchobs (in module navground.learning.types)": [[19, "navground.learning.types.PyTorchObs", false]], "pytorchpolicy (class in navground.learning.types)": [[19, "navground.learning.types.PyTorchPolicy", false]], "radius (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.radius", false]], "radius (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.radius", false]], "randompolicy (class in navground.learning.policies.random_policy)": [[16, "navground.learning.policies.random_policy.RandomPolicy", false]], "randompredictor (class in navground.learning.policies.random_predictor)": [[16, "navground.learning.policies.random_predictor.RandomPredictor", false]], "record_episode_video() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.record_episode_video", false]], "record_run_video() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.record_run_video", false]], "reduction (in module navground.learning.policies)": [[16, "navground.learning.policies.Reduction", false]], "register_schema() (groupedpolicybehavior static method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.register_schema", false]], "register_schema() (policybehavior static method)": [[13, "navground.learning.behaviors.PolicyBehavior.register_schema", false]], "registrable (class in navground.learning.register)": [[17, "navground.learning.register.Registrable", false]], "reload_from_file() (navgroundexperiment static method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.reload_from_file", false]], "remove_modulation() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.remove_modulation", false]], "remove_modulation() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.remove_modulation", false]], "render_kwargs() (in module navground.learning.scenarios.pad)": [[13, "navground.learning.scenarios.pad.render_kwargs", false]], "reset() (multiagentnavgroundenv method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.reset", false]], "reset() (navgroundenv method)": [[6, "navground.learning.env.NavgroundEnv.reset", false]], "reward (class in navground.learning.types)": [[19, "navground.learning.types.Reward", false]], "reward (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.reward", false]], "rewardprobe (class in navground.learning.probes)": [[13, "navground.learning.probes.RewardProbe", false]], "rotation_tau (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.rotation_tau", false]], "rotation_tau (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.rotation_tau", false]], "run_for() (navgroundexperiment method)": [[20, "navground.learning.utils.benchmarl.NavgroundExperiment.run_for", false]], "sacpolicywithcomm (class in navground.learning.policies.centralized_policy_with_comm)": [[16, "navground.learning.policies.centralized_policy_with_comm.SACPolicyWithComm", false]], "safety_margin (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.safety_margin", false]], "safety_margin (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.safety_margin", false]], "save() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.save", false]], "save_env() (in module navground.learning.io)": [[12, "navground.learning.io.save_env", false]], "scenario (multiagentnavgroundenv property)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.scenario", false]], "scenario (navgroundenv property)": [[6, "navground.learning.env.NavgroundEnv.scenario", false]], "schema() (groupedpolicybehavior static method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.schema", false]], "schema() (policybehavior static method)": [[13, "navground.learning.behaviors.PolicyBehavior.schema", false]], "sensorlike (in module navground.learning.types)": [[19, "navground.learning.types.SensorLike", false]], "sensors (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.sensors", false]], "sensorsequencelike (in module navground.learning.types)": [[19, "navground.learning.types.SensorSequenceLike", false]], "set() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.set", false]], "set() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.set", false]], "set_env() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.set_env", false]], "set_logger() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.set_logger", false]], "set_state_from() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.set_state_from", false]], "set_state_from() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.set_state_from", false]], "set_velocity() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.set_velocity", false]], "set_velocity() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.set_velocity", false]], "setup_tqdm() (in module navground.learning.il)": [[9, "navground.learning.il.setup_tqdm", false]], "shared_parallel_env() (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.shared_parallel_env", false]], "singleagentpolicy (class in navground.learning.utils.benchmarl)": [[20, "navground.learning.utils.benchmarl.SingleAgentPolicy", false]], "social_margin (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.social_margin", false]], "social_margin (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.social_margin", false]], "socialreward (class in navground.learning.rewards)": [[18, "navground.learning.rewards.SocialReward", false]], "sort_keys (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.sort_keys", false]], "space (actionconfig property)": [[5, "navground.learning.config.ActionConfig.space", false]], "space (binarycontrolactionconfig property)": [[5, "navground.learning.config.BinaryControlActionConfig.space", false]], "space (controlactionconfig property)": [[5, "navground.learning.config.ControlActionConfig.space", false]], "space (discretecontrolactionconfig property)": [[5, "navground.learning.config.DiscreteControlActionConfig.space", false]], "space (discretecontrolactionwithcommconfig property)": [[5, "navground.learning.config.DiscreteControlActionWithCommConfig.space", false]], "space (modulationactionconfig property)": [[5, "navground.learning.config.ModulationActionConfig.space", false]], "speed (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.speed", false]], "speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.speed", false]], "splitsacpolicy (class in navground.learning.policies.split_sac_policy)": [[16, "navground.learning.policies.split_sac_policy.SplitSACPolicy", false]], "state (in module navground.learning.types)": [[19, "navground.learning.types.State", false]], "stateconfig (class in navground.learning.config)": [[5, "navground.learning.config.StateConfig", false]], "step() (multiagentnavgroundenv method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.step", false]], "step() (navgroundenv method)": [[6, "navground.learning.env.NavgroundEnv.step", false]], "stopatpadbehavior (class in navground.learning.behaviors.pad)": [[13, "navground.learning.behaviors.pad.StopAtPadBehavior", false]], "sub_dict() (indices method)": [[11, "navground.learning.indices.Indices.sub_dict", false]], "sub_sequence() (indices method)": [[11, "navground.learning.indices.Indices.sub_sequence", false]], "success_condition (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.success_condition", false]], "successprobe (class in navground.learning.probes)": [[13, "navground.learning.probes.SuccessProbe", false]], "t (in module navground.learning.indices)": [[11, "navground.learning.indices.T", false]], "tag (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.tag", false]], "target (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.target", false]], "target (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.target", false]], "target_ref (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.target_ref", false]], "target_ref (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.target_ref", false]], "tau (stopatpadbehavior property)": [[13, "navground.learning.behaviors.pad.StopAtPadBehavior.tau", false]], "terminate_on_failure (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.terminate_on_failure", false]], "terminate_on_success (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.terminate_on_success", false]], "terminationcondition (in module navground.learning.types)": [[19, "navground.learning.types.TerminationCondition", false]], "to_frame() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.to_frame", false]], "to_frame() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.to_frame", false]], "trajectoryplotconfig (class in navground.learning.evaluation)": [[7, "navground.learning.evaluation.TrajectoryPlotConfig", false]], "twist (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.twist", false]], "twist (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.twist", false]], "twist_from_wheel_speeds() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.twist_from_wheel_speeds", false]], "twist_from_wheel_speeds() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.twist_from_wheel_speeds", false]], "twist_towards_velocity() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.twist_towards_velocity", false]], "twist_towards_velocity() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.twist_towards_velocity", false]], "type (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.type", false]], "type (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.type", false]], "use_absolute_frame (defaultstateconfig attribute)": [[5, "navground.learning.config.DefaultStateConfig.use_absolute_frame", false]], "use_acceleration_action (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.use_acceleration_action", false]], "use_acceleration_action (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.use_acceleration_action", false]], "use_acceleration_action (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.use_acceleration_action", false]], "use_wheels (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.use_wheels", false]], "use_wheels (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.use_wheels", false]], "use_wheels (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.use_wheels", false]], "velocity (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.velocity", false]], "velocity (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.velocity", false]], "videocallback (class in navground.learning.utils.sb3)": [[20, "navground.learning.utils.sb3.VideoCallback", false]], "videoconfig (class in navground.learning.evaluation)": [[7, "navground.learning.evaluation.VideoConfig", false]], "wheel_speeds (groupedpolicybehavior property)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.wheel_speeds", false]], "wheel_speeds (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.wheel_speeds", false]], "wheel_speeds_from_twist() (groupedpolicybehavior method)": [[13, "navground.learning.behaviors.GroupedPolicyBehavior.wheel_speeds_from_twist", false]], "wheel_speeds_from_twist() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.wheel_speeds_from_twist", false]], "width (corridorwithobstacle property)": [[13, "navground.learning.scenarios.CorridorWithObstacle.width", false]], "with_env() (gymprobe class method)": [[13, "navground.learning.probes.GymProbe.with_env", false]], "with_env() (initpolicybehavior class method)": [[7, "navground.learning.evaluation.InitPolicyBehavior.with_env", false]], "with_indices() (successprobe class method)": [[13, "navground.learning.probes.SuccessProbe.with_indices", false]], "with_reward() (rewardprobe class method)": [[13, "navground.learning.probes.RewardProbe.with_reward", false]]}, "objects": {"navground": [[10, 0, 0, "-", "learning"]], "navground.learning": [[13, 0, 0, "-", "behaviors"], [5, 0, 0, "-", "config"], [6, 0, 0, "-", "env"], [7, 0, 0, "-", "evaluation"], [8, 0, 0, "-", "examples"], [9, 0, 0, "-", "il"], [11, 0, 0, "-", "indices"], [12, 0, 0, "-", "io"], [14, 0, 0, "-", "onnx"], [15, 0, 0, "-", "parallel_env"], [16, 0, 0, "-", "policies"], [13, 0, 0, "-", "probes"], [17, 0, 0, "-", "register"], [13, 0, 0, "-", "scenarios"], [13, 0, 0, "-", "state_estimations"], [19, 0, 0, "-", "types"], [20, 0, 0, "-", "utils"], [21, 0, 0, "-", "wrappers"]], "navground.learning.behaviors": [[13, 1, 1, "", "GroupedPolicyBehavior"], [13, 1, 1, "", "PolicyBehavior"], [13, 0, 0, "-", "pad"]], "navground.learning.behaviors.GroupedPolicyBehavior": [[13, 1, 1, "", "Heading"], [13, 3, 1, "", "actuate"], [13, 2, 1, "", "actuated_twist"], [13, 2, 1, "", "actuated_wheel_speeds"], [13, 3, 1, "", "add_modulation"], [13, 2, 1, "", "angular_speed"], [13, 2, 1, "", "assume_cmd_is_actuated"], [13, 3, 1, "", "check_if_target_satisfied"], [13, 3, 1, "", "clear_modulations"], [13, 3, 1, "", "clone"], [13, 3, 1, "", "clone_behavior"], [13, 3, 1, "", "cmd_twist_along_path"], [13, 3, 1, "", "cmd_twist_towards_angular_speed"], [13, 3, 1, "", "cmd_twist_towards_orientation"], [13, 3, 1, "", "cmd_twist_towards_point"], [13, 3, 1, "", "cmd_twist_towards_pose"], [13, 3, 1, "", "cmd_twist_towards_stopping"], [13, 3, 1, "", "cmd_twist_towards_velocity"], [13, 3, 1, "", "compute_cmd"], [13, 3, 1, "", "compute_cmd_internal"], [13, 2, 1, "", "desired_velocity"], [13, 3, 1, "", "desired_velocity_towards_point"], [13, 3, 1, "", "desired_velocity_towards_velocity"], [13, 2, 1, "", "deterministic"], [13, 3, 1, "", "dump"], [13, 2, 1, "", "efficacy"], [13, 2, 1, "", "environment_state"], [13, 3, 1, "", "estimate_time_until_target_satisfied"], [13, 3, 1, "", "feasible_angular_speed"], [13, 3, 1, "", "feasible_speed"], [13, 3, 1, "", "feasible_twist"], [13, 3, 1, "", "feasible_twist_from_current"], [13, 2, 1, "", "fix_orientation"], [13, 2, 1, "", "flat"], [13, 3, 1, "", "get"], [13, 3, 1, "", "get_actuated_twist"], [13, 3, 1, "", "get_property_type_name"], [13, 3, 1, "", "get_target_angular_direction"], [13, 3, 1, "", "get_target_angular_distance"], [13, 3, 1, "", "get_target_angular_speed"], [13, 3, 1, "", "get_target_angular_velocity"], [13, 3, 1, "", "get_target_direction"], [13, 3, 1, "", "get_target_distance"], [13, 3, 1, "", "get_target_orientation"], [13, 3, 1, "", "get_target_pose"], [13, 3, 1, "", "get_target_position"], [13, 3, 1, "", "get_target_speed"], [13, 3, 1, "", "get_target_twist"], [13, 3, 1, "", "get_target_velocity"], [13, 3, 1, "", "get_twist"], [13, 3, 1, "", "get_velocity"], [13, 3, 1, "", "has"], [13, 2, 1, "", "has_target"], [13, 3, 1, "", "has_type"], [13, 2, 1, "", "heading_behavior"], [13, 2, 1, "", "history"], [13, 2, 1, "", "horizon"], [13, 2, 1, "", "include_angular_speed"], [13, 2, 1, "", "include_radius"], [13, 2, 1, "", "include_target_angular_speed"], [13, 2, 1, "", "include_target_direction"], [13, 2, 1, "", "include_target_direction_validity"], [13, 2, 1, "", "include_target_distance"], [13, 2, 1, "", "include_target_distance_validity"], [13, 2, 1, "", "include_target_speed"], [13, 2, 1, "", "include_velocity"], [13, 3, 1, "", "init_policy"], [13, 3, 1, "", "is_stopped"], [13, 2, 1, "", "is_stuck"], [13, 2, 1, "", "kinematics"], [13, 3, 1, "", "load"], [13, 3, 1, "", "make_type"], [13, 2, 1, "", "max_acceleration"], [13, 2, 1, "", "max_angular_acceleration"], [13, 2, 1, "", "max_angular_speed"], [13, 2, 1, "", "max_speed"], [13, 2, 1, "", "modulations"], [13, 2, 1, "", "optimal_angular_speed"], [13, 2, 1, "", "optimal_speed"], [13, 2, 1, "", "orientation"], [13, 2, 1, "", "path_look_ahead"], [13, 2, 1, "", "path_tau"], [13, 2, 1, "", "policy_path"], [13, 2, 1, "", "pose"], [13, 2, 1, "", "position"], [13, 2, 1, "", "properties"], [13, 2, 1, "", "radius"], [13, 3, 1, "", "register_schema"], [13, 3, 1, "", "remove_modulation"], [13, 2, 1, "", "rotation_tau"], [13, 2, 1, "", "safety_margin"], [13, 3, 1, "", "schema"], [13, 3, 1, "", "set"], [13, 3, 1, "", "set_state_from"], [13, 3, 1, "", "set_velocity"], [13, 2, 1, "", "social_margin"], [13, 2, 1, "", "speed"], [13, 2, 1, "", "target"], [13, 2, 1, "", "target_ref"], [13, 3, 1, "", "to_frame"], [13, 2, 1, "", "twist"], [13, 3, 1, "", "twist_from_wheel_speeds"], [13, 3, 1, "", "twist_towards_velocity"], [13, 2, 1, "", "type"], [13, 2, 1, "", "use_acceleration_action"], [13, 2, 1, "", "use_wheels"], [13, 2, 1, "", "velocity"], [13, 2, 1, "", "wheel_speeds"], [13, 3, 1, "", "wheel_speeds_from_twist"]], "navground.learning.behaviors.GroupedPolicyBehavior.Heading": [[13, 2, 1, "", "name"]], "navground.learning.behaviors.PolicyBehavior": [[13, 1, 1, "", "Heading"], [13, 3, 1, "", "actuate"], [13, 2, 1, "", "actuated_twist"], [13, 2, 1, "", "actuated_wheel_speeds"], [13, 3, 1, "", "add_modulation"], [13, 2, 1, "", "angular_speed"], [13, 2, 1, "", "assume_cmd_is_actuated"], [13, 3, 1, "", "check_if_target_satisfied"], [13, 3, 1, "", "clear_modulations"], [13, 3, 1, "", "clone"], [13, 3, 1, "", "clone_behavior"], [13, 3, 1, "", "close"], [13, 3, 1, "", "cmd_twist_along_path"], [13, 3, 1, "", "cmd_twist_towards_angular_speed"], [13, 3, 1, "", "cmd_twist_towards_orientation"], [13, 3, 1, "", "cmd_twist_towards_point"], [13, 3, 1, "", "cmd_twist_towards_pose"], [13, 3, 1, "", "cmd_twist_towards_stopping"], [13, 3, 1, "", "cmd_twist_towards_velocity"], [13, 3, 1, "", "compute_cmd"], [13, 2, 1, "", "desired_velocity"], [13, 3, 1, "", "desired_velocity_towards_point"], [13, 3, 1, "", "desired_velocity_towards_velocity"], [13, 2, 1, "", "deterministic"], [13, 3, 1, "", "dump"], [13, 2, 1, "", "efficacy"], [13, 2, 1, "", "environment_state"], [13, 3, 1, "", "estimate_time_until_target_satisfied"], [13, 3, 1, "", "feasible_angular_speed"], [13, 3, 1, "", "feasible_speed"], [13, 3, 1, "", "feasible_twist"], [13, 3, 1, "", "feasible_twist_from_current"], [13, 2, 1, "", "fix_orientation"], [13, 2, 1, "", "flat"], [13, 3, 1, "", "get"], [13, 3, 1, "", "get_actuated_twist"], [13, 3, 1, "", "get_property_type_name"], [13, 3, 1, "", "get_target_angular_direction"], [13, 3, 1, "", "get_target_angular_distance"], [13, 3, 1, "", "get_target_angular_speed"], [13, 3, 1, "", "get_target_angular_velocity"], [13, 3, 1, "", "get_target_direction"], [13, 3, 1, "", "get_target_distance"], [13, 3, 1, "", "get_target_orientation"], [13, 3, 1, "", "get_target_pose"], [13, 3, 1, "", "get_target_position"], [13, 3, 1, "", "get_target_speed"], [13, 3, 1, "", "get_target_twist"], [13, 3, 1, "", "get_target_velocity"], [13, 3, 1, "", "get_twist"], [13, 3, 1, "", "get_velocity"], [13, 3, 1, "", "has"], [13, 2, 1, "", "has_target"], [13, 3, 1, "", "has_type"], [13, 2, 1, "", "heading_behavior"], [13, 2, 1, "", "history"], [13, 2, 1, "", "horizon"], [13, 2, 1, "", "include_angular_speed"], [13, 2, 1, "", "include_radius"], [13, 2, 1, "", "include_target_angular_speed"], [13, 2, 1, "", "include_target_direction"], [13, 2, 1, "", "include_target_direction_validity"], [13, 2, 1, "", "include_target_distance"], [13, 2, 1, "", "include_target_distance_validity"], [13, 2, 1, "", "include_target_speed"], [13, 2, 1, "", "include_velocity"], [13, 3, 1, "", "init_policy"], [13, 3, 1, "", "is_stopped"], [13, 2, 1, "", "is_stuck"], [13, 2, 1, "", "kinematics"], [13, 3, 1, "", "load"], [13, 3, 1, "", "make_type"], [13, 2, 1, "", "max_acceleration"], [13, 2, 1, "", "max_angular_acceleration"], [13, 2, 1, "", "max_angular_speed"], [13, 2, 1, "", "max_speed"], [13, 2, 1, "", "modulations"], [13, 2, 1, "", "optimal_angular_speed"], [13, 2, 1, "", "optimal_speed"], [13, 2, 1, "", "orientation"], [13, 2, 1, "", "path_look_ahead"], [13, 2, 1, "", "path_tau"], [13, 2, 1, "", "policy_path"], [13, 2, 1, "", "pose"], [13, 2, 1, "", "position"], [13, 2, 1, "", "properties"], [13, 2, 1, "", "radius"], [13, 3, 1, "", "register_schema"], [13, 3, 1, "", "remove_modulation"], [13, 2, 1, "", "rotation_tau"], [13, 2, 1, "", "safety_margin"], [13, 3, 1, "", "schema"], [13, 3, 1, "", "set"], [13, 3, 1, "", "set_state_from"], [13, 3, 1, "", "set_velocity"], [13, 2, 1, "", "social_margin"], [13, 2, 1, "", "speed"], [13, 2, 1, "", "target"], [13, 2, 1, "", "target_ref"], [13, 3, 1, "", "to_frame"], [13, 2, 1, "", "twist"], [13, 3, 1, "", "twist_from_wheel_speeds"], [13, 3, 1, "", "twist_towards_velocity"], [13, 2, 1, "", "type"], [13, 2, 1, "", "use_acceleration_action"], [13, 2, 1, "", "use_wheels"], [13, 2, 1, "", "velocity"], [13, 2, 1, "", "wheel_speeds"], [13, 3, 1, "", "wheel_speeds_from_twist"]], "navground.learning.behaviors.PolicyBehavior.Heading": [[13, 2, 1, "", "name"]], "navground.learning.behaviors.pad": [[13, 1, 1, "", "CentralizedPadBehavior"], [13, 1, 1, "", "DistributedPadBehavior"], [13, 1, 1, "", "StopAtPadBehavior"]], "navground.learning.behaviors.pad.DistributedPadBehavior": [[13, 2, 1, "", "pad_width"]], "navground.learning.behaviors.pad.StopAtPadBehavior": [[13, 2, 1, "", "pad_width"], [13, 2, 1, "", "tau"]], "navground.learning.config": [[5, 1, 1, "", "ActionConfig"], [5, 1, 1, "", "BinaryControlActionConfig"], [5, 1, 1, "", "ControlActionConfig"], [5, 1, 1, "", "ControlActionWithCommConfig"], [5, 1, 1, "", "DefaultObservationConfig"], [5, 1, 1, "", "DefaultStateConfig"], [5, 1, 1, "", "DiscreteControlActionConfig"], [5, 1, 1, "", "DiscreteControlActionWithCommConfig"], [5, 1, 1, "", "GroupConfig"], [5, 1, 1, "", "ModulationActionConfig"], [5, 1, 1, "", "ObservationConfig"], [5, 1, 1, "", "StateConfig"], [5, 5, 1, "", "merge_groups_configs"]], "navground.learning.config.ActionConfig": [[5, 3, 1, "", "configure"], [5, 3, 1, "", "get_action"], [5, 3, 1, "", "get_cmd_from_action"], [5, 3, 1, "", "is_configured"], [5, 2, 1, "", "space"]], "navground.learning.config.BinaryControlActionConfig": [[5, 2, 1, "", "space"]], "navground.learning.config.ControlActionConfig": [[5, 2, 1, "", "action_size"], [5, 2, 1, "", "asdict"], [5, 3, 1, "", "configure_kinematics"], [5, 4, 1, "", "fix_orientation"], [5, 3, 1, "", "from_dict"], [5, 4, 1, "", "has_wheels"], [5, 4, 1, "", "max_acceleration"], [5, 4, 1, "", "max_angular_acceleration"], [5, 2, 1, "", "space"], [5, 4, 1, "", "use_acceleration_action"], [5, 4, 1, "", "use_wheels"]], "navground.learning.config.ControlActionWithCommConfig": [[5, 4, 1, "", "comm_size"], [5, 2, 1, "", "comm_space"]], "navground.learning.config.DefaultObservationConfig": [[5, 2, 1, "", "asdict"], [5, 3, 1, "", "configure_kinematics"], [5, 4, 1, "", "flat"], [5, 4, 1, "", "flat_values"], [5, 3, 1, "", "from_dict"], [5, 4, 1, "", "history"], [5, 4, 1, "", "ignore_keys"], [5, 4, 1, "", "include_angular_speed"], [5, 4, 1, "", "include_orientation"], [5, 4, 1, "", "include_position"], [5, 4, 1, "", "include_radius"], [5, 4, 1, "", "include_target_angular_speed"], [5, 4, 1, "", "include_target_direction"], [5, 4, 1, "", "include_target_direction_validity"], [5, 4, 1, "", "include_target_distance"], [5, 4, 1, "", "include_target_distance_validity"], [5, 4, 1, "", "include_target_orientation"], [5, 4, 1, "", "include_target_orientation_validity"], [5, 4, 1, "", "include_target_speed"], [5, 4, 1, "", "include_velocity"], [5, 4, 1, "", "keys"], [5, 4, 1, "", "max_radius"], [5, 4, 1, "", "max_target_distance"], [5, 4, 1, "", "max_x"], [5, 4, 1, "", "max_y"], [5, 4, 1, "", "min_x"], [5, 4, 1, "", "min_y"], [5, 4, 1, "", "normalize"], [5, 4, 1, "", "sort_keys"]], "navground.learning.config.DefaultStateConfig": [[5, 2, 1, "", "asdict"], [5, 3, 1, "", "from_dict"], [5, 4, 1, "", "include_all"], [5, 4, 1, "", "include_angular_speed"], [5, 4, 1, "", "include_orientation"], [5, 4, 1, "", "include_position"], [5, 4, 1, "", "include_radius"], [5, 4, 1, "", "include_target_angular_speed"], [5, 4, 1, "", "include_target_direction"], [5, 4, 1, "", "include_target_direction_validity"], [5, 4, 1, "", "include_target_distance"], [5, 4, 1, "", "include_target_distance_validity"], [5, 4, 1, "", "include_target_orientation"], [5, 4, 1, "", "include_target_orientation_validity"], [5, 4, 1, "", "include_target_speed"], [5, 4, 1, "", "include_velocity"], [5, 4, 1, "", "include_x"], [5, 4, 1, "", "include_y"], [5, 4, 1, "", "max_radius"], [5, 4, 1, "", "max_target_distance"], [5, 4, 1, "", "use_absolute_frame"]], "navground.learning.config.DiscreteControlActionConfig": [[5, 2, 1, "", "space"]], "navground.learning.config.DiscreteControlActionWithCommConfig": [[5, 4, 1, "", "comm_size"], [5, 2, 1, "", "comm_space"], [5, 2, 1, "", "space"]], "navground.learning.config.GroupConfig": [[5, 4, 1, "", "action"], [5, 2, 1, "", "asdict"], [5, 4, 1, "", "color"], [5, 4, 1, "", "deterministic"], [5, 4, 1, "", "failure_condition"], [5, 4, 1, "", "indices"], [5, 4, 1, "", "observation"], [5, 4, 1, "", "policy"], [5, 4, 1, "", "reward"], [5, 4, 1, "", "sensors"], [5, 4, 1, "", "success_condition"], [5, 4, 1, "", "tag"], [5, 4, 1, "", "terminate_on_failure"], [5, 4, 1, "", "terminate_on_success"]], "navground.learning.config.ModulationActionConfig": [[5, 3, 1, "", "from_dict"], [5, 4, 1, "", "params"], [5, 2, 1, "", "space"]], "navground.learning.config.ObservationConfig": [[5, 3, 1, "", "configure"], [5, 2, 1, "", "history"], [5, 3, 1, "", "is_configured"]], "navground.learning.config.StateConfig": [[5, 3, 1, "", "get_space"], [5, 3, 1, "", "get_state"]], "navground.learning.env": [[6, 6, 1, "", "BaseEnv"], [6, 1, 1, "", "NavgroundEnv"]], "navground.learning.env.NavgroundEnv": [[6, 3, 1, "", "action_config"], [6, 2, 1, "", "asdict"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_cmd_from_action"], [6, 2, 1, "", "init_args"], [6, 3, 1, "", "observation_config"], [6, 2, 1, "", "policy"], [6, 3, 1, "", "reset"], [6, 2, 1, "", "scenario"], [6, 3, 1, "", "step"]], "navground.learning.evaluation": [[7, 1, 1, "", "InitPolicyBehavior"], [7, 1, 1, "", "TrajectoryPlotConfig"], [7, 1, 1, "", "VideoConfig"], [7, 5, 1, "", "config_eval_log"], [7, 5, 1, "", "display_episode_video"], [7, 5, 1, "", "display_run_video"], [7, 5, 1, "", "evaluate"], [7, 5, 1, "", "evaluate_policies"], [7, 5, 1, "", "evaluate_policy"], [7, 5, 1, "", "evaluate_with_experiment"], [7, 5, 1, "", "evaluate_with_experiment_and_env"], [7, 5, 1, "", "make_experiment"], [7, 5, 1, "", "make_experiment_with_env"], [7, 5, 1, "", "record_episode_video"], [7, 5, 1, "", "record_run_video"]], "navground.learning.evaluation.InitPolicyBehavior": [[7, 3, 1, "", "with_env"]], "navground.learning.examples": [[8, 0, 0, "-", "corridor_with_obstacle"], [8, 0, 0, "-", "cross"], [8, 0, 0, "-", "pad"]], "navground.learning.examples.corridor_with_obstacle": [[8, 5, 1, "", "get_env"]], "navground.learning.examples.cross": [[8, 5, 1, "", "get_env"]], "navground.learning.examples.pad": [[8, 1, 1, "", "PadReward"], [8, 5, 1, "", "comm"], [8, 5, 1, "", "get_env"], [8, 5, 1, "", "marker"], [8, 5, 1, "", "neighbor"]], "navground.learning.il": [[9, 6, 1, "", "AnyPolicy"], [9, 1, 1, "", "BC"], [9, 1, 1, "", "BaseILAlgorithm"], [9, 1, 1, "", "DAgger"], [9, 6, 1, "", "PolicyCallable"], [9, 6, 1, "", "PolicyCallableWithInfo"], [9, 5, 1, "", "make_vec_from_env"], [9, 5, 1, "", "make_vec_from_penv"], [9, 5, 1, "", "setup_tqdm"]], "navground.learning.il.BC": [[9, 3, 1, "", "collect_runs"]], "navground.learning.il.BaseILAlgorithm": [[9, 2, 1, "", "action_space"], [9, 2, 1, "", "env"], [9, 3, 1, "", "get_env"], [9, 3, 1, "", "learn"], [9, 3, 1, "", "load"], [9, 2, 1, "", "logger"], [9, 2, 1, "", "observation_space"], [9, 2, 1, "", "policy"], [9, 3, 1, "", "save"], [9, 3, 1, "", "set_env"], [9, 3, 1, "", "set_logger"]], "navground.learning.il.rollout": [[9, 5, 1, "", "generate_trajectories"]], "navground.learning.indices": [[11, 1, 1, "", "Indices"], [19, 6, 1, "", "IndicesLike"], [11, 6, 1, "", "T"], [11, 5, 1, "", "join_indices"]], "navground.learning.indices.Indices": [[11, 3, 1, "", "all"], [11, 3, 1, "", "as_set"], [11, 2, 1, "", "asdict"], [11, 3, 1, "", "from_dict"], [11, 3, 1, "", "intersect"], [11, 2, 1, "", "lowest"], [11, 3, 1, "", "sub_dict"], [11, 3, 1, "", "sub_sequence"]], "navground.learning.io": [[12, 5, 1, "", "export_behavior"], [12, 5, 1, "", "export_policy_as_behavior"], [12, 5, 1, "", "load_behavior"], [12, 5, 1, "", "load_env"], [12, 5, 1, "", "save_env"]], "navground.learning.onnx": [[14, 1, 1, "", "OnnxPolicy"], [14, 5, 1, "", "export"]], "navground.learning.onnx.OnnxPolicy": [[14, 2, 1, "", "action_space"], [14, 2, 1, "", "observation_space"], [14, 3, 1, "", "predict"]], "navground.learning.parallel_env": [[15, 6, 1, "", "BaseParallelEnv"], [15, 1, 1, "", "JointEnv"], [15, 1, 1, "", "MultiAgentNavgroundEnv"], [15, 5, 1, "", "make_shared_parallel_env_with_env"], [15, 5, 1, "", "make_vec_from_penv"], [15, 5, 1, "", "parallel_env"], [15, 5, 1, "", "shared_parallel_env"]], "navground.learning.parallel_env.MultiAgentNavgroundEnv": [[15, 3, 1, "", "action_config"], [15, 2, 1, "", "asdict"], [15, 3, 1, "", "from_dict"], [15, 3, 1, "", "get_cmd_from_action"], [15, 3, 1, "", "get_policy"], [15, 2, 1, "", "init_args"], [15, 3, 1, "", "observation_config"], [15, 3, 1, "", "reset"], [15, 2, 1, "", "scenario"], [15, 3, 1, "", "step"]], "navground.learning.policies": [[16, 6, 1, "", "Reduction"]], "navground.learning.policies.centralized_policy_with_comm": [[16, 1, 1, "", "DistributedCommPolicy"], [16, 1, 1, "", "SACPolicyWithComm"]], "navground.learning.policies.info_predictor": [[16, 1, 1, "", "InfoPolicy"]], "navground.learning.policies.null_policy": [[16, 1, 1, "", "NullPolicy"]], "navground.learning.policies.null_predictor": [[16, 1, 1, "", "NullPredictor"]], "navground.learning.policies.order_invariant": [[16, 1, 1, "", "OrderInvariantCombinedExtractor"], [16, 1, 1, "", "OrderInvariantFlattenExtractor"], [16, 5, 1, "", "make_order_invariant_flatten_extractor"]], "navground.learning.policies.random_policy": [[16, 1, 1, "", "RandomPolicy"]], "navground.learning.policies.random_predictor": [[16, 1, 1, "", "RandomPredictor"]], "navground.learning.policies.split_sac_policy": [[16, 6, 1, "", "ActorSpec"], [16, 1, 1, "", "AlternateActorCallback"], [16, 6, 1, "", "InputSpec"], [16, 6, 1, "", "NetArch"], [16, 1, 1, "", "SplitSACPolicy"]], "navground.learning.probes": [[13, 1, 1, "", "CommProbe"], [13, 1, 1, "", "GymProbe"], [13, 1, 1, "", "RewardProbe"], [13, 1, 1, "", "SuccessProbe"]], "navground.learning.probes.CommProbe": [[13, 4, 1, "", "dtype"]], "navground.learning.probes.GymProbe": [[13, 3, 1, "", "with_env"]], "navground.learning.probes.RewardProbe": [[13, 4, 1, "", "dtype"], [13, 3, 1, "", "with_reward"]], "navground.learning.probes.SuccessProbe": [[13, 4, 1, "", "dtype"], [13, 3, 1, "", "with_indices"]], "navground.learning.register": [[17, 1, 1, "", "Registrable"]], "navground.learning.register.Registrable": [[17, 3, 1, "", "_get_dict"], [17, 3, 1, "", "_make_from_dict"], [17, 2, 1, "", "asdict"], [17, 3, 1, "", "from_dict"]], "navground.learning.rewards": [[18, 1, 1, "", "EfficacyReward"], [18, 1, 1, "", "FixedReward"], [18, 1, 1, "", "NullReward"], [18, 1, 1, "", "SocialReward"]], "navground.learning.scenarios": [[13, 1, 1, "", "CorridorWithObstacle"], [13, 1, 1, "", "ForwardScenario"], [13, 1, 1, "", "PadScenario"]], "navground.learning.scenarios.CorridorWithObstacle": [[13, 3, 1, "", "init_world"], [13, 2, 1, "", "length"], [13, 2, 1, "", "max_radius"], [13, 2, 1, "", "min_radius"], [13, 2, 1, "", "width"]], "navground.learning.scenarios.ForwardScenario": [[13, 3, 1, "", "init_world"]], "navground.learning.scenarios.pad": [[13, 5, 1, "", "render_kwargs"]], "navground.learning.state_estimations": [[13, 1, 1, "", "CommSensor"]], "navground.learning.types": [[19, 6, 1, "", "Action"], [19, 6, 1, "", "AnyPolicyPredictor"], [19, 6, 1, "", "Array"], [19, 6, 1, "", "Bounds"], [19, 6, 1, "", "EpisodeStart"], [19, 6, 1, "", "Info"], [19, 6, 1, "", "Observation"], [19, 6, 1, "", "ObservationTransform"], [19, 6, 1, "", "PathLike"], [19, 1, 1, "", "PolicyPredictor"], [19, 1, 1, "", "PolicyPredictorWithInfo"], [19, 6, 1, "", "PyTorchObs"], [19, 1, 1, "", "PyTorchPolicy"], [19, 1, 1, "", "Reward"], [19, 6, 1, "", "SensorLike"], [19, 6, 1, "", "SensorSequenceLike"], [19, 6, 1, "", "State"], [19, 6, 1, "", "TerminationCondition"], [19, 5, 1, "", "accept_info"]], "navground.learning.types.PolicyPredictor": [[19, 3, 1, "", "predict"]], "navground.learning.types.PolicyPredictorWithInfo": [[19, 3, 1, "", "predict"]], "navground.learning.types.PyTorchPolicy": [[19, 3, 1, "", "__call__"], [19, 3, 1, "", "forward"]], "navground.learning.types.Reward": [[19, 3, 1, "", "__call__"]], "navground.learning.utils": [[20, 0, 0, "-", "benchmarl"], [20, 0, 0, "-", "plot"], [20, 0, 0, "-", "sb3"]], "navground.learning.utils.benchmarl": [[20, 1, 1, "", "AlternateActorCallback"], [20, 1, 1, "", "ExportPolicyCallback"], [20, 1, 1, "", "NavgroundExperiment"], [20, 1, 1, "", "SingleAgentPolicy"], [20, 5, 1, "", "evaluate_policy"], [20, 5, 1, "", "make_env"]], "navground.learning.utils.benchmarl.NavgroundExperiment": [[20, 3, 1, "", "action_space"], [20, 3, 1, "", "evaluate_policy"], [20, 3, 1, "", "export_policies"], [20, 3, 1, "", "export_policy"], [20, 3, 1, "", "get_indices"], [20, 3, 1, "", "get_single_agent_policies"], [20, 3, 1, "", "get_single_agent_policy"], [20, 3, 1, "", "load_log"], [20, 3, 1, "", "load_policies"], [20, 3, 1, "", "load_policy"], [20, 2, 1, "", "log_directory"], [20, 3, 1, "", "observation_space"], [20, 3, 1, "", "plot_eval_logs"], [20, 3, 1, "", "reload_from_file"], [20, 3, 1, "", "run_for"]], "navground.learning.utils.plot": [[20, 1, 1, "", "LogField"], [20, 5, 1, "", "plot_logs"], [20, 5, 1, "", "plot_policy"]], "navground.learning.utils.sb3": [[20, 1, 1, "", "ExportOnnxCallback"], [20, 1, 1, "", "ProgressBarWithRewardCallback"], [20, 1, 1, "", "VideoCallback"], [20, 5, 1, "", "load_eval_logs"], [20, 5, 1, "", "plot_eval_logs"]], "navground.learning.wrappers": [[21, 1, 1, "", "MaskWrapper"], [21, 1, 1, "", "NameWrapper"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "property", "Python property"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "type", "Python type alias"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:property", "3": "py:method", "4": "py:attribute", "5": "py:function", "6": "py:type"}, "terms": {"": [4, 5, 6, 8, 13, 16, 18, 19, 20, 23, 24, 27, 28, 31, 32, 33, 35, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "0": [4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66, 67], "00": [23, 24, 27, 28, 33, 35, 36, 39, 41, 42, 43, 52], "000": [28, 35], "000000": 24, "0000000e": [23, 24], "000116": 48, "0039401": 23, "007": 32, "00738173": [23, 24], "00999999978": 60, "01": [4, 13, 32, 35, 36], "01181411743164": 41, "01894906": [23, 24], "0199999996": 23, "02": [22, 23, 27, 28, 33, 34, 65, 66, 67], "023": 66, "03": [36, 65], "0316518565019": 52, "034": [24, 65, 66], "03458167280833": 52, "0378687": 23, "04": [27, 28, 33], "040": 66, "041": 32, "04168": 39, "04322448": 24, "044": 33, "045": 66, "04596518": 24, "05": [28, 29, 33, 34, 52], "054": 33, "056": 66, "0569957": 24, "059": 24, "06": [13, 32, 52, 65], "062": 65, "064": 32, "07": [40, 41, 42, 45, 46, 52, 55, 57, 61], "07210597448923": 41, "077": 33, "078": 66, "08": [23, 24, 28, 29, 33, 52], "084282": 53, "08487248": 24, "0939999968": 23, "094": [22, 23, 28, 29, 33, 34, 65, 66, 67], "095158": 46, "097": 65, "097995": 24, "0989": 25, "0f": [27, 32, 33], "0x1336b32f0": 66, "0x16aa292a0": 9, "0x177bb5400": 62, "0x32d0c4530": 35, "0x32d549370": 35, "0x331d2a780": 62, "0x33bb29b20": 40, "0x372f5d4c0": 32, "0x37a6eb290": 32, "1": [4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66, 67], "10": [3, 7, 8, 13, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66, 67], "100": [4, 7, 23, 24, 25, 30, 31, 32, 33, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 65, 66], "1000": [4, 23, 24, 27, 28, 32, 33, 35, 36, 39, 40, 47], "10000": [4, 27, 36], "100000": [24, 46, 53, 55, 56], "100000001": [23, 24], "10000000149011612": 23, "1003": 25, "1007616": [45, 54], "100_000": [33, 46, 53, 55, 56], "101": [7, 20, 22, 32, 33, 39, 40, 42, 45], "101070028": 4, "1024": [45, 54], "1025013": 24, "10392849743498": 52, "104": 41, "105": 61, "105096": 35, "108": 52, "10_000": [4, 27], "11": [22, 23, 24, 27, 28, 31, 32, 33, 35, 36, 39, 40, 41, 43, 45, 47, 52, 53, 54, 55, 56, 57, 61, 62, 65], "110": [7, 42], "114": 54, "114324592916077": 62, "115": 45, "11797": 53, "11926": 39, "119999997": [23, 24], "11999999731779099": 23, "11_54_30": 52, "12": [3, 7, 22, 23, 24, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 47, 52, 54, 61, 62, 65, 66, 67], "120": [36, 65, 66], "1200": [22, 65, 66], "12000": 36, "120000": 24, "122": 46, "12227725982666": 52, "123": [27, 30, 52], "125": 33, "12508": 39, "126": 39, "128": [27, 32, 33, 65, 66], "12_02_37": 52, "12_13_25": 52, "12_23_48": 52, "13": [3, 23, 24, 27, 28, 31, 32, 33, 35, 36, 39, 43, 44, 45, 52, 56, 61, 62, 65], "130": 36, "131": 52, "135": 66, "136": 66, "13928985595703": 42, "14": [23, 24, 27, 28, 32, 35, 36, 39, 40, 41, 43, 44, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 65], "14000": 36, "141": 55, "142": 36, "145": 39, "149": 52, "15": [23, 24, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 42, 43, 44, 45, 46, 48, 52, 53, 57, 61, 62], "150_000": 27, "1511286": 24, "151734483397266": 52, "15306982": [23, 24], "157": 27, "158": [28, 36], "159": 36, "15960643500521": 47, "15963947": 40, "15_59_07": 41, "16": [16, 23, 24, 27, 28, 32, 33, 35, 36, 39, 40, 41, 42, 44, 46, 48, 52, 61], "16000": 36, "162161301618": 42, "163": [36, 41], "166": [8, 32, 54, 56, 57], "167": [53, 57], "1683": 25, "169": [28, 33], "16_09_02": 41, "16_09_42": 43, "16_28_14": 44, "16_30_29": 43, "16_46_34": 42, "17": [23, 24, 27, 28, 31, 32, 33, 35, 36, 39, 41, 42, 43, 45, 46, 47, 48, 52, 61, 66], "170": [28, 31], "1702": 25, "172": [36, 39], "1723": 25, "174": 36, "1776": 25, "179": 36, "18": [23, 24, 27, 28, 31, 32, 33, 35, 36, 39, 42, 43, 46, 48, 52, 61, 62], "180": 31, "1800": 30, "18000": 36, "1825": 25, "183": 57, "185": 53, "18549144": 24, "186": 27, "188": 39, "189": 45, "18_28_41": 42, "19": [22, 23, 24, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 44, 46, 48, 52, 61], "190": 32, "1902": 25, "194": [33, 36], "19581495": 35, "199": 36, "1_000": 35, "1_000_000": [45, 54, 66], "1e": [13, 27, 32, 33, 43, 48], "1h": 66, "2": [4, 5, 7, 8, 11, 13, 16, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66, 67], "20": [4, 8, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 43, 44, 45, 48, 52, 53, 57, 61, 66], "200": [7, 27, 28, 32, 36, 39, 41, 42, 43, 44, 45, 46, 48, 52, 53, 54, 55, 56, 57, 61, 62], "2000": [32, 33, 36, 39], "20000": [35, 36], "200000": 57, "200_000": 57, "200k": 27, "202": 7, "2021": 4, "20250520_155144": 36, "20250521_083306": 61, "20250521_083912": 61, "20250521_084713": 61, "20250521_085449": 62, "20250521_100129": 40, "20250521_105409": 56, "20250521_124055": 53, "20250521_130546": 57, "20250521_131201": 55, "20250521_131506": 54, "20250521_140207": 46, "20250521_141550": 46, "20250521_144105": 46, "20250521_150232": 48, "20250521_152203": 48, "20250521_152224": 45, "20250521_152323": 47, "2041": 25, "2048": [61, 62], "2053": 25, "2060": 25, "207028388977051": 43, "2083": 25, "2088": 25, "209": 46, "2095": 25, "20_000": [35, 47, 48], "20k": 32, "21": [23, 24, 27, 28, 32, 33, 35, 36, 39, 41, 42, 43, 46, 47, 48, 52, 56, 61, 62], "211": 65, "21168919": 24, "2181036": 24, "22": [23, 24, 27, 28, 31, 32, 33, 35, 36, 39, 41, 42, 43, 44, 46, 47, 52, 56, 61], "22000": 36, "224": 33, "225": 32, "227": 32, "228": [31, 32], "23": [23, 24, 27, 28, 31, 32, 33, 35, 36, 41, 42, 43, 44, 46, 47, 48, 52, 56, 61], "232": 31, "234": 31, "23716867": 24, "2372903": 24, "24": [23, 24, 27, 32, 33, 35, 41, 43, 44, 47, 48, 56, 61, 62], "24000": 36, "246": 32, "25": [22, 23, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 46, 47, 48, 52, 53, 56, 57, 60, 61, 62, 65, 66], "250": 32, "252": 24, "255": [16, 23, 30, 31], "256": [16, 27, 32, 33, 43, 48], "25k": 36, "26": [23, 24, 27, 30, 35, 41, 42, 43, 46, 47, 48, 52, 61, 66], "260": 23, "26000": 36, "266": 23, "268704": 57, "27": [23, 24, 27, 35, 36, 42, 43, 46, 47, 52, 61, 62], "27712064847142": 61, "27864": 55, "28": [23, 24, 27, 30, 32, 35, 36, 42, 44, 46, 52, 62], "28000": 36, "281": 32, "2831855": 24, "28543382920021": 41, "29": [23, 24, 27, 30, 33, 43, 52, 62], "29011178": 24, "293": 33, "2935146": 24, "29579": 57, "297": 23, "2_000": [36, 61], "2d": 24, "2f": [27, 28, 31, 32, 33, 35, 36, 40], "2wdiff": [22, 23, 28, 29, 33, 34, 35, 36, 65, 66, 67], "3": [3, 7, 11, 16, 20, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "30": [7, 23, 24, 27, 28, 30, 31, 33, 36, 41, 42, 43, 44, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "300": [7, 23, 28, 30, 31, 33, 35, 36], "3000": 35, "30000": 36, "300000": 46, "300_000": [46, 61], "301056": 61, "305": 7, "3065185546875": 52, "30817246": [23, 24], "30k": 32, "31": [23, 24, 27, 41, 42, 43, 44, 46, 52, 62, 65], "310": 31, "313": 7, "32": [9, 16, 23, 27, 36, 43, 47, 62, 65], "32000": 36, "324": 39, "328231702248257": 43, "32967997": [23, 24], "33": [23, 27, 36, 46, 62], "335": 31, "3351982": 24, "33800991": 47, "34": [22, 23, 36, 39, 41, 42, 44, 46, 52, 62], "34000": 36, "342201232910156": 44, "343908": 56, "347": 33, "3484901": [23, 24], "35": [23, 33, 42, 46, 62], "35280955": 24, "354489778550846": 40, "36": [23, 27, 28, 46, 62], "360": [28, 35], "36000": 36, "366667": 24, "37": [23, 27, 35, 39, 44, 46, 62], "375972": 24, "38": [23, 46, 52, 62], "38000": 36, "384": 27, "38925827": [23, 24], "39": [23, 24, 25, 27, 28, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "3_000_000": 65, "3d": 4, "3e": [41, 42, 43, 44, 48, 52], "3f": [23, 24, 65, 66], "4": [7, 11, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "40": [8, 23, 24, 27, 28, 36, 43, 44, 46, 52], "400": [22, 23, 30, 40, 47, 65, 66], "4000": 36, "40000": [36, 61], "400k": [32, 33], "4013637": 24, "40_000": [36, 61], "40k": 32, "41": [23, 52], "415": 32, "42": [23, 27, 32, 52, 62], "425860404968262": 43, "42879337": 24, "43": [23, 30, 36, 43], "43155256": 24, "4343923": 24, "44": [23, 27, 44, 52, 62], "44292223": 24, "44533634": 24, "44618": 39, "447618566666655": 62, "45": [23, 35], "454994": 24, "46": [35, 36, 39], "46368217": [23, 24], "466118": 46, "46954215": 24, "47": [36, 39, 52], "4769401550293": 52, "4778133": [23, 24], "48": [30, 32], "48566": 45, "4887372": 24, "49": 35, "494501651731493": 43, "49761885007222": 52, "499": 33, "5": [4, 7, 11, 13, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66, 67], "50": [27, 30, 31, 41, 42], "500": [27, 45, 46, 48, 53, 55, 56, 57], "50000": [27, 40, 47], "500000": 48, "50013": 52, "500_000": [48, 62], "5088892": [23, 24], "50_000": 40, "50k": 33, "51": [31, 36], "51274070806373": 42, "517": 28, "52": [36, 42, 48], "5299": 25, "53": 39, "5318": 25, "53239": 39, "5325": 25, "53362036148707": 52, "5348": 25, "54": [27, 36, 52, 54], "54047640000001": 62, "541203": 48, "55": [35, 36, 40, 52], "553191": 24, "5531914234161377": 23, "5547919": 24, "56": [35, 36], "56125": 39, "56168243333333": 61, "56305325": 24, "565": 27, "5689087": 24, "57": [35, 36], "5725663e": [23, 24], "58": [36, 39], "58046": 39, "59": 35, "591048258543015": 43, "59525": 54, "59714": 46, "599": 23, "5e": 48, "5m": 65, "5x": 27, "6": [7, 11, 13, 22, 23, 24, 25, 27, 28, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 48, 52, 53, 54, 55, 57, 60, 61, 62, 65, 66], "60": [22, 23, 24, 30, 31, 33, 36, 65], "600": [4, 23, 24, 30, 31, 32, 33], "6000": [36, 41, 42, 43, 44, 52], "60000": 27, "600000024": 60, "60380": 39, "61": 52, "61308354": 24, "614": 32, "6155738": 35, "618880409527502": 61, "62": 52, "62414": 46, "62434775": [23, 24], "63": [33, 36, 39], "6368": 25, "6379": 25, "6386": 25, "64": [16, 36], "640": 23, "641": 32, "642": 27, "643845558166504": 52, "65": [32, 33, 36, 39], "65664": 39, "66": [28, 39, 43, 48], "662088394165039": 52, "663": 32, "6635826": 24, "6674728": [23, 24], "67": 36, "674": 27, "67737": 52, "68": [35, 39, 46], "684062957763672": 42, "6844907": 24, "69": 46, "695": 35, "69993": 54, "7": [7, 22, 23, 24, 25, 27, 28, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 48, 52, 53, 54, 55, 57, 61, 62, 65, 66], "70": [36, 42, 46, 52], "700k": 66, "7053": 25, "7081": 25, "71": [27, 28, 36, 39, 42, 46, 52], "7113": 25, "712881": 24, "71470490296682": 52, "72": [22, 46], "722": 46, "72873973549812": 52, "73": 46, "73132": 46, "74": [36, 39, 41, 55], "75": [27, 35, 39], "750": 23, "750_000": 32, "75968134": 35, "76": [39, 52], "76000": 39, "7619184": 24, "7693684": 24, "77": [27, 36, 39, 46, 52], "78": [41, 52], "781858468055725": 52, "79": 52, "7965191": 35, "7968806942304": 41, "8": [16, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 65, 66], "80": [39, 52], "8000": 36, "8002": 23, "8097478": 24, "81": [39, 46, 61], "81250881777759": 62, "81776": 39, "8187": 25, "82": [36, 46, 52], "8212": 25, "82219696044922": 41, "8253108": 24, "83": [36, 46, 52], "83333396911621": 28, "84": [27, 36, 42, 52], "843858": 56, "85": 52, "85238175789515": 42, "86": [42, 52], "863906": 24, "87": [36, 52], "88285": 48, "883285865221644": 52, "88571418921153": 42, "89": [36, 52], "8984411": 24, "9": [22, 23, 24, 27, 28, 31, 32, 35, 36, 40, 42, 43, 45, 47, 48, 52, 53, 54, 55, 57, 61, 62, 65, 66], "90": [7, 30, 31, 36], "900": 31, "900_000": 61, "90241": 55, "903168": 61, "91": [36, 52], "911902901256326": 61, "92": 36, "92672473333332": 61, "93338553905487": 52, "936": 32, "94": [27, 36, 47], "94150": 39, "943050052673952": 43, "944": 39, "95": [27, 28], "95323870290115": 52, "96": [35, 39], "9602": 25, "9612": 25, "964": 23, "97": 36, "98": 27, "980400666666664": 61, "98083089987437": 41, "982": 23, "98785": 48, "99094602": 23, "99785438": 23, "A": [5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 26, 28, 32, 38, 50, 60], "As": [4, 22, 23, 31, 32, 35, 36, 52, 53, 55, 57, 58, 59, 66], "At": 4, "By": [4, 60], "For": [4, 5, 7, 11, 16, 22, 23, 24, 32, 33, 34, 35, 47, 60], "If": [3, 4, 5, 6, 7, 9, 12, 13, 14, 15, 16, 17, 18, 20, 24, 33, 47], "In": [0, 4, 9, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67], "It": [4, 6, 7, 9, 14, 15, 18, 24, 27, 31, 32, 33, 35, 36, 52], "Its": 66, "Not": 13, "On": 0, "One": [4, 23, 30, 34, 38, 64], "That": 16, "The": [0, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 28, 30, 31, 32, 33, 35, 37, 38, 39, 40, 43, 46, 47, 48, 56, 60, 61, 62, 63, 64, 65, 66], "Their": 60, "Then": [6, 15, 35, 38], "There": [0, 4, 23], "These": 64, "To": [4, 13, 23, 24, 27, 35, 43, 46, 50], "_": [4, 20, 23, 27, 28, 30, 31, 35, 36, 40, 42, 45], "__call__": [10, 19, 65], "__class__": 35, "__init__": 65, "__name__": [30, 31, 32, 35], "_close": 39, "_comm": 5, "_get_dict": [5, 10, 17], "_make_from_dict": [5, 10, 17], "_navground": 13, "_navground_sim": 7, "_prepar": [35, 39], "a_env": 23, "ab": 65, "abc": [5, 7, 19], "abil": 13, "abl": [5, 6, 11, 15, 16, 17, 31], "about": [23, 27, 28, 30, 31, 32, 33, 36, 39, 47, 50, 53, 60, 64, 65, 66], "abov": [4, 13, 20, 23, 28, 31, 32, 60], "absolut": [5, 13, 36], "abstract": [5, 19], "acc": [28, 42, 45], "acceler": [5, 8, 13, 24, 28, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], "acceleret": 47, "accept": [7, 9, 19, 23], "accept_info": [10, 19], "accord": 35, "accordingli": 8, "achiev": 65, "acknowledg": 2, "act": [4, 24, 40, 42, 45], "action": [0, 4, 6, 8, 9, 10, 13, 14, 15, 16, 19, 20, 21, 23, 24, 27, 28, 32, 33, 35, 36, 40, 44, 46, 47, 49, 50, 51, 53, 55, 56, 57, 58, 59, 63, 64, 65, 66], "action_config": [4, 6, 10, 13, 15, 22, 23, 24, 27, 28, 33, 35, 36, 65, 66], "action_discret": [52, 62], "action_indic": 21, "action_listen": 44, "action_mb": 62, "action_s": [5, 16], "action_spac": [9, 14, 16, 20, 23, 24, 32, 35, 36, 40, 44, 45, 47, 52, 54, 61, 62], "action_speak": 44, "actionconfig": [0, 4, 5, 6, 15], "actionnet": [16, 47], "activ": [16, 31], "activation_class": 43, "activation_fn": 16, "activation_kwarg": 43, "actor": 16, "actor_spec": [16, 48], "actorspec": [10, 16], "actual": [23, 28], "actuat": [4, 5, 6, 13, 15, 23, 35], "actuated_twist": 13, "actuated_wheel_spe": 13, "ad": [5, 6, 7, 9, 13, 15, 46], "adam": 16, "add": [0, 3, 5, 7, 9, 13, 16, 17, 18, 23, 27, 32, 36, 50, 65], "add_init": [7, 31], "add_modul": [13, 65], "add_prob": 28, "add_record_prob": [13, 22, 31, 39, 45, 46, 47, 48], "add_safety_to_agent_margin": 23, "addit": [5, 7, 16, 23, 35], "adjust": 13, "advanc": 13, "advantag": 46, "aec": 4, "after": [4, 6, 13, 15, 16, 23, 24, 28, 35, 36], "again": 23, "agent": [2, 5, 7, 8, 10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 34, 35, 36, 37, 38, 39, 40, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67], "agent_0": 21, "agent_1": 21, "agent_dim": 43, "agent_index": [6, 13], "agent_kwarg": [27, 28, 36], "agent_margin": [22, 23, 33, 34, 65, 66, 67], "aggreg": [15, 20], "aggregar": 24, "aggress": 30, "agreement": 4, "ahead": 13, "ai": 4, "aim": 66, "albeit": 47, "algo": [30, 31], "algorithm": [4, 9, 20, 27, 32, 33, 34, 36, 38, 41, 42, 43, 44, 49, 52, 58, 59, 61, 62, 64, 65, 66], "algorithm_config": [4, 20, 41, 42, 43, 44, 52], "algorithmconfig": 20, "alia": 13, "aliv": 4, "all": [3, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 19, 20, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 47, 48, 65, 66, 67], "all_reward": [23, 24], "allow": [15, 36, 50], "almost": [28, 30, 31, 32, 39], "along": [8, 13, 28, 29, 35, 52, 60, 64], "alpha": [18, 22, 23, 24, 27, 28, 30, 31, 35, 65, 66], "alreadi": [5, 13, 16, 23, 31, 32, 33, 35, 43, 46, 50, 65], "also": [4, 5, 7, 8, 13, 14, 23, 24, 25, 27, 29, 33, 35, 36, 39, 50, 52, 65, 66], "alt_cb": 43, "altern": [16, 20, 22, 35, 49, 51], "alternateactorcallback": [10, 16, 20, 43, 48], "although": [31, 33], "althought": 30, "altmodel": 43, "altough": 32, "alwai": [16, 18, 24, 28, 31, 32, 60, 63, 64], "among": [4, 24, 30, 31, 34, 38], "an": [4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 27, 28, 31, 33, 36, 37, 38, 47, 52, 57, 62, 65], "analys": 32, "analysi": [30, 31], "andd": 14, "angl": 35, "angular": [5, 13, 23, 28, 35, 36, 65], "angular_spe": [5, 13, 35, 65], "angular_toler": 36, "ani": [4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 19, 20, 22, 24, 25, 31, 35, 36], "anoth": [5, 11, 13, 31, 33, 67], "another_world": 7, "anymor": 13, "anyof": 13, "anypolici": [9, 10], "anypolicypredictor": [5, 7, 10, 13, 19, 20], "anyth": [19, 53], "anywai": 28, "apart": 65, "api": [4, 9, 13, 23, 24, 32], "append": [21, 23, 24, 30, 31, 35, 48], "appli": [4, 5, 6, 7, 9, 13, 15, 16, 23, 27, 30, 31, 32, 60, 63], "ar": [0, 3, 4, 5, 7, 8, 9, 11, 13, 15, 16, 20, 21, 23, 24, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 46, 47, 50, 52, 60, 62, 64, 65, 66], "architectur": [16, 27], "area": [6, 8, 15, 60], "arg": [9, 13, 15, 16, 19], "argmin": 28, "argument": [6, 7, 8, 9, 15, 16, 17, 19], "aris": 4, "around": [13, 23, 31], "arrai": [5, 10, 19, 21, 23, 24, 31, 32, 35, 42, 45], "as_set": [10, 11], "asarrai": [22, 28, 30, 31, 35, 39, 45, 46, 47, 48, 65, 66], "asdict": [5, 6, 10, 11, 15, 17, 24], "ask": 23, "assertionerror": 16, "assign": [4, 5, 18, 22, 23, 30, 35, 36, 65], "associ": [13, 16, 20], "assum": [13, 16], "assume_cmd_is_actu": 13, "astyp": [23, 45, 46], "atari": 4, "attribut": [5, 9, 36], "audio": [22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "author": 4, "auto": [9, 23], "automat": [23, 36], "autoreload": [40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 61], "autoreset": 23, "avail": [4, 11, 22], "averag": [7, 20, 23, 30, 31, 33, 65, 66], "avoid": [16, 28, 29, 31, 32, 33, 35, 39, 47, 50, 60], "awai": [13, 23], "ax": [20, 23, 28, 30, 31, 35, 40, 42, 45], "ax1": [28, 30, 31], "ax2": [28, 30, 31], "axi": [13, 20, 22, 23, 28, 35, 39, 40, 42, 45, 65, 66], "b": [5, 16, 64], "back": [8, 33], "backbon": 52, "background_extra": 36, "backward": [5, 13], "balanc": 39, "bar": [20, 32, 33], "barrier_angl": [28, 29, 65, 66], "base": [4, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 28, 38, 64], "base_class": [9, 24], "basealgorithm": [9, 12], "basecallback": [16, 20], "baseenv": [6, 7, 8, 10, 12, 13, 15, 20], "basefeaturesextractor": 16, "baseilalgorithm": [7, 9, 10, 12], "baselin": [4, 32], "baseline3": 3, "baselines3": [4, 23, 32], "baseparallelenv": [7, 8, 10, 12, 13, 15, 20], "baseparallelwrapp": 21, "basepolici": [9, 12, 16], "basepolicymixin": 13, "basic": [2, 4, 23, 38], "batch": [14, 16, 20, 47], "batch_siz": [25, 27, 32, 33], "bbox_to_anchor": 27, "bc": [4, 9, 10, 27, 30, 31, 32, 33, 35], "bc_cmd": 35, "bc_efficaci": 35, "bc_feasible_cmd": 35, "bc_kwarg": [9, 27, 32, 33], "bc_reward": 27, "bc_train_kwarg": [27, 32, 33], "becaus": [3, 25, 27, 35, 47, 50, 62, 63], "becom": [23, 32], "been": [4, 13, 23, 31, 35], "befor": [6, 13, 15, 16, 23, 24, 30, 35, 36], "begin": [7, 19, 28, 65], "behavior": [0, 4, 6, 7, 10, 12, 18, 22, 23, 24, 28, 29, 30, 31, 34, 35, 36, 38, 53, 60, 63, 64, 65, 66], "behaviorgroupmemb": 13, "behaviormodul": [13, 65], "behaviors_same_sid": 39, "behind": 4, "being": [7, 35], "belong": [5, 19], "below": [4, 30, 31, 32, 33, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "benchmark": [23, 31], "benchmarl": [3, 10, 25, 41, 42, 43, 44, 50, 58, 64], "best": [20, 36, 38, 46, 48, 52], "best_model": [36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62], "best_model_bin_shar": 46, "best_model_discret": 62, "best_model_float": 46, "best_model_float_shar": 46, "best_model_mb": 62, "best_model_save_path": [40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62], "best_polici": [20, 41, 42, 43, 44, 47, 48, 52], "best_policy_alt": 48, "best_ppo_model": 61, "best_ppo_os_model": 61, "best_sac_model": 61, "beta": [18, 23, 24, 65], "better": [27, 31, 32, 33, 35, 36, 52], "between": [4, 5, 8, 13, 18, 23, 24, 25, 33, 35, 38, 58, 59, 62], "bia": 43, "bin": [27, 28, 30, 31, 65, 66], "binar": [8, 13, 41, 43, 45, 46, 47, 48], "binari": [13, 51, 63], "binarycontrolactionconfig": [5, 62], "bit": [5, 30, 31, 46, 47, 50, 62], "bitwise_or": 24, "black": [22, 30, 31], "black_death": 15, "blind": 57, "block": 31, "blue": [4, 27, 30, 31, 35, 64, 65, 66], "bodi": [5, 28], "bool": [5, 6, 7, 8, 9, 13, 14, 15, 16, 19, 20, 23, 36], "both": [4, 5, 8, 11, 13, 39, 40, 47, 50, 52, 62], "bottom": [19, 28], "bound": [5, 6, 7, 8, 10, 11, 13, 15, 16, 19, 20, 22, 23, 28, 29, 32, 33, 34, 39, 65, 66], "boundari": [6, 7, 13, 15, 28, 29], "boundary_dist": 28, "bounding_box": [35, 36], "box": [5, 14, 16, 20, 23, 24, 32, 35, 40, 44, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61], "brake": [5, 13, 40, 55, 62], "break": 4, "bring": 32, "broadcast": [5, 8, 13, 45, 46, 47, 48, 64], "browser": [22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "bufferdescript": 23, "build": [4, 16], "c": [4, 50], "cach": 13, "call": [4, 5, 6, 13, 14, 15, 17, 23], "callabl": [7, 9, 13, 16, 19, 65], "callback": [7, 16, 20, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "can": [0, 4, 5, 11, 13, 16, 17, 19, 22, 23, 24, 25, 27, 28, 32, 33, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 64], "cannot": [4, 12, 28, 48], "carri": 56, "carrot": 13, "case": [13, 23, 24, 27, 28, 31, 32, 36, 39, 40, 50, 52, 60, 64], "cast": 50, "catch_warn": 23, "categor": 23, "categorical_act": [4, 20], "caus": 50, "cb": [36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62], "cc": [30, 31], "cell": [13, 27, 32], "center": [4, 53, 57], "central": [10, 13, 38, 39, 43, 52, 64], "centralized_policy_with_comm": 47, "centralizedpad": 39, "centralizedpadbehavior": [13, 39], "challeng": 34, "chang": [13, 28, 32, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65], "check": [4, 13, 16, 19, 23, 24, 31, 32, 33, 35, 36, 52, 66], "check_if_target_satisfi": [13, 36], "checkpoint": [20, 41, 42, 43, 44, 52], "checkpoint_at_end": [41, 42, 43, 44, 52], "choos": 7, "circular": 13, "citat": 18, "cl": 32, "cl4": 4, "clamp": 13, "class": [4, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 65], "classmethod": [5, 6, 7, 9, 11, 13, 15, 17], "clean": 13, "clear_modul": 13, "clip": [30, 31], "clip_mean": 16, "clone": [4, 10, 13, 29, 35, 38], "clone_behavior": [4, 13, 22], "close": [4, 13, 23], "cm": 28, "cmap": [20, 40], "cmd": 35, "cmd_twist_along_path": 13, "cmd_twist_towards_angular_spe": 13, "cmd_twist_towards_orient": 13, "cmd_twist_towards_point": 13, "cmd_twist_towards_pos": 13, "cmd_twist_towards_stop": 13, "cmd_twist_towards_veloc": 13, "cnn": 16, "cnn_output_dim": 16, "coat": 19, "code": 23, "coher": [23, 24], "col": [27, 30, 31], "collect": [5, 7, 9, 13, 15, 16, 23, 24, 27, 32, 33, 66], "collect_run": [9, 27, 32, 33, 35], "collis": [4, 7, 13, 30, 31, 32, 60], "color": [4, 5, 6, 7, 13, 15, 20, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42, 45, 46, 47, 48, 65, 66], "color_high": [13, 41, 42, 43, 44, 45, 46, 47, 48], "color_low": [13, 41, 42, 43, 44, 45, 46, 47, 48], "colorbar": [28, 40], "column": [7, 27, 28, 36], "com": 3, "combin": [0, 16, 46], "combinedextractor": 16, "come": [25, 67], "comm": [8, 13, 41, 42, 43, 44, 45, 46, 50, 51], "comm_net_arch": [16, 47], "comm_siz": [5, 41, 42, 43, 44, 45, 46, 47, 48], "comm_spac": [5, 16, 47], "command": [0, 4, 5, 6, 13, 15, 24, 28, 35], "commiss": 4, "commnet": [16, 47], "common": [4, 7, 9, 11, 16, 19, 20, 23, 24, 27, 32, 33, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "commprob": [10, 13, 45, 46, 47, 48], "commsensor": [10, 13], "commun": [10, 38, 46, 47, 49, 51, 57, 64], "compar": [23, 24, 27, 30, 31, 32, 33, 35], "comparis": [29, 38], "comparison": [31, 38], "compat": [4, 9, 13, 52], "complet": [5, 6, 15, 32, 52], "complex": [24, 36, 38, 50], "compon": [2, 4, 10, 35], "compos": [4, 5, 13, 16, 23, 24, 25, 39, 62], "compositevideoclip": [30, 31], "compress": 47, "comput": [4, 5, 6, 7, 9, 13, 15, 16, 19, 23, 24, 28, 30, 31, 32, 33, 35, 39, 50, 54, 58, 59, 63, 65], "computation": 13, "compute_cmd": [13, 35], "compute_cmd_intern": 13, "concat_vec_envs_v1": [9, 15, 24], "concaten": [4, 9, 15, 16, 24, 28, 42, 45], "concret": 4, "condit": [5, 6, 13, 15, 19], "config": [4, 5, 7, 8, 13, 20, 27, 28, 32, 33, 41, 42, 43, 44, 45, 46, 47, 48, 52, 54, 62, 65, 66], "config_eval_log": [7, 10], "configur": [2, 4, 6, 7, 9, 10, 13, 15, 16, 20, 22, 24, 25, 27, 32, 33, 35, 36, 40, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "configure_kinemat": 5, "configwithkinemat": 5, "conflict": [39, 60], "conform": [4, 6, 15, 16, 20, 23], "confugur": 35, "consid": [6, 13, 15, 24, 31, 64], "consist": 65, "const": 18, "constant": [6, 13, 15, 28, 29, 63, 65], "constrain": 13, "constraint": 28, "construct": [4, 20, 52], "constructor": [8, 9], "consum": [5, 9, 13], "contain": [4, 5, 11, 16, 19, 23, 24, 35, 52, 61], "content": [5, 17], "context": 13, "contin": [54, 63, 64], "continu": [30, 31, 46, 49, 50, 52, 54], "continuo": [58, 61, 62], "contrari": [65, 66], "control": [4, 5, 6, 8, 13, 15, 23, 24, 28, 32, 33, 35, 36, 39, 62], "control_action_with_comm": [41, 43, 44, 46, 47, 48], "control_period": [22, 23, 28, 29, 33, 34, 35, 36, 65, 66, 67], "controlactionconfig": [4, 5, 6, 8, 13, 15, 22, 23, 24, 27, 28, 33, 35, 36, 40, 44, 47, 52, 53, 55, 56, 57, 61, 62, 65, 66], "controlactionwithcommconfig": [5, 41, 43, 44, 46, 47, 48], "conveni": [13, 15], "convent": 14, "converg": 52, "convers": [5, 11], "convert": [4, 5, 6, 13, 15, 16, 17, 19, 25, 26, 38], "converto": [26, 38], "cooper": 31, "coordin": [5, 39, 46, 57, 64], "copi": [7, 9, 11, 13, 31], "core": [4, 5, 13, 18, 22, 28, 31, 35, 36, 39, 40, 53, 54, 55, 56, 57, 60, 61, 62, 65], "correspond": [13, 16, 18, 19], "corridor": [2, 10, 13, 27, 28, 38, 52, 60, 64], "corridorwithobstacl": [10, 28, 29], "cost": 33, "could": [4, 12, 23, 30, 32, 35], "cover": [11, 23, 31], "covert": [11, 24], "cpu": [4, 25], "creat": [4, 8, 9, 13, 15, 16, 20, 25, 32, 33, 36, 37, 38], "criteria": [6, 9, 15], "criterion": 36, "critic": [18, 20, 58], "critic_model_config": [20, 43, 44], "critical_safety_margin": [18, 23, 24], "cross": [2, 10, 22, 23, 33, 38, 39, 59, 60, 66], "crosstoru": [65, 66, 67], "csv": [20, 27, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "cum_reward": 23, "cumul": [7, 20, 23], "current": [5, 13, 20, 27, 32, 33, 39], "custom": [4, 9], "cyan": [45, 46, 47, 48, 63], "cycl": [4, 23], "d": [13, 30, 31], "d_": [27, 32, 33, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "dagger": [4, 10, 29, 30, 31, 38], "dagger_kwarg": 9, "dagger_reward": 27, "darkviolet": 30, "dash": [30, 31, 32], "data": [5, 7, 9, 13, 20, 22, 23, 30, 31, 36], "dataclass": [5, 65], "dataclassconfig": 5, "datafram": [20, 27, 30, 31, 32, 33, 35, 36, 39, 65, 66], "dataset": [9, 13, 28], "datetim": [27, 32, 33, 35, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "dc": [5, 65], "deadlock": 13, "decent": [27, 31], "decentr": 52, "decis": 4, "decod": 50, "decompos": 5, "decor": 65, "decreas": [30, 31], "deeper": 33, "def": [23, 27, 30, 31, 35, 36, 42, 65], "default": [6, 7, 9, 10, 13, 15, 16, 17, 18, 23, 24, 60], "default_rng": 33, "default_social_margin": [18, 23, 24], "defaultobservationconfig": [4, 5, 6, 13, 15, 22, 23, 24, 27, 28, 33, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "defaultstateconfig": [5, 24, 41, 42, 43, 44, 52], "defer": 5, "defin": [0, 5, 13, 17, 19, 23, 24, 27, 29, 32, 36, 37, 38, 64], "degrad": 31, "degre": 5, "deleg": 13, "delta": 13, "demand": [6, 15], "denot": 13, "densiti": [22, 27, 28, 30, 31, 39, 65, 66], "depend": [5, 7, 13, 16, 48], "descreas": 65, "describ": [4, 5, 6, 15, 16, 19, 35], "descript": 23, "description_of_the_return_valu": 9, "design": [4, 7, 32], "desir": [4, 13, 39], "desired_veloc": 13, "desired_velocity_towards_point": 13, "desired_velocity_towards_veloc": 13, "detect": [8, 29], "determin": 13, "determinist": [4, 5, 7, 9, 13, 14, 19, 20, 23, 35, 40, 42, 45], "deterministic_polici": 9, "dev": [7, 20, 22, 28, 32, 33, 35, 36, 65, 66], "develop": 3, "deviat": 7, "devic": [4, 25], "df": [27, 32, 33, 35, 36, 39, 65, 66], "dict": [4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 30, 31, 32, 33, 35, 40, 44, 46, 47, 48, 53, 54, 55, 56, 57, 61], "dict_spac": 16, "dictionari": [4, 5, 6, 9, 11, 13, 15, 16, 17, 19, 23, 32], "dictionart": 11, "did": 59, "differ": [0, 3, 4, 7, 13, 16, 19, 23, 24, 25, 27, 30, 31, 32, 33, 34, 38, 47, 50, 58, 59, 62, 64, 67], "different_speed_env": 65, "different_speed_reward": 65, "differentspe": 65, "differnet": 24, "difficult": [57, 64], "dimens": [5, 16, 64], "dimension": 60, "dir": 35, "direcli": [32, 35], "direclti": 23, "direct": [5, 13, 23, 28, 37, 38, 66], "directionalcomm": 44, "directli": [4, 22, 32, 41, 42, 47, 50, 52], "directori": [9, 12, 20, 27], "directoru": 20, "disabl": [9, 16], "disable_logg": 23, "disc": [22, 23, 24, 28, 29, 33, 34, 65, 66, 67], "disclaim": 2, "discontinu": 4, "discret": [49, 50, 58, 63, 64], "discrete_control_act": 52, "discrete_control_action_with_comm": [42, 45], "discretecontrolactionconfig": [5, 52, 54, 62], "discretecontrolactionwithcommconfig": [5, 42, 45], "discsstateestim": 8, "discuss": [23, 28], "displai": [5, 6, 7, 13, 15, 20, 22, 23, 27, 30, 31, 32, 33, 36, 37, 38, 39, 65, 66], "display_episode_video": [7, 10, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "display_in_notebook": [28, 30, 31, 60], "display_run_video": [7, 10], "display_shap": 65, "display_video": [22, 23, 28, 33, 35, 39, 60, 65, 66], "display_video_from_run": [30, 36, 65, 66], "display_width": [22, 23, 28, 30, 33, 35, 36, 65, 66], "distanc": [4, 5, 13, 28, 66], "distance_to_enter_pad": 13, "distibuit": 52, "distinguish": 19, "distribut": [4, 16, 22, 28, 30, 31, 38, 39, 51, 52, 54, 55, 56, 57, 59, 64, 65, 66], "distributedblind": 53, "distributedcommbinarywithrewardshar": 46, "distributedcommcentraltrain": 47, "distributedcommdiscret": 45, "distributedcommdiscretewithrewardshar": 42, "distributedcommfloatwithoutrewardshar": 46, "distributedcommfloatwithrewardshar": [41, 43, 46, 48], "distributedcommpolici": [10, 16, 47], "distributeddiscret": [52, 54], "distributedpadbehavior": [13, 39], "distributedposit": 55, "distributedspe": 57, "divers": 4, "divid": 7, "dlr": 4, "do": [3, 4, 5, 9, 22, 28, 32, 38, 47, 50, 53], "doc": 4, "document": 0, "doe": [5, 13, 23, 28, 32, 35, 39, 46, 48, 50, 62, 63], "doesn": [22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "dof": [5, 23, 24], "don": [23, 32, 52, 66], "done": [13, 23, 24, 32, 50], "dot": [30, 31, 32], "dot_radiu": [27, 28], "down": 57, "draw_target": 36, "dropna": 32, "dry": [6, 15], "dt": [27, 32, 33, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "dtype": [5, 6, 8, 13, 15, 16, 23, 24, 25, 28, 30, 31, 35, 40, 42, 45, 47], "dummi": [16, 18, 31, 35, 36, 38, 39, 52, 53, 57, 60, 62, 64], "dummy_polici": 36, "dummy_reward": 36, "dummy_reward_std_dev": 36, "dummybehavior": 31, "dummycontinu": 61, "dummydiscret": 62, "dummymultibinari": 62, "dummyvecenv": 36, "dump": [5, 6, 13, 15, 60], "durat": [6, 7, 8, 15, 22, 23, 27, 28, 30, 31, 32, 33, 35, 36, 39, 60, 65, 66], "dure": [5, 13, 16, 27, 28, 31, 32, 33, 36, 45, 46, 47, 48, 50, 62], "dynam": [14, 15, 20], "dynamic_batch_s": [14, 20], "e": [4, 5, 13, 16, 19, 20, 21, 22, 23, 24, 28, 31, 32, 33, 36, 39, 47, 50, 59, 65, 66], "each": [0, 5, 7, 16, 20, 23, 24, 25, 27, 28, 31, 32, 33, 35, 39, 47, 50, 53, 64], "earlier": 35, "easi": 39, "easier": 31, "easy_prob": 39, "edg": 60, "effect": [5, 47, 60], "efficaci": [7, 8, 10, 13, 30, 35, 39, 50, 57, 65], "efficacyreward": [8, 10, 18, 35], "effici": [30, 39], "effort": 31, "ego": [4, 5, 28], "ego_": 23, "ego_angular_spe": 28, "ego_target_direct": [23, 24, 25, 28], "ego_target_dist": [23, 24], "ego_veloc": [28, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "either": [5, 35, 47, 50], "element": [7, 23], "elif": 22, "els": [7, 8, 9, 11, 13, 20, 22, 30, 31, 35, 42, 45, 47], "elsewis": [53, 57], "emb": [4, 22], "emit": 20, "empti": [2, 5, 6, 7, 13, 15, 17, 20, 29, 35, 38], "en": 32, "enabl": [7, 14], "encod": [5, 47, 50], "end": [4, 10, 13], "enforc": 13, "enforce_feas": 13, "enlarg": 28, "enough": [13, 27, 32, 33, 36, 40, 60], "ent_weight": [27, 32, 33], "enter": [8, 13, 47], "entir": 23, "entri": 5, "enumer": [23, 27, 30, 31, 35, 39, 40, 42, 45, 46, 47, 48], "env": [4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 20, 21, 23, 25, 26, 27, 28, 31, 32, 33, 35, 36, 38, 41, 42, 43, 44, 52], "env1": 23, "env2": 24, "env3": 24, "env4": 24, "env_id": 9, "env_kwarg": [23, 27, 35], "env_make_kwarg": 9, "env_stat": 24, "env_util": [23, 27, 35], "envbas": 20, "enviro": [9, 23, 24, 32, 36, 37, 38], "enviromen": 32, "environ": [0, 2, 3, 5, 7, 9, 10, 12, 13, 16, 19, 20, 21, 25, 26, 27, 29, 34, 38, 47, 50, 52, 59, 62, 67], "environen": 32, "environment_st": 13, "environn": 24, "ep_rew_mean": [27, 32, 33, 65, 66], "episod": [6, 7, 8, 14, 15, 19, 20, 23, 31, 33, 35, 36, 65, 66], "episode_count": 23, "episode_mean_reward": 23, "episode_start": [14, 19, 23], "episode_trigg": 23, "episodestart": [9, 10, 14, 19, 23], "epoch": 27, "epsilon_angular_spe": [13, 36], "epsilon_spe": [13, 36], "equal": [18, 22, 28, 62], "equival": 32, "error": 13, "especiali": 27, "estim": [4, 10, 33], "estimate_time_until_target_satisfi": 13, "eta": [22, 23, 28, 29, 33, 34, 65, 66], "eu": 4, "european": 4, "eval": [20, 27, 35, 36], "eval_act": 47, "eval_df": 27, "eval_env": [20, 41, 42, 43, 44, 47, 52], "eval_freq": [36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62], "eval_sensor": 47, "evalu": [2, 5, 10, 11, 13, 14, 16, 19, 20, 27, 28, 30, 31, 32, 33, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 58, 59, 61, 62, 65, 66], "evaluate_polici": [4, 7, 10, 20, 27, 32, 33, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "evaluate_with_experi": [7, 10], "evaluate_with_experiment_and_env": [7, 10, 27, 28], "evaluation_episod": [41, 42, 43, 44, 52], "evaluation_interv": [41, 42, 43, 44, 52], "evalut": [36, 41, 42, 52], "evalutate_polici": 36, "evalute_polici": 35, "even": [23, 24, 27, 28, 30, 31, 33, 39, 40, 64], "event": 28, "everi": [5, 6, 7, 15, 20], "everyth": [4, 39], "eviron": [24, 31], "evolv": [4, 50], "exampl": [2, 4, 7, 10, 11, 13, 16, 30, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "excess": 65, "exchag": 47, "exchang": [46, 47, 48, 50], "exclus": [2, 8, 16, 20, 38, 48], "excus": 28, "execut": [4, 27], "exist": 13, "exist_ok": [41, 42, 43, 44, 52], "exit": [6, 7, 13, 15, 16, 39], "exp": [27, 28, 30, 31, 36, 39, 45, 46, 47, 48, 62, 65, 66], "expect": [4, 16, 20, 23, 31, 32, 33, 35, 52, 53, 57], "expens": [13, 32], "experi": [4, 10, 13, 20, 28, 31, 35, 36, 39, 41, 42, 43, 44, 45, 46, 47, 48, 52, 62], "experiment_mappo": [41, 42, 52], "experiment_mappo_o": 52, "experiment_masac": [41, 42, 43, 44, 52], "experiment_masac_alt": 43, "experiment_masac_discret": 52, "experiment_masac_st": 52, "experimentalrun": [13, 22], "experimentconfig": [4, 20, 41, 42, 43, 44, 52], "expert": [9, 27, 32, 33, 35, 36], "expert_cmd": 35, "expert_efficaci": 35, "expert_reward_mean": 35, "expert_reward_std_dev": 35, "expir": 36, "explain": [23, 32], "explicit": 64, "explicitli": [16, 23, 47, 50, 64], "explictli": 23, "explod": 16, "explor": [29, 55], "export": [4, 10, 12, 20, 22, 23, 24, 30, 31, 36, 37, 38, 47, 52], "export_al": 20, "export_behavior": [10, 12], "export_polici": 20, "export_policy_as_behavior": [4, 10, 12, 35, 36], "export_to_onnx": [36, 40, 45, 46, 48, 53, 54, 55, 56, 57, 61, 62], "exportonnxcallback": [10, 20], "exportpolicycallback": [10, 20, 41, 42, 43, 44, 52], "expos": [5, 8, 9, 14, 15, 20, 23, 24, 32], "express": 4, "extend": [1, 2, 4, 7, 9], "extens": [4, 43, 46], "extract": [0, 4, 11, 16, 23], "extractor": 10, "f": [4, 22, 23, 24, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "fact": [4, 28, 38], "factor": [6, 7, 15, 22, 23, 28, 30, 31, 33, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "factori": [5, 7, 13, 18], "fail": [5, 13, 27], "failur": [5, 6, 13, 15, 19], "failure_condit": [5, 6, 15, 44], "fair": 31, "fals": [4, 5, 6, 7, 8, 9, 13, 15, 16, 19, 20, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "famili": 4, "familiar": 29, "far": [30, 31], "farama": 4, "faster": [32, 35], "fastest": 13, "favor": [18, 40], "feasibl": [13, 35], "feasible_angular_spe": 13, "feasible_spe": 13, "feasible_twist": 13, "feasible_twist_from_curr": 13, "featur": [4, 16], "features_extractor_class": 16, "features_extractor_kwarg": 16, "fed": 16, "fenc": [6, 15], "few": 28, "fewer": 13, "field": [5, 6, 13, 15, 16, 17, 20, 23, 24, 25], "fig": [23, 27, 28, 30, 31, 35, 36, 40, 42, 45], "figsiz": [22, 23, 27, 28, 30, 31, 32, 33, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 65, 66], "figur": [22, 27, 28, 45, 46, 48, 53, 57, 65, 66], "figure_format": [27, 28, 32, 33, 65, 66], "file": [4, 7, 12, 13, 20, 23, 24, 35, 36], "filenam": 23, "filesystem": 19, "fill": [36, 65], "filter": 35, "filter_kei": 16, "filter_slic": 16, "filterwarn": [23, 25, 27, 28, 32, 33, 35, 36, 41, 42, 43, 44, 52, 65, 66], "final": [6, 15, 28, 33, 34, 36, 38], "fine": 35, "finish": [13, 23], "firebrick": [27, 28, 29], "first": [4, 5, 9, 13, 16, 24, 25, 28, 29, 33, 36, 38, 39, 40, 47, 62, 66, 67], "first_0": 25, "first_1": 25, "first_2": 25, "first_3": 25, "first_4": 25, "first_5": 25, "first_6": 25, "first_7": 25, "first_8": 25, "first_9": 25, "first_group": 24, "fist": [53, 57], "five": 4, "fix": [5, 10, 13, 20, 27, 32, 41, 43, 44, 46, 47, 48, 52, 54, 55, 56, 57, 60, 61, 62], "fix_orient": [5, 13, 23, 24, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "fixedreward": [10, 18], "flag": [27, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "flat": [5, 8, 13, 16, 23, 24, 27, 28, 33, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "flat_valu": [5, 23, 24, 52], "flatten": [5, 16, 22, 28, 30, 31, 65, 66], "float": [5, 6, 7, 8, 13, 15, 16, 18, 19, 20, 23, 47, 48, 50, 51, 65], "float32": [13, 16, 23, 24, 25, 28, 32, 35, 40, 42, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61], "float64": [13, 19, 28], "focu": 24, "folder": 20, "folder_nam": [41, 42, 43, 44, 52], "follow": [4, 13, 23, 24, 27, 30, 32, 34, 37, 38, 50, 58, 60, 64], "forc": 5, "fork": 3, "form": [4, 50], "format": 7, "forth": [8, 33], "forward": [5, 10, 19, 39, 53, 57, 63], "forwardscenario": 13, "found": 13, "foundat": 4, "four": 67, "fov": [24, 25], "fp": [7, 30, 31], "frac": 13, "fraction": 31, "frame": [5, 13, 24, 28, 36], "freedom": 5, "from": [0, 3, 4, 5, 6, 7, 9, 11, 13, 14, 15, 16, 17, 19, 20, 22, 23, 25, 26, 27, 28, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67], "from_dict": [5, 6, 10, 11, 15, 17], "fromarrai": 23, "full": [13, 28, 30, 31, 32, 36, 39, 40, 42, 45, 53, 57, 63], "fun": [23, 30], "func": [19, 20], "function": [0, 2, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 19, 23, 27, 32, 39, 47], "functool": 31, "fund": 4, "further": 50, "g": [4, 5, 13, 19, 21, 23, 24, 28], "game": 4, "gamma": 65, "gap": 28, "gather": 23, "gener": [4, 5, 6, 9, 11, 13, 15, 19, 23, 24, 31, 36, 46], "generallu": 60, "generate_trajectori": [9, 10], "gentrajterminationfn": 9, "get": [4, 5, 6, 9, 11, 13, 15, 19, 20, 23, 29, 31, 33, 37], "get_act": 5, "get_actuated_twist": 13, "get_cmd": 35, "get_cmd_from_act": [5, 6, 10, 15, 24], "get_dir": [27, 32, 33, 36, 65, 66], "get_env": [8, 9, 10, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "get_feasible_cmd": 35, "get_from_yaml": [4, 41, 42, 43, 44, 52], "get_groups_reward": [30, 31], "get_imag": 23, "get_indic": 20, "get_polici": [10, 15, 65, 66], "get_property_type_nam": 13, "get_record": [28, 30, 31, 65, 66], "get_single_agent_polici": [4, 20, 44, 52], "get_spac": 5, "get_stat": 5, "get_target_angular_direct": 13, "get_target_angular_dist": 13, "get_target_angular_spe": [13, 65], "get_target_angular_veloc": 13, "get_target_direct": 13, "get_target_dist": 13, "get_target_orient": 13, "get_target_pos": [13, 36], "get_target_posit": 13, "get_target_spe": [13, 65], "get_target_twist": 13, "get_target_veloc": 13, "get_tim": 65, "get_twist": 13, "get_veloc": 13, "getmtim": [40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "git": 3, "github": 3, "give": 39, "given": [6, 12, 13, 15], "glob": [40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "global": [5, 8, 15, 24, 25, 58], "go": [23, 24, 27, 31, 32, 33, 36, 64], "goal": [23, 38, 64], "goe": 28, "gold": [45, 46, 47, 48], "goldenrod": 36, "good": [27, 28, 36, 61], "gotopos": 36, "grai": [22, 23, 33, 34], "grant": 4, "granular": 50, "graph": 7, "greedi": 31, "green": [4, 27, 30, 31, 35, 42, 45, 46, 65, 66], "grei": [31, 36], "group": [4, 7, 10, 13, 15, 16, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 44, 65, 66, 67], "group_map": 25, "groupbi": [30, 31], "groupconfig": [5, 7, 10, 13, 15, 20, 24, 27, 28, 30, 31, 44, 65], "groupedpolicybehavior": 10, "groups_config": 31, "grp_1_ep_1": 7, "grp_1_ep_2": 7, "grp_2_ep_1": 7, "grp_2_ep_2": 7, "gt": [28, 32, 35, 40, 62, 66], "guarante": 13, "guid": [0, 2], "guzzi": 22, "gym": [4, 5, 6, 9, 14, 16, 20, 23, 27, 28, 33, 35, 36, 47], "gymanasium": 4, "gymansium": [23, 26, 38], "gymenv": 4, "gymnasium": [0, 2, 5, 8, 10, 22, 26, 27, 28, 32, 33, 35, 36, 38, 47], "gymprob": [10, 13, 28], "h": [4, 27, 30, 31, 32, 33, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "ha": [4, 5, 6, 9, 13, 15, 16, 18, 19, 23, 24, 28, 30, 31, 35, 50], "half": [13, 32, 53, 57], "handl": 19, "happen": [28, 32, 35, 46], "has_stat": 4, "has_target": 13, "has_typ": 13, "has_wheel": [5, 23, 24], "hasproperti": 13, "have": [4, 13, 14, 15, 18, 22, 23, 24, 27, 28, 30, 31, 32, 33, 35, 36, 40, 47, 50, 52, 61, 66, 67], "head": 13, "heading_behavior": 13, "height": [20, 23, 31, 41, 43, 44, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "held": 4, "helper": [4, 16, 17, 27, 30, 32], "here": [19, 31, 38, 39], "heterogen": 4, "hexbin": 28, "hidden": 19, "hide_ax": [7, 36], "hierarchicallogg": 9, "high": [5, 13, 20, 23, 41, 42, 43, 45, 46, 47, 48], "higher": [13, 30, 31, 32], "hist": [22, 27, 28, 30, 31, 39, 65, 66], "histogram": [30, 31], "histori": [5, 13, 23, 24], "histtyp": 39, "hl": [22, 23, 24, 28, 29, 30, 31, 32, 33, 34, 38, 65, 66], "hl_group": [30, 31], "hl_mean": 31, "hl_r": 31, "hl_reward": [27, 30, 31, 65, 66], "hl_std": 31, "hline": 32, "hold": 4, "homogen": 15, "horizon": [4, 13, 22, 23, 28, 29, 33, 34, 65, 66], "horizont": [8, 13, 52, 61], "hour": 33, "how": [1, 2, 4, 5, 9, 13, 22, 23, 33, 36, 38, 47, 66], "howev": 4, "hparam": 7, "html5": [22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "http": [3, 32], "human": [4, 6, 15, 23, 34, 38], "hyper": 38, "i": [3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 50, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66], "i1": 28, "i2": 28, "id": [6, 18], "ideal": 13, "ident": 47, "identifi": [4, 5], "idl": [6, 15], "idsia": 3, "ignor": [5, 13, 14, 23, 25, 27, 28, 32, 33, 35, 36, 39, 41, 42, 43, 44, 52, 60, 65, 66], "ignore_kei": [5, 6, 13, 15, 23, 24, 57], "ignore_toler": [13, 36], "il": [4, 9, 27, 30, 31, 32, 33, 35], "im": [23, 40], "imag": [4, 16, 19, 23], "image_for_world": [6, 15], "imageclip": [30, 31], "img": [30, 31], "imit": [0, 2, 10, 13, 29, 31, 32, 33, 38], "immers": 31, "impact": [5, 30, 31, 32, 33, 52], "implement": [4, 9, 13, 14, 17, 52], "implicitli": 50, "implicli": 23, "import": [3, 4, 6, 7, 15, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "imshow": [23, 40], "in_box": [27, 28, 36], "in_featur": 43, "includ": [0, 4, 5, 6, 8, 13, 15, 16, 19, 20, 24, 25, 36, 64, 65, 66], "include_act": [6, 15, 23], "include_al": 5, "include_angular_spe": [5, 13, 23, 24, 27, 28, 33, 36, 65, 66], "include_i": [5, 23, 24, 41, 42, 43, 44, 52], "include_orient": 5, "include_posit": [5, 24, 41, 42, 43, 44, 52], "include_radiu": [5, 13, 23, 24], "include_success": [6, 8, 15, 23, 41, 42, 43, 44, 52], "include_target_angular_spe": [5, 13, 23, 24], "include_target_direct": [5, 13, 22, 23, 24, 27, 28, 33, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "include_target_direction_valid": [5, 13, 23, 24], "include_target_dist": [5, 13, 22, 23, 24, 33, 36], "include_target_distance_valid": [5, 13, 23, 24], "include_target_orient": [5, 23, 24, 36], "include_target_orientation_valid": [5, 23, 24], "include_target_spe": [5, 13, 23, 24, 65], "include_valid": [23, 24, 28, 29], "include_veloc": [5, 13, 23, 24, 27, 28, 33, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "include_x": [5, 23, 24], "increas": [22, 30, 53, 57], "increasingli": 38, "incur": [28, 60], "inde": 62, "independ": 16, "index": [2, 4, 6, 11, 12, 15, 20, 24, 32, 33, 65, 66], "indic": [5, 7, 10, 13, 15, 16, 19, 20, 21, 23, 24, 25, 30, 31, 33, 40, 44], "indiceslik": [7, 10, 11, 13, 15, 19], "individu": [6, 15, 19, 20, 23, 24, 65, 67], "inf": [5, 13, 23, 24, 60], "infer": [7, 10, 16, 23, 31, 35, 39, 46, 47, 50], "inferencesess": 14, "info": [4, 6, 9, 10, 15, 19, 23, 24, 35], "info_predictor": 9, "infopolici": [6, 9, 10, 15, 16], "inform": [4, 5, 16, 19, 23, 35, 36, 47, 50, 56, 64], "inherit": [5, 23], "init": [9, 13], "init_arg": [6, 10, 15], "init_polici": [13, 65], "init_speed_modul": 65, "init_success": [6, 8, 15, 23, 36, 41, 42, 43, 44, 52], "init_world": [13, 28, 66], "initi": [4, 5, 6, 7, 8, 11, 13, 15, 16, 17, 27, 28, 33, 36, 52, 65], "initpolicybehavior": [7, 10, 30, 65], "initvar": 5, "inlinebackend": [27, 28, 32, 33, 65, 66], "input": [4, 13, 14, 16, 19, 28, 29, 40, 50, 52], "input_spec": 16, "inputspec": [10, 16], "insid": [4, 8, 23, 35], "inspect": [53, 56, 57], "inspir": 18, "instabl": [4, 64], "instal": [2, 32, 33], "instanc": [4, 5, 6, 15, 17, 22, 23, 24], "instanti": 4, "instead": [4, 5, 7, 13, 16, 22, 24, 32, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63], "int": [4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21, 28, 30, 31, 45, 46, 65], "int8": [13, 46], "integ": [4, 11, 32], "integr": [2, 13, 23, 24, 25, 38], "interact": 4, "interest": [29, 31, 64], "interestingli": [30, 31], "interfac": [4, 7, 9, 20], "intermedi": [6, 8, 15], "intermediate_success": [6, 8, 15, 23, 41, 42, 43, 44, 52], "intern": [0, 7, 13, 17, 47], "interpret": [5, 6, 15], "intersect": [5, 10, 11], "interv": 5, "introduc": 36, "introduct": [2, 32], "intuit": 31, "invari": 10, "io": [4, 12, 23, 24, 25, 28, 30, 31, 32, 33, 35, 36, 65, 66], "ipython": 23, "is_configur": 5, "is_failur": [13, 39, 44], "is_shar": 25, "is_stop": [13, 36], "is_stuck": 13, "is_success": [6, 13, 15, 36, 39, 44], "is_wheel": 13, "item": [4, 5, 6, 11, 15, 16, 24, 30, 31, 42], "iter": [4, 11, 20, 21, 41, 42, 43, 44, 52], "its": [4, 5, 6, 13, 15, 17, 23, 28, 32, 35, 36, 39, 46, 55, 56, 57, 63], "j": [30, 31], "jam": [13, 31], "jeguzzi": 3, "jenv": 24, "jerom": 22, "job": 23, "join_indic": [10, 11], "joint": [47, 52], "jointenv": [10, 15, 16, 24, 40, 47], "json": [5, 6, 11, 13, 15], "jupyt": [23, 27, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "just": [4, 5, 8, 9, 13, 20, 23, 24, 28, 31, 32, 35, 36, 61, 63, 66], "k": [20, 22, 32, 42], "keep": [4, 5, 7, 13, 21, 30, 31, 32, 52, 62], "kei": [4, 5, 6, 11, 13, 15, 16, 20, 21, 23, 24, 32, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "kept": 65, "keyword": [7, 8, 15], "kind": 36, "kinemat": [4, 5, 13, 22, 23, 28, 29, 33, 34, 35, 36, 65, 66, 67], "know": [39, 53, 63, 64], "known": [5, 64], "kwarg": [7, 8, 9, 13, 15, 16, 19, 20, 27, 35, 41, 42, 43, 45, 46, 47, 48], "kwargs_bin": 46, "l": 35, "l2_weight": [27, 32, 33], "label": [20, 22, 27, 28, 30, 31, 35, 39, 42, 45, 46, 47, 48, 65, 66], "lambda": [23, 27, 30, 31, 36, 65], "languag": 23, "larg": [4, 27, 52], "larger": [5, 6, 13, 15, 31], "last": [13, 19, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "later": [5, 23, 28, 33, 35, 39, 60], "latest": 3, "layer": [16, 27, 32, 33], "layer_class": 43, "layout": 16, "lead": [13, 30, 31, 32, 60], "learn": [0, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67], "learning_r": [16, 20, 43, 48], "learnt": [46, 47, 53, 56, 57], "least": [5, 13, 28, 46], "leav": 32, "led": 13, "left": [19, 28], "leftward": [53, 57], "legend": [22, 27, 30, 31, 35, 39, 42, 45, 46, 47, 48, 65, 66], "len": [23, 24, 28, 36, 39], "lenght_high": 20, "lenght_low": 20, "length": [5, 7, 11, 13, 20, 23, 28, 29, 36, 39, 60], "length_ep_1": 7, "length_ep_2": 7, "length_high": [20, 36], "length_low": 20, "length_queu": 23, "less": [13, 27, 30, 31, 32, 33, 56], "let": [5, 22, 23, 24, 27, 28, 30, 31, 32, 33, 35, 36, 40, 46, 52, 53, 56, 57, 60, 62, 65], "level": [20, 23], "lib": 4, "librari": 4, "lidar": [24, 25], "like": [3, 4, 7, 9, 13, 22, 23, 24, 28, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 65, 66, 67], "limit": [13, 46], "linalg": 65, "line": [30, 31, 32], "linear": [18, 23, 28, 35, 36, 40, 43, 58, 59, 61, 63, 65], "linecollect": 32, "linestyl": [20, 32], "link": 4, "linspac": [27, 30, 31, 35, 40, 42, 45, 65, 66], "list": [5, 7, 11, 12, 13, 15, 16, 19, 20, 24, 36], "listen": [44, 50, 64], "liter": [7, 11, 13, 15, 19], "littl": [28, 31], "load": [0, 2, 4, 5, 6, 9, 10, 13, 14, 15, 17, 20, 22, 25, 26, 27, 30, 31, 32, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "load_behavior": [10, 12], "load_env": [10, 12, 23, 24, 25, 30, 31, 32], "load_eval_log": [10, 20, 36], "load_experi": 35, "load_ext": [32, 33, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 61], "load_from_zip_fil": 9, "load_log": 20, "load_plugin": 4, "load_polici": [20, 41, 42, 43, 44, 52], "load_scenario": [6, 7, 15, 22, 23, 24, 27, 28, 33, 35, 36, 39, 65, 66], "load_state_estim": [22, 23, 24, 33, 65, 66], "log": [3, 10, 20, 27, 28, 32, 33, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "log_alt": 48, "log_bin_shar": 46, "log_directori": 20, "log_discret": 62, "log_float": 46, "log_float_shar": 46, "log_graph": 7, "log_interv": [27, 32, 33, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "log_mb": 62, "log_rollouts_n_episod": [27, 32, 33], "log_rollouts_venv": [27, 32, 33], "log_std_init": 16, "logdir": [32, 33], "logfield": [10, 20], "logger": [7, 9, 27, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "logic": 13, "long": 13, "longer": [27, 31, 64], "longitudin": 60, "look": [4, 13, 24, 28, 29, 30, 31, 33, 34, 38, 40, 47, 50, 64, 66, 67], "loop": [23, 24, 28, 35], "loss": [20, 43], "loss_actor": 43, "lot": [30, 31], "low": [5, 13, 20, 23, 36, 41, 42, 43, 44, 45, 46, 47, 48], "lower": [5, 8, 13, 18, 20, 30, 31, 35, 53, 57, 65, 66], "lowest": [10, 11, 28], "lr": [41, 42, 43, 44, 52], "lr_schedul": 16, "lt": [28, 32, 35, 40, 41, 42, 43, 44, 52, 62, 66], "lx": 40, "ly": 40, "m": [27, 28, 32, 33, 36, 39, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "ma_env": [30, 31], "machin": [4, 24], "mai": [4, 5, 13, 24, 28, 35, 46, 60], "main": [0, 3, 7], "maintain": [9, 31], "major": 28, "make": [4, 6, 7, 20, 23, 27, 28, 30, 31, 33, 34, 35, 36, 39, 40, 46, 63, 65], "make_env": [4, 10, 20, 25], "make_experi": [7, 10], "make_experiment_with_env": [7, 10, 27, 30, 31, 36, 45, 46, 47, 48, 62, 65, 66], "make_order_invariant_flatten_extractor": [10, 16], "make_shared_parallel_env_with_env": [10, 15, 24, 31, 32], "make_typ": 13, "make_vec": 23, "make_vec_env": [9, 23, 27, 35], "make_vec_from_env": [9, 10, 33], "make_vec_from_penv": [4, 9, 10, 15, 32, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 65, 66], "make_video": [30, 31], "make_video_from_run": [30, 31], "make_world": [4, 7, 22, 23, 33, 35, 39, 60, 65], "makedir": [41, 42, 43, 44, 52], "manag": 28, "mani": [4, 9, 24, 34, 38], "manual": [4, 23], "map": [5, 6, 9, 11, 15, 17, 23, 24, 35, 39, 47], "mappo": [49, 58], "mappo_navground_mlp__21107964_25_05_21": 41, "mappo_navground_mlp__47240504_25_05_21": 42, "mappo_navground_mlp__e7616175_25_05_21": 52, "mappoconfig": [41, 42, 52], "margin": [13, 18, 23, 28], "mark": 19, "marker": [8, 32, 33, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "markerstateestim": 8, "markov": 4, "markovvectorenv": 9, "marl": [4, 49], "masac": [44, 49, 58], "masac_exp": 4, "masac_navground_mlp__1e615e81_25_05_21": 41, "masac_navground_mlp__2399ac94_25_05_21": 52, "masac_navground_mlp__3694a5f2_25_05_21": 52, "masac_navground_mlp__60c5e310_25_05_21": 42, "masac_navground_mlp__dcf869d3_25_05_21": 52, "masac_navground_mlp__f924c091_25_05_21": 44, "masac_navground_splitmlp__013da278_25_05_21": 43, "masac_navground_splitmlp__44bff93e_25_05_21": 43, "masacconfig": [4, 41, 42, 43, 44, 52], "mask": [16, 19, 21], "maskwrapp": [10, 21], "master": 32, "math": 36, "matplotlib": [22, 23, 27, 28, 30, 31, 32, 33, 35, 39, 40, 42, 44, 45, 46, 47, 48, 62, 65, 66], "max": [5, 27, 28, 30, 31, 32, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "max_acceler": [5, 13, 23, 24, 27, 28, 33, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "max_angular_acceler": [5, 13, 23, 24, 27, 28, 33, 36, 65, 66], "max_angular_spe": [5, 13, 23, 24, 35], "max_backward_spe": 36, "max_dur": [6, 8, 15, 23, 24, 27, 28, 33, 35, 36, 44, 65, 66], "max_episode_step": [4, 23], "max_forward_spe": 36, "max_i": [5, 28, 29, 35, 36], "max_id": [23, 24], "max_n_it": [41, 42, 43, 44, 52], "max_numb": 5, "max_number_of_ag": 15, "max_number_of_obstacl": 13, "max_obstacle_radiu": 13, "max_radiu": [5, 13, 22, 23, 24, 28, 29, 33, 34, 65, 66, 67], "max_rang": [24, 25], "max_spe": [5, 8, 13, 22, 23, 24, 28, 29, 33, 34, 35, 36, 55, 61, 62, 65, 66, 67], "max_step": 25, "max_target_dist": [5, 23, 24], "max_x": [5, 8, 35, 36], "maxim": [5, 6, 8, 11, 13, 15, 18, 23, 35, 65], "maximum": [5, 8, 13], "mdp": 4, "mean": [7, 20, 23, 24, 27, 28, 30, 31, 32, 33, 35, 36, 39, 41, 42, 43, 44, 52, 65, 66], "mean_ep_length": 36, "mean_reward": 36, "measur": [28, 30, 31, 33, 39], "median": [27, 28], "meet": [38, 64], "merg": 7, "merge_groups_config": [5, 7, 10], "meshgrid": 40, "messag": [5, 8, 13, 16, 41, 43, 44, 45, 47, 48, 49, 50, 51, 64], "messsag": 50, "met": [6, 15, 33], "metadata": [6, 15, 23], "meter": 36, "method": [5, 13, 17, 20], "metric": 4, "microsecond": 35, "mid": [13, 53, 56, 57], "middl": [8, 23, 33], "mimic": 7, "min": [13, 27, 28, 35], "min_i": [5, 28, 29, 35, 36], "min_number_of_obstacl": 13, "min_obstacle_radiu": 13, "min_radiu": [13, 28, 29], "min_x": [5, 8, 35, 36], "minim": [5, 13, 28, 37, 64], "minimum": 13, "mix": [5, 32], "ml": [2, 5, 13, 23, 26, 31, 32, 38, 64], "mlp": [4, 10, 27, 42, 44, 49, 50, 51, 52], "mlpconfig": [4, 41, 42, 43, 44, 52], "mlppolici": [4, 27, 32, 33, 35, 65, 66], "mlps_spec": 43, "modal": 50, "mode": [6, 8, 15, 59], "model": [4, 7, 9, 12, 13, 14, 16, 19, 20, 27, 29, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 64, 65, 66], "model1": 7, "model2": 7, "model3": 7, "model_alt": 48, "model_bin_shar": 46, "model_config": [4, 20, 41, 42, 43, 44, 52], "model_discret": 62, "model_float": 46, "model_float_shar": 46, "model_mb": 62, "modelconfig": 20, "modifi": [9, 13, 22], "modul": [2, 10, 13, 16, 20, 50, 57, 65], "modulationactionconfig": [4, 5], "monitor": [15, 40, 47, 61, 62], "monitor_keyword": 15, "monolith": 16, "more": [4, 5, 8, 13, 15, 20, 24, 27, 28, 29, 30, 32, 33, 34, 36, 38, 50, 60], "moreov": [4, 13], "most": [23, 24, 28], "motion": [13, 64], "move": [5, 13, 18, 23, 24, 28, 30, 31, 32, 33, 35, 36, 39, 53, 56, 57, 60, 63, 67], "moviepi": [30, 31], "mp4": [7, 20, 23, 40, 44, 53, 54, 55, 56, 57, 60, 61, 62], "mpy": [30, 31], "much": [13, 30, 31, 32, 55, 56], "multi": [2, 7, 8, 10, 16, 23, 24, 32, 33, 34, 38, 52, 59, 63, 64], "multi_ag": [8, 61, 62], "multiagentmlp": 43, "multiagentnavgroundenv": [4, 10, 12, 15, 20], "multibinari": [5, 62], "multiinputpolici": [36, 40, 45, 46, 53, 54, 55, 56, 57, 61, 62], "multipl": [4, 13, 15, 24, 32], "multipli": [5, 13], "multiprocess": 7, "must": [6, 19, 32, 64], "my": 22, "my_polici": 4, "my_torchrl_polici": 4, "myenviro": 4, "mymultiagentenviro": 4, "mypolici": 19, "myscenario": 4, "n": [4, 5, 23, 24, 30, 31, 35], "n_agent": 43, "n_critic": 16, "n_env": [23, 27], "n_epoch": [4, 27, 32, 33, 35], "n_eval_episod": [7, 20, 27, 28, 32, 33, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "n_step": [45, 54, 61, 62], "naground": 22, "name": [0, 5, 8, 13, 17, 19, 20, 23, 24, 25, 28, 29, 30, 31, 32, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "name_prefix": 23, "name_wrapp": 4, "namedtupl": 20, "namespac": [8, 13], "namewrapp": [4, 10, 21], "natev": 25, "navground": [2, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 64, 65, 66], "navground_act": [6, 15, 23, 24], "navground_learn": [3, 22], "navgroundbaseenv": [6, 15], "navgroundenv": [4, 6, 10, 12, 15, 23], "navgroundexperi": [4, 10, 20, 41, 42, 43, 44, 52], "navgroundtaskclass": 20, "navig": [4, 9, 13, 18, 23, 27, 29, 32, 33, 34, 35, 37, 38, 39, 47, 50, 65, 66, 67], "ncol": [23, 27, 28, 30, 31, 35, 40, 42, 45], "ndarrai": [4, 6, 8, 13, 15, 19], "nearbi": 39, "nearer": 40, "nearest": [13, 23, 28, 35], "necessarili": 4, "need": [4, 5, 15, 23, 63], "neg": 35, "neighbor": [8, 18, 23, 24, 25, 32, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54, 58, 59, 61, 62], "neighbor_weight": [8, 41, 42, 43, 44, 45, 46, 48], "neightbor": 31, "neither": 4, "nest_asyncio": 23, "net": 50, "net_arch": [9, 16, 27, 32, 33, 35, 36, 65, 66], "netarch": [10, 16], "network": [16, 27, 32, 33], "neural": [32, 33], "neuron": [27, 32, 33], "never": 16, "new": [0, 4, 5, 6, 9, 13, 15, 23, 24], "next": [4, 13, 19, 23, 24, 27, 30, 31, 32, 33, 47], "nn": [16, 50], "no_tick": [28, 36], "non": [13, 16, 20], "none": [4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 23, 27, 30, 31, 35, 43, 48, 65], "nonetheless": 32, "nor": 4, "norm": 65, "norm_class": 43, "norm_kwarg": 43, "normal": [5, 13, 16, 19, 23, 24, 35], "normalize_imag": 16, "normalized_imag": 16, "notat": 64, "note": [4, 13, 31, 32, 35, 47, 48, 62], "notebook": [22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67], "notebook_view": 23, "noth": [4, 5, 13], "notna": 27, "now": [4, 22, 24, 27, 31, 32, 33, 35, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "np": [9, 19, 22, 23, 24, 27, 28, 30, 31, 33, 35, 36, 39, 40, 42, 45, 46, 47, 48, 65, 66], "nrow": [30, 31], "null": [10, 13, 23, 24], "nullpolici": [10, 16], "nullpredictor": [10, 16], "nullreward": [10, 18], "num": [30, 31], "num_cel": 43, "num_cpu": 24, "num_env": [9, 15, 23, 24, 32, 33, 45, 46, 48, 53, 54, 55, 56, 57], "num_timestep": [36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61], "number": [4, 5, 6, 7, 9, 13, 15, 16, 19, 20, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 65, 66, 67], "number_of_episod": [30, 31], "number_of_process": [30, 31], "number_of_run": [27, 28, 30, 31, 36, 39, 45, 65, 66], "number_of_video": 36, "numer": 5, "numpi": [4, 13, 19, 22, 23, 24, 27, 28, 30, 31, 33, 35, 36, 39, 40, 42, 45, 46, 47, 48, 65, 66], "o": [19, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 64], "ob": [19, 23, 35, 40, 42, 45], "object": [5, 7, 9, 11, 13, 14, 16, 17, 23], "observ": [0, 4, 6, 7, 8, 9, 10, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66], "observa": 31, "observation_config": [4, 6, 10, 13, 15, 22, 23, 24, 27, 28, 33, 35, 36, 65, 66], "observation_indic": 21, "observation_kei": 21, "observation_spac": [9, 14, 16, 20, 23, 24, 35, 36, 40, 42, 44, 46, 47, 48, 53, 54, 55, 56, 57, 61], "observationconfig": [0, 4, 5, 6, 8, 15], "observationtransform": [7, 10, 13, 19], "obstacl": [2, 8, 13, 23, 27, 28, 31, 35, 36, 37, 38, 60], "obtacl": [28, 29], "off": [23, 52, 61], "offer": 4, "offlin": 23, "offpolicyalgorithm": 7, "old": 13, "older": 23, "omega": 13, "onc": [4, 13, 23, 35, 39], "one": [4, 5, 6, 7, 8, 12, 13, 14, 15, 16, 20, 23, 24, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 40, 60, 64, 65], "ones": [4, 24], "onli": [4, 5, 6, 7, 8, 13, 15, 16, 20, 23, 27, 28, 47, 48, 53, 54, 58, 59, 60], "onlin": 23, "onnx": [2, 4, 7, 10, 12, 16, 20, 22, 23, 30, 31, 32, 35, 36, 47, 48], "onnxpolici": [10, 14, 20, 22, 35, 48], "onnxruntim": 14, "open": [4, 22, 23, 24, 27, 28, 33], "open_html": 23, "openai": 4, "oper": [4, 47], "opinion": 4, "oppos": [52, 60, 62, 63, 64], "opposingsid": 61, "opposit": [5, 22, 23, 39, 55, 58], "optim": [13, 16, 18, 23, 32, 38, 39, 52, 65], "optimal_angular_spe": [13, 65], "optimal_spe": [13, 22, 23, 28, 29, 33, 34, 65, 66], "optimizer_class": 16, "optimizer_kwarg": 16, "option": [4, 5, 6, 7, 9, 13, 15, 16, 19, 20], "orang": [27, 35, 64], "order": [7, 10, 13, 65], "order_invariant_kei": 16, "order_invariant_slic": 16, "orderinvariantcombinedextractor": [10, 16], "orderinvariantflattenextractor": [10, 16], "orgin": 9, "orient": [4, 5, 13, 35, 36], "origin": [4, 9, 11, 13, 16, 23, 24, 32, 36], "other": [4, 11, 13, 15, 16, 20, 22, 23, 24, 28, 30, 31, 32, 33, 39, 40, 47, 48, 50, 52, 53, 54, 55, 56, 57, 60, 64], "other_agent_current_spe": 13, "other_agent_distance_to_exit_pad": 13, "other_agent_optional_spe": 13, "other_agent_time_to_exit_the_pad": 13, "other_group": 5, "otherwis": [5, 13, 16], "our": [3, 23, 28, 30, 31, 36, 38, 40], "out": [9, 24, 25], "out_featur": 43, "outgo": 16, "outlier": [30, 31], "output": [4, 5, 13, 14, 16, 23, 24, 28, 29, 35, 40, 47, 49, 50, 51], "over": [4, 7, 13, 30, 31, 33], "overlap": 5, "overli": 30, "overload": 13, "overrid": [13, 17], "overwrit": [22, 23, 28, 32, 33], "own": [5, 6, 13, 15, 18, 20, 23, 28, 36, 61], "p": [13, 30, 31, 32], "p_straight": 28, "packag": [3, 4, 9], "pad": [2, 10, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62], "pad_penalti": [8, 39, 53, 57], "pad_toler": [13, 60], "pad_width": [13, 60], "padreward": [8, 39, 41, 42, 43, 44, 45, 46, 48, 53, 57], "padscenario": [8, 13, 39, 44, 60], "page": 2, "pai": 57, "pair": 23, "panda": [27, 30, 31, 32, 33, 35, 36, 39, 65, 66], "paralel": 25, "parallel": [7, 8, 9, 15, 23, 24, 25, 32, 34, 47, 50, 58, 64], "parallel_env": [4, 9, 10, 15, 16, 20, 24, 30, 31, 32, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 65, 66], "parallelenv": [5, 8, 9, 15, 21], "param": 5, "paramet": [4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 38, 48, 66], "part": [4, 5, 9, 11, 13, 19, 24, 48], "parti": 3, "partial": [4, 31, 52], "particular": [0, 4, 9, 24, 34, 64], "pass": [4, 6, 7, 8, 9, 13, 15, 28], "patch": 9, "path": [7, 9, 12, 13, 14, 19, 20, 23, 30, 31, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "path_look_ahead": 13, "path_tau": 13, "pathlib": [36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "pathlik": [5, 7, 10, 12, 13, 14, 19, 20], "pcg64": 9, "pd": [20, 27, 30, 31, 32, 33, 35, 36, 39, 65, 66], "peer": [4, 31, 34, 38], "penal": [8, 28, 39, 65], "penalti": [18, 23, 28, 39, 50, 53, 57], "penv": [4, 24, 25, 32, 65, 66], "penv2": [24, 25], "penv_stat": [24, 25], "per": [5, 27, 28, 32, 35], "perceiv": [28, 47, 50, 52, 54, 58, 59], "perfom": [31, 32], "perform": [4, 13, 14, 23, 27, 32, 33, 34, 35, 36, 38, 39, 47, 59, 65, 66], "period": [2, 13, 38, 66], "periodic_i": 13, "periodic_x": 13, "pettingzoo": [0, 2, 5, 7, 8, 9, 10, 22, 25, 26, 32, 38], "pettingzoo_env_to_vec_env_v1": [15, 24], "pettingzoowrapp": 4, "physic": 4, "pi": [28, 35], "pick": [28, 39], "pictur": 60, "pil": 23, "pip": 3, "pipelin": 35, "pkl": 20, "pl": 9, "place": [13, 23], "plai": [30, 35], "plain": 17, "planner": 13, "plaza": 67, "plot": [7, 10, 22, 27, 28, 30, 31, 32, 33, 35, 36, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "plot_comparison_test_run": 27, "plot_config": 7, "plot_eval_log": [10, 20, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "plot_last_pos": 36, "plot_log": [10, 20], "plot_polici": [10, 20, 41, 43, 44, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "plot_policy_with_comm": 42, "plot_run": [27, 28, 36], "plot_test_run": 27, "plt": [22, 23, 27, 28, 30, 31, 32, 33, 35, 39, 40, 42, 44, 45, 46, 47, 48, 62, 65, 66], "po": [30, 31], "point": [4, 8, 13, 28, 36, 51, 66], "polic": [30, 31], "polici": [0, 2, 5, 6, 9, 10, 12, 13, 14, 15, 19, 20, 24, 25, 26, 27, 33, 34, 36, 37, 38, 41, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 63, 65, 66, 67], "policy_": 20, "policy_color": [30, 31], "policy_group": [30, 31], "policy_kwarg": [9, 16, 27, 32, 33, 35, 36, 47, 48, 65, 66], "policy_mappo": [41, 42, 52], "policy_mappo_o": 52, "policy_masac": [41, 42, 43, 52], "policy_masac_alt": 43, "policy_masac_discret": 52, "policy_masac_st": 52, "policy_mean": 31, "policy_path": [4, 13, 22, 35], "policy_r": 31, "policy_reward": [30, 31], "policy_std": 31, "policybehavior": [4, 10, 12, 22, 35], "policycal": [9, 10], "policycallablewithinfo": [9, 10], "policypredictor": [10, 14, 16, 19, 23], "policypredictorwithinfo": [7, 10, 16, 19, 23], "popul": 31, "port": 23, "portion": 13, "pose": [13, 22, 27, 28, 30, 31, 37, 38, 45, 65, 66], "pose2": 13, "posit": [5, 6, 8, 13, 15, 16, 23, 24, 25, 28, 36, 40, 47, 52, 53, 54, 57, 58, 59, 60, 61, 62, 64], "posixpath": [36, 41, 42, 43, 44, 52], "possibl": [3, 6, 11, 12, 13, 15, 28, 36, 38, 62], "possible_ag": [24, 32], "possibli": [4, 5, 7, 19, 23, 57], "post": 13, "ppo": [50, 52, 58, 62, 63, 64], "ppo_log": 61, "ppo_model": 61, "ppo_os_log": 61, "ppo_os_model": 61, "practic": [4, 36], "pre": [7, 13, 27, 34, 38, 65], "preced": 39, "precens": 46, "precis": [27, 30, 31, 32, 33, 35, 36, 39, 65, 66], "predefin": 4, "predict": [10, 13, 14, 19, 23, 24, 35, 40, 42, 45, 66], "predictor": [16, 19, 35], "predix": 21, "prefer": [3, 35], "prefix": [20, 21, 25, 36], "prepar": 13, "presenc": 50, "present": 20, "prevent": 4, "previosli": 27, "previou": [4, 24, 27, 31, 32, 48, 50, 58, 59, 65], "previous": [12, 50], "print": [23, 24, 27, 28, 31, 32, 33, 35, 36, 39, 60, 65, 66], "pro": 4, "probabl": [22, 27, 28, 65, 66], "probe": [7, 10, 22, 28, 31, 39, 45, 46, 47, 48], "problem": [4, 39], "problemat": 31, "process": [4, 6, 7, 9, 15, 16, 19, 23, 30, 31], "processor": 4, "produc": [35, 62], "progress": [9, 20, 27, 32, 33, 65, 66], "progress_bar": [27, 32, 33, 35, 65, 66], "progressbarcallback": 20, "progressbarwithrewardcallback": [10, 20], "project": [4, 13], "promot": [36, 50], "properti": [5, 6, 9, 11, 13, 14, 15, 17, 20], "protect": 13, "protocol": [14, 19, 23], "provid": [0, 4, 5, 7, 12, 15, 17, 20, 24, 27, 40], "psac": 4, "psac_ma": 4, "pt": [20, 41, 42, 43, 44, 52], "public": 13, "py": [9, 20, 22], "pybind11_object": 13, "pypi": 3, "pyplot": [22, 23, 27, 28, 30, 31, 32, 33, 35, 39, 40, 42, 44, 45, 46, 47, 48, 62, 65, 66], "pyplot_help": [27, 28, 36], "python": [3, 4, 22], "python3": 3, "pytorch": [3, 4, 14, 35], "pytorchob": [10, 19], "pytorchpolici": [10, 14, 19, 20], "pz": 4, "qualiti": 28, "quantifi": 31, "quantil": 27, "quasi": 13, "queri": 13, "queue": 5, "quit": [27, 28], "r": [11, 22, 25, 36, 39], "r_env": 23, "rad": 28, "radian": 36, "radii": 23, "radiu": [5, 13, 22, 23, 24, 25, 28, 29, 33, 34, 35, 36, 65, 66, 67], "rais": [5, 11, 12, 13, 15, 16, 17, 20], "random": [4, 9, 10, 13, 22, 23, 24, 25, 27, 32, 33, 35, 36], "random_polici": [23, 36], "random_predictor": [24, 36], "random_reward": 36, "random_reward_std_dev": 36, "randomli": [28, 36, 60], "randompolici": [10, 16, 23], "randompredictor": [10, 16, 24, 36], "rang": [4, 8, 13, 22, 23, 24, 25, 28, 29, 33, 34, 36, 39, 65, 66, 67], "rare": 28, "rate": [3, 36, 39, 50], "ratio": 30, "ravel": 40, "rd_kwarg": [30, 31], "rdylgn": [20, 40], "reach": [13, 32, 37, 38], "read": [0, 4, 9, 11, 22, 23, 24, 27, 28, 33], "read_csv": [27, 32, 33, 65, 66], "readi": 33, "readthedoc": 32, "real": [6, 7, 15, 23, 35], "realiti": 4, "realli": [31, 65], "realtim": [6, 15], "realtime_factor": [6, 15, 23], "receiv": [8, 13, 48, 50], "recent": 5, "recevi": [47, 50], "reconstruct": 14, "record": [4, 7, 13, 22, 23, 25, 27, 28, 31, 32, 33, 36, 39, 45, 46, 47, 48], "record_config": [22, 27, 28, 30, 31, 36, 45, 62, 65, 66], "record_efficaci": [4, 35], "record_episode_video": [7, 10, 40, 44, 53, 54, 55, 56, 57, 61, 62], "record_pos": 4, "record_reward": [7, 30, 31, 45, 65], "record_run_video": [7, 10], "record_success": 7, "record_video": 60, "record_video_from_run": 61, "recordconfig": 22, "recorded_step": 39, "recordepisodestatist": 23, "recordprob": 13, "recordvideo": 23, "recreat": 23, "rectangl": 47, "rectangular": 19, "recurr": 19, "red": [7, 22, 30, 31, 42, 45, 46, 60, 65, 66], "redo": 33, "reduc": [4, 50], "reduct": [10, 16], "refer": [2, 5, 12, 13, 23], "reference_register_schema": 13, "reflect": [4, 35], "region": 19, "regist": [0, 2, 5, 6, 10, 13], "register_schema": 13, "registr": [5, 10, 17, 19], "reinforc": [29, 33, 38, 67], "reject": 9, "rel": [5, 8, 24, 28, 35, 40, 52, 53, 54, 55, 56, 57, 61, 64], "relat": [5, 6, 12, 15], "relative_margin": [65, 66], "relax": 13, "releas": 3, "relev": [5, 8], "reli": 35, "reload": [20, 22, 23, 31, 35, 43, 46], "reload_ext": [43, 46], "reload_from_fil": [20, 41, 42, 43, 44, 52], "relu": 16, "remain": [4, 32], "remov": [13, 16, 54, 55, 57], "remove_modul": 13, "removed_kei": 16, "removed_slic": 16, "renam": 21, "render": [6, 7, 8, 13, 15, 24, 41, 42, 43, 44, 52], "render_fp": 23, "render_kwarg": [6, 8, 13, 15, 23, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62], "render_mod": [6, 8, 15, 23, 41, 42, 43, 44, 52], "replac": [4, 23], "replic": [13, 16, 30], "replicated_kei": 16, "replicated_slic": 16, "repres": [23, 24, 64], "represent": [5, 6, 7, 11, 12, 13, 15, 17, 23, 24], "reproduc": 31, "request": [5, 13], "requir": [4, 9, 15, 23, 31, 32, 35, 36, 39], "rescal": [32, 33], "reset": [4, 6, 10, 15, 19, 23, 24], "reset_info": 23, "reset_num_timestep": [36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "reshap": [39, 40, 42, 45], "resiz": 23, "resolut": 24, "resolv": 4, "respect": [14, 23, 65], "respons": [4, 32], "rest": [4, 30, 31, 33], "restor": 20, "restore_fil": 20, "restrict": 64, "result": [24, 47], "resus": 32, "retreat": [53, 57], "retriev": [9, 12], "return": [4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 30, 31, 35, 36, 41, 42, 43, 44, 52, 65], "return_episode_reward": [7, 20, 27, 28], "return_mean": [27, 32, 33], "return_queu": 23, "return_st": 4, "revers": 13, "reward": [0, 2, 4, 5, 6, 7, 10, 13, 15, 19, 20, 22, 23, 24, 27, 28, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 48, 50, 51, 53, 57, 64, 65, 66], "reward_agent_1_ep_1": 7, "reward_agent_2_ep_1": 7, "reward_agent_n_ep_m": 7, "reward_color": 20, "reward_ep_1": 7, "reward_ep_2": 7, "reward_high": [20, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "reward_linestyl": 20, "reward_low": [20, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "reward_mean": 35, "reward_std_dev": 35, "reward_threshold": 7, "rewardprob": [7, 10, 13, 22, 31, 39], "rewards_1_19": 31, "rewards_env": 31, "rewards_ma": 32, "rewards_ma_env": 30, "rewards_sa": 33, "rewardwithspeed": 65, "rexasi": 4, "rgb_arrai": [6, 15, 23, 41, 42, 43, 44, 52], "right": [13, 19, 28, 53, 57], "rightward": 35, "rigor": 38, "rkwarg": 44, "rl": [4, 27, 31, 32, 36, 52, 61, 64, 66], "rm": 4, "rng": [9, 33], "rnn": 19, "robot": [3, 4, 35], "roll": [25, 65, 66], "rollout": [4, 9, 13, 25, 27, 32, 33, 59, 65, 66], "rollout_round_min_episod": [27, 32, 33], "rollout_round_min_timestep": 4, "rollout_without_info": 9, "rolloutinfowrapp": 9, "rot": 13, "rotat": [13, 30, 31], "rotation_tau": 13, "round": 39, "row": [27, 30, 47], "rt_env": 23, "rule": [28, 60], "run": [4, 6, 7, 9, 13, 14, 15, 18, 20, 22, 23, 27, 28, 30, 31, 32, 33, 35, 36, 39, 45, 46, 47, 48, 62, 65, 66], "run_and_time_if": 27, "run_for": [4, 20, 41, 42, 43, 44, 52], "run_if": [27, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "run_index": [27, 30, 31, 65], "run_mp": [30, 31], "run_onc": [30, 36, 45, 46, 47, 48, 62], "runtim": [13, 38, 67], "runtime_error": 13, "rx": [42, 45, 46], "sa": [34, 38], "sa_env": 24, "sac": [4, 10, 29, 30, 31, 35, 36, 38, 45, 47, 50, 52, 53, 54, 55, 56, 57, 58, 63, 64, 65, 66], "sac_cmd": 35, "sac_efficaci": 35, "sac_feasible_cmd": 35, "sac_log": 61, "sac_model": 61, "sac_reward": [27, 65, 66], "sacpolici": 16, "sacpolicywithcomm": [10, 16, 47], "safe": [13, 28, 30, 47, 50, 53, 61], "safe_dump": 24, "safer": 30, "safeti": [7, 13, 18, 23, 28, 30, 31], "safety_margin": [13, 18, 22, 23, 24, 27, 28, 29, 33, 34, 65, 66], "safety_viol": 7, "sai": 24, "same": [4, 7, 8, 9, 13, 15, 16, 19, 20, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 39, 47, 50, 60, 62, 63, 64, 65, 66, 67], "same_speed_env": 66, "same_speed_reward": 66, "samespe": 66, "sampl": [6, 9, 14, 15, 20, 23, 24, 32, 35, 60, 65], "sample_until": 9, "sampler": [35, 36, 39, 65], "samples_so_far": [27, 32, 33], "satisfi": 13, "save": [0, 2, 4, 7, 9, 10, 14, 20, 22, 26, 27, 32, 33, 35, 36, 38, 48, 65, 66], "save_env": [10, 12, 23, 24, 28, 32, 33, 65, 66], "save_fold": [41, 42, 43, 44, 52], "save_path": 20, "save_to_zip_fil": 9, "save_util": 9, "sb3": [16, 20, 24, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62], "scalar": 19, "scale": [20, 23], "scanner": 24, "scenario": [0, 4, 6, 8, 10, 15, 22, 23, 24, 27, 29, 31, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 64, 67], "scenario_with_polici": 22, "schedul": 16, "schema": 13, "scheme": 5, "search": 2, "second": [5, 13, 16, 24, 25, 27, 29, 30, 31, 32, 33, 35, 47, 52, 62], "second_10": 25, "second_11": 25, "second_12": 25, "second_13": 25, "second_14": 25, "second_15": 25, "second_16": 25, "second_17": 25, "second_18": 25, "second_19": 25, "second_group": 24, "see": [4, 6, 13, 15, 22, 28, 31, 32, 36, 40, 47, 52, 55], "seed": [4, 6, 7, 9, 13, 15, 20, 22, 23, 25, 27, 28, 30, 31, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65], "seem": [22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "seen": [23, 31, 61], "select": [4, 5, 6, 7, 11, 12, 13, 15, 16, 17, 23, 24, 35, 41, 42, 43, 44], "self": [5, 6, 9, 13, 15, 17, 19, 23, 65], "sens": [0, 4, 5, 28, 35, 46], "sensing_spac": 5, "sensingst": [4, 13], "sensor": [0, 4, 5, 6, 10, 12, 13, 15, 19, 22, 23, 24, 25, 27, 29, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66, 67], "sensorlik": [5, 6, 10, 15, 19], "sensors_bin": 46, "sensorsequencelik": [5, 6, 8, 10, 15, 19], "separ": [4, 13, 16, 36, 50], "sequenc": [5, 6, 7, 9, 11, 15, 16, 19, 20, 35, 39, 50], "seri": [29, 31, 32, 64], "serv": 64, "set": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 33, 65], "set_env": 9, "set_first_agent_to_dummi": 31, "set_init": 65, "set_logg": [9, 27, 32, 33, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "set_nam": [32, 33, 65, 66], "set_opt": [27, 30, 31, 32, 33, 35, 36, 39, 65, 66], "set_optimal_angular_spe": 65, "set_se": 4, "set_state_from": 13, "set_text": 40, "set_titl": [23, 28, 30, 31, 35], "set_veloc": 13, "set_xlabel": [28, 30, 31, 35, 40, 42, 45], "set_xlim": [30, 31], "set_xtick": 40, "set_ylabel": [28, 30, 31, 40, 42, 45], "set_ylim": [30, 31], "set_ytick": 40, "setup": [23, 28], "setup_tqdm": [9, 10, 27, 32, 33, 35], "sever": [4, 23, 52, 64], "shape": [13, 16, 22, 23, 25, 28, 31, 42, 47], "share": [4, 15, 16, 23, 24, 27, 39, 48, 51, 58, 59, 64, 66, 67], "share_features_extractor": 16, "share_param": 43, "shared_parallel_env": [4, 10, 15, 24, 65, 66], "short": 23, "shorten": 23, "shorter": [18, 32], "should": [3, 5, 8, 13, 14, 16, 23, 28, 36, 39, 47, 57, 60], "show": [22, 23, 38, 65], "showcas": [23, 24, 25, 35, 64], "side": [0, 22, 23, 28, 33, 34, 58, 60, 62, 63, 64, 65, 66, 67], "sightli": 36, "sigl": [4, 32], "sign": 13, "signal": [6, 15, 46], "signific": [32, 46], "significalti": 32, "significantli": [32, 33, 53, 57], "silent": 13, "sim": [4, 5, 6, 7, 13, 15, 19, 22, 23, 24, 27, 28, 30, 31, 33, 35, 36, 39, 40, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "similar": [4, 7, 9, 16, 19, 20, 23, 24, 30, 31, 32, 33, 35, 39, 52, 53, 56], "similarli": [4, 9, 22, 31, 35, 66], "similat": 7, "simpl": [13, 16, 28, 29, 35, 65], "simpledaggertrain": 9, "simpler": [4, 55], "simplest": 33, "simpli": 23, "simplif": 4, "simplifi": [4, 9], "simul": [4, 5, 6, 8, 13, 15, 19, 22, 23, 24, 27, 31, 32, 33, 65, 66], "sin": 65, "singl": [2, 4, 5, 7, 8, 10, 13, 14, 15, 16, 20, 22, 23, 26, 28, 29, 30, 32, 34, 35, 38, 47, 50, 52, 59, 61, 62, 64], "singleagentpolici": [10, 20], "sinusoid": 65, "size": [5, 7, 8, 13, 14, 16, 20, 23, 25, 28, 30, 31, 41, 42, 43, 44, 45, 46, 47, 48], "skip": [27, 30, 32, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "skip_if": [27, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "slice": [7, 11, 13, 15, 16, 19, 24, 30, 31], "slide": 11, "slighti": 7, "slightli": [4, 23, 36, 47], "slow": 57, "small": [13, 60], "smaller": 6, "smooth": 66, "smoother": 13, "so": [0, 5, 18, 23, 31], "soa": 64, "social": [10, 13, 23, 24], "social_margin": [13, 18, 23, 24], "socialreward": [4, 10, 18, 22, 23, 24, 27, 28, 33, 65, 66], "sole": [15, 16], "solid": [30, 31], "solut": 53, "solv": 39, "some": [4, 7, 13, 16, 20, 21, 32, 36, 46], "sometim": 28, "soon": 15, "sorri": [22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "sort": 5, "sort_kei": [5, 23, 24], "sourc": 4, "space": [4, 5, 6, 8, 9, 14, 15, 16, 20, 23, 24, 27, 29, 35, 47, 58, 59, 60, 63], "spawn": [4, 60], "speak": [50, 64], "speaker": 44, "spec": [16, 23, 27, 35], "special": [13, 23], "specif": [0, 4, 14, 16, 23], "specifi": [4, 5, 7, 13, 14, 15, 16, 32, 36, 50], "speed": [5, 6, 8, 13, 15, 18, 23, 24, 28, 29, 31, 35, 36, 38, 39, 40, 52, 53, 54, 55, 58, 59, 61, 62, 63, 67], "speed_toler": [22, 23, 33, 34, 65, 66, 67], "split": [10, 30, 49, 51], "split_mlp": 43, "split_sac_polici": 48, "splitmlpconfig": 43, "splitmodel": [43, 48], "splitmodelaltern": 48, "splitsacpolici": [10, 16, 48], "squar": 67, "squash_output": 16, "src": 22, "stabil": 50, "stabl": [3, 4, 23, 32], "stable_baselines3": [4, 7, 9, 16, 19, 20, 23, 24, 27, 30, 31, 32, 33, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "stablebaselin": 54, "stablebaseline3": [7, 10, 15, 23, 32, 36, 52, 59, 61, 62], "stack": [4, 5, 15, 16, 24, 32, 35, 40, 42, 45, 47], "stacklevel": 22, "stai": 23, "stamp": [27, 32, 33, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "stand": 32, "standard": [4, 7], "start": [13, 14, 23, 24, 27, 28, 30, 31, 32, 33, 35, 36, 37, 53, 57, 58, 60, 62, 63, 64], "start_angl": [24, 25], "start_in_opposite_sid": [13, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62], "start_max_x": [13, 60], "start_min_x": [13, 60], "startfromopposingsid": 52, "state": [0, 4, 6, 8, 9, 10, 14, 15, 19, 23, 25, 26, 38, 41, 42, 43, 44, 47, 50, 58], "state_config": 24, "state_estim": [4, 13, 22, 23, 28, 29, 31, 33, 34, 39, 65, 66], "state_spac": [24, 52], "stateconfig": [5, 8, 15, 24], "static": [8, 13, 20], "statist": [7, 23, 32], "status": 13, "std": [7, 13, 20, 28, 31, 32, 33, 35, 36, 39, 65, 66], "std_dev": 35, "stddev": [32, 33, 65, 66], "step": [4, 5, 6, 7, 8, 10, 13, 15, 19, 20, 22, 23, 24, 27, 28, 30, 31, 32, 33, 35, 36, 39, 47, 50, 60, 64, 65, 66], "still": [4, 9, 13, 32, 35], "stop": [13, 24, 36, 39, 53, 57], "stopatpad": [39, 53, 57], "stopatpadbehavior": [13, 39], "store": [7, 13, 20, 32], "stori": [30, 31], "str": [4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 19, 20, 21, 36, 41, 42, 43, 44, 52], "straight": [23, 28, 30, 31, 60], "straightforward": 4, "strategi": [13, 50], "stream": 67, "strftime": [27, 32, 33, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "stricli": 31, "string": [4, 13], "stroke": 13, "structur": 20, "struggl": [52, 61], "stuck": [5, 6, 9, 13, 15, 30, 31], "stuck_timeout": [6, 15, 23], "studi": 64, "sub": [4, 7, 9, 11, 13, 16, 17], "sub_dict": [10, 11], "sub_sequ": [10, 11], "subclass": [0, 4, 15], "submodul": [16, 47], "subplot": [23, 27, 28, 30, 31, 35, 40, 42, 45], "subset": 16, "succe": 5, "success": [3, 5, 6, 7, 8, 13, 15, 19, 20, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "success_condit": [5, 6, 15, 36, 44], "success_r": 36, "successfulli": [32, 33, 36, 66], "successprob": [10, 13, 39], "suffix": [14, 25], "sugar": 19, "suitabl": 4, "sum": [16, 18, 24, 28, 30, 31, 36, 39, 40], "summari": [34, 38, 51, 66], "super": [5, 65], "supersuit": [4, 9, 15, 24], "support": [3, 4, 9, 16, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "suptitl": [28, 31, 40], "surpris": [23, 31, 46], "svg": [27, 28, 32, 33, 65, 66], "svg_color": 65, "svg_for_ag": 36, "switch": [27, 33, 62], "system": [4, 5, 33], "t": [10, 11, 22, 23, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "tackl": 4, "tag": [5, 6, 15, 21, 24, 25, 44], "tag1": 21, "tag2": 21, "tagn": 21, "take": [16, 27, 28, 32, 33, 34, 40, 52, 64], "taken": 4, "tanh": 43, "targer": 28, "target": [4, 5, 13, 18, 23, 28, 30, 31, 35, 36, 38, 66, 67], "target_angular_spe": 65, "target_margin": [22, 23, 33, 34], "target_ref": 13, "target_spe": 65, "targetefficacyreward": 36, "task": [4, 6, 15, 20, 28, 31, 32, 35, 36, 37, 50, 55, 57, 64], "tau": [13, 22, 23, 28, 29, 33, 34, 65, 66], "tau_": 13, "tb_log_nam": [27, 32, 33], "td": 4, "teal": 30, "tell": [30, 31], "tend": 40, "tendenc": 39, "tensor": [4, 16, 19, 25], "tensorboard": [7, 27, 32, 33, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "tensordict": [4, 20, 25], "term": [39, 46, 65], "termin": [4, 5, 6, 7, 13, 15, 19, 23, 24], "terminate_if_idl": [6, 15, 23], "terminate_on_failur": [5, 6, 15, 23, 24, 44], "terminate_on_success": [5, 6, 15, 23, 24, 36, 44], "terminate_outside_bound": 7, "terminate_when_all_idle_or_stuck": [36, 39], "terminationcondit": [5, 6, 10, 15, 19], "ternari": 5, "test": [3, 7, 19, 31, 36, 48, 50, 58, 59, 60, 65], "test_env": [27, 35, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61], "test_env_bin": 46, "test_env_discret": [52, 62], "test_env_mb": 62, "test_env_st": 52, "test_scenario": [44, 65], "test_venv": [32, 33, 36, 40, 41, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57], "test_venv_bin": 46, "test_venv_discret": 52, "text": 44, "textrm": 13, "th": 16, "tha": 65, "than": [5, 6, 8, 28, 29, 30, 31, 32, 33, 35, 47, 53, 55, 56, 57, 66], "thei": [4, 5, 7, 12, 13, 15, 24, 31, 32, 35, 47, 50, 60, 64, 66, 67], "them": [4, 7, 13, 20, 23, 31, 32, 35, 38, 39], "themselv": 31, "theoret": [32, 33], "therefor": [4, 9, 13, 23, 24, 31, 32, 35, 66], "theta": 13, "thi": [4, 5, 6, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 64, 65, 66, 67], "think": 4, "third": 3, "those": [4, 64], "thought": 9, "three": [7, 27, 31, 32, 33, 35], "through": [13, 16, 19, 23, 24], "thymio": [22, 23, 28, 29, 33, 34, 35, 36, 65, 66, 67], "time": [4, 5, 6, 7, 8, 13, 15, 19, 23, 27, 28, 30, 31, 32, 33, 36, 39, 50, 60, 64, 65, 66], "time_step": [4, 5, 6, 7, 8, 13, 15, 19, 22, 23, 24, 27, 28, 31, 33, 35, 36, 39, 44, 60, 65, 66], "timedelta": 35, "timeit": [28, 35], "timeout": 36, "tini": 9, "titl": [20, 22, 27, 28, 39, 40, 44, 45, 46, 47, 48, 62, 65, 66], "to_csv": [27, 30, 31, 32, 33, 35, 36, 39, 65, 66], "to_fram": 13, "to_html": 23, "to_svg": 36, "todo": [5, 18], "togeh": 30, "toget": [30, 31], "togeth": [4, 9, 12, 16, 24, 27, 36, 40, 47, 50], "toler": [13, 22, 23, 33, 34, 36, 60], "tolist": 40, "too": [20, 24, 25, 28, 31], "took": [27, 32, 33], "tool": [4, 22, 52], "top": [19, 28], "torch": [16, 19, 25, 52], "torch_lay": 16, "torchrl": [20, 26, 38], "total": [16, 24, 30, 31], "total_timestep": [4, 27, 32, 33, 35, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "toward": [13, 18, 23, 28, 35, 36, 52], "tqdm": [9, 20], "train": [0, 2, 3, 5, 7, 9, 10, 20, 27, 29, 34, 37, 38, 41, 42, 44, 45, 46, 49, 51, 52, 58, 59, 60, 62, 63, 64, 67], "train_env": [36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61], "train_env_bin": 46, "train_env_discret": [52, 62], "train_env_mappo": [41, 42], "train_env_mb": 62, "train_env_o": 52, "train_env_st": 52, "train_ppo_env": 61, "train_scenario": [44, 60], "train_venv": [40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 65, 66], "train_venv_bin": 46, "train_world": 60, "trainer": 9, "training_venv": [32, 33], "trajectori": [4, 7, 9, 22, 28, 36], "trajectoryaccumul": 13, "trajectoryplotconfig": [7, 10], "trajectorywithrew": 9, "trajectoti": 28, "transform": [4, 7, 13, 24], "translat": 0, "transmit": [5, 13, 47, 48], "travel": [8, 13, 28, 29, 31, 35], "treat": [5, 6, 15, 59], "tri": [33, 39], "trivial": 28, "true": [4, 5, 6, 7, 8, 13, 14, 15, 16, 19, 20, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "truncat": [4, 6, 15, 23, 24], "truncate_fast": [15, 23], "truncate_outside_bound": [6, 15, 23], "try": [23, 27, 28, 31, 33, 34, 46, 62], "tune": 39, "tupl": [6, 7, 9, 11, 12, 13, 14, 15, 16, 19, 20, 23, 24], "turn": [4, 13, 60], "tutori": [2, 4, 33, 59, 66, 67], "twist": [13, 35, 62], "twist2": [4, 5, 6, 13, 15, 24, 35], "twist_cmd": 13, "twist_from_wheel_spe": 13, "twist_towards_veloc": 13, "two": [0, 4, 5, 7, 13, 16, 20, 23, 25, 26, 27, 29, 31, 32, 33, 38, 39, 40, 47, 50, 53, 58, 59, 60, 62, 64, 66, 67], "two_axi": 20, "tx": [42, 45, 46, 47, 48], "type": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 24, 28, 29, 32, 33, 34, 35, 36, 39, 60, 64, 65, 66, 67], "type_alias": 19, "typeerror": [12, 15], "typevar": 11, "typic": [4, 28], "u": [13, 22, 23, 24, 28, 31, 32, 33, 35, 36, 40, 46, 52, 53, 56, 57, 62, 65], "ui": [6, 15, 22, 23, 28, 30, 31, 33, 35, 36, 39, 60, 61, 65, 66], "uint8": [16, 23, 24, 25, 30, 31], "uncom": [27, 32], "undefin": [6, 13, 15], "under": [6, 20], "underli": 4, "understand": [23, 31], "unidirect": [49, 50, 64], "uniform": [35, 36, 38, 65, 67], "uniformli": [52, 60, 64], "union": [4, 11], "unit": 35, "unknown": 13, "unless": 62, "unsaf": 31, "unspecifi": 32, "unstabl": 46, "until": [4, 6, 9, 15], "untrain": 33, "unwrap": [12, 15, 23, 27, 31, 32, 35, 36], "up": [6, 13, 15, 16, 31], "updat": [4, 6, 13, 15, 28], "update_dri": [6, 15], "update_static_obstacl": [28, 29], "upper": [5, 8, 13, 20, 32, 33], "us": [5, 6, 7, 9, 11, 12, 13, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 46, 47, 49, 50, 51, 52, 54, 59, 61, 62, 64, 65, 66, 67], "use_absolute_fram": 5, "use_acceleration_act": [5, 8, 13, 23, 24, 27, 28, 33, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "use_expln": 16, "use_masked_tensor": 16, "use_multiprocess": 7, "use_nearest_point": [23, 24], "use_onnx": 7, "use_sd": [16, 46], "use_wheel": [5, 13, 23, 24], "use_world_bound": 7, "useful": [47, 50], "user": [3, 13, 16, 22], "userwarn": 22, "usual": [35, 65, 66], "util": [2, 4, 5, 10, 15, 25, 27, 32, 33, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "v": [6, 7, 13, 15, 20, 24, 30, 31, 42, 46], "valid": [5, 6, 13, 15, 23, 24, 25], "valu": [5, 6, 7, 8, 11, 13, 15, 16, 17, 19, 23, 24, 27, 28, 30, 31, 35, 36, 39, 53, 57, 62, 65, 66], "value_1": 32, "value_2": 32, "valueerror": [5, 11, 17, 20], "vari": [38, 67], "variabl": [15, 20, 41, 43, 44, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "variant": [13, 48, 52, 64], "variat": 16, "varyoptimalspe": 65, "vec_env": [32, 36, 45, 46, 48, 53, 54, 55, 56, 57, 65, 66], "vecenv": [7, 9, 15, 20], "vecmonitor": [15, 32, 45, 46, 48, 53, 54, 55, 56, 57, 65, 66], "vector": [4, 9, 13, 15, 32, 35, 36, 59], "veloc": [5, 8, 13, 23, 24, 25, 35, 36, 52, 54, 56, 57, 65], "venv": [4, 9, 23, 24, 32, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "venv1": 24, "verbos": [16, 20, 32, 33, 35, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62], "veri": [4, 28, 31, 35, 46], "verifi": 62, "version": [4, 9, 23, 24, 35, 52], "vertic": 19, "via": [6, 15], "video": [10, 20, 22, 23, 28, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "video_config": 7, "video_env": [23, 47], "video_fold": 23, "video_format": 20, "video_polici": 47, "videocallback": [10, 20], "videoconfig": [7, 10], "view": [4, 23, 32, 47], "violat": [7, 18, 23, 28, 30, 31, 60], "virtual": 13, "visibl": 28, "visual": [32, 33, 65], "vmax": 40, "vmin": 40, "wa": 4, "wai": [0, 4, 8, 9, 13, 23, 28, 33, 48], "wait": [6, 15, 23, 44], "wall": [13, 28, 29], "want": [7, 9, 13, 23, 24, 28, 29, 30, 31, 32, 36, 38], "warn": [5, 7, 20, 22, 23, 25, 27, 28, 32, 33, 35, 36, 41, 42, 43, 44, 52, 65, 66], "waypoint": [23, 33], "we": [0, 3, 4, 5, 7, 9, 15, 16, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67], "websocket": [6, 15], "webui": [6, 15], "weight": [8, 18, 30, 65], "well": [23, 31, 32, 36, 62, 65, 66], "what": 32, "wheel": [5, 13, 65], "wheel_axi": [22, 23, 28, 29, 33, 34, 35, 36, 65, 66, 67], "wheel_spe": 13, "wheel_speeds_from_twist": 13, "when": [4, 5, 6, 7, 8, 13, 15, 16, 20, 23, 24, 25, 27, 28, 30, 31, 32, 35, 36, 39, 52, 53, 55, 56, 57, 60, 61, 62, 67], "where": [4, 5, 7, 8, 9, 12, 13, 14, 19, 20, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 46, 48, 50, 52, 53, 60, 62, 64, 65, 66, 67], "whether": [4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 19, 20], "which": [4, 5, 6, 7, 8, 9, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 36, 39, 46, 47, 50, 53, 62, 63, 64, 65], "while": [4, 9, 13, 18, 23, 24, 30, 32, 33, 35, 36, 50, 52, 63, 64, 65], "white": 13, "whole": [28, 30, 31, 35], "whose": [4, 7, 9, 16], "why": 23, "width": [7, 13, 20, 22, 23, 28, 29, 30, 31, 33, 36, 41, 43, 44, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62], "window": [23, 65, 66], "with_ag": [27, 28, 36], "with_criteria": 39, "with_env": [7, 13, 28], "with_indic": 13, "with_reward": [13, 22, 39], "with_safety_margin": [27, 28], "with_wal": [13, 60], "with_world": [27, 36], "within": [36, 47], "without": [39, 51, 58, 59, 60], "work": [4, 16], "world": [4, 5, 6, 7, 13, 15, 19, 22, 23, 28, 31, 33, 35, 36, 39, 60, 65, 66, 67], "world_kwarg": [7, 27, 28, 36], "worri": 60, "worst": 27, "would": [4, 6, 15, 39, 40, 47, 50], "wrap": [4, 9, 15, 21, 22, 23], "wrapper": [2, 4, 10, 13], "write": 13, "writefil": [22, 23, 28], "wrong": 28, "x": [5, 11, 13, 15, 20, 22, 23, 27, 28, 30, 31, 32, 33, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62, 65, 66], "xlabel": [22, 27, 28, 65, 66], "xlim": [27, 28], "xv": [40, 42, 45], "y": [5, 13, 22, 27, 28, 30, 31, 32, 33, 36, 40, 45, 46, 47, 48, 53, 54, 55, 56, 57, 61, 62, 65, 66], "yaml": [0, 4, 5, 6, 7, 12, 13, 15, 17, 19, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 65, 66], "ye": 5, "yellow": [63, 65, 66], "yet": [3, 4, 5, 13, 32, 35, 64], "ylabel": [22, 27, 28, 45, 46, 47, 48, 62, 65, 66], "ylim": [28, 32, 33], "you": [3, 4, 13, 32, 33, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 61, 62], "your": [22, 23, 28, 30, 31, 33, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66], "yv": [40, 42, 45], "z": 13, "zero": [6, 13, 15, 16, 18, 35], "zip": [23, 27, 30, 31, 32, 33, 35, 39, 42, 45], "\u03bc": [28, 35]}, "titles": ["How to extend", "Guides", "Welcome to navground_learning\u2019s documentation!", "Installation", "Introduction", "Configuration", "Single-agent Gymnasium Environment", "Evaluation", "Examples", "Imitation Learning", "Reference", "Indices", "Saving and Loading", "Navground Components", "Onnx", "Multi-agent Pettingzoo Environment", "Policies", "Register", "Rewards functions", "Types", "Utils", "Wrappers", "Using a ML policy in Navground", "Gymnasium", "PettingZoo", "TorchRL", "Basics", "Learning", "Scenario", "Corridor with obstacle", "Performance of policies trained in multi-agent environment", "Performance of policies trained in single-agent environment", "Training agents among peers", "Training one agent among many agents", "Crossing", "Learn to follow a direction.", "Learn to reach a pose", "Empty environment", "Tutorials", "Model-based behaviors", "Centralized policy trained with SAC", "Continuous actions with MLP", "Discrete actions", "Continuous actions using split MLP", "Unidirection communication", "Parallel PPO with discrete actions and MLP", "Parallel SAC with MLP", "Distributed policy with comm, trained centrally", "Distributed policy with comm trained using parallel SAC: split model", "BenchMARL", "Distributed policy with communication", "Parallel SAC", "BenchMARL", "Without perceiving neighbors", "Parallel PPO with discrete actions", "Perceiving only neighbor position", "Perceiving neighbor position and speed", "Perceiving only neighbor speed", "Distributed policy", "Parallel SAC", "Scenario", "Continous actions", "Discrete actions", "Single ML agent meets Dummy agent", "Exclusive crossing on a pad", "Different speeds", "Uniform speeds", "Periodic Crossing"], "titleterms": {"": 2, "A": 24, "One": 31, "The": 36, "acknowledg": 4, "action": [5, 41, 42, 43, 45, 48, 52, 54, 61, 62], "agent": [4, 6, 15, 30, 31, 32, 33, 63], "along": 39, "altern": [43, 48], "among": [32, 33], "an": 35, "base": [5, 9, 39], "basic": 26, "behavior": [5, 9, 13, 27, 32, 33, 39], "benchmarl": [4, 20, 49, 52], "binari": [5, 46, 62], "central": [16, 40, 47, 50], "class": [5, 9], "clone": [9, 27, 32, 33], "comm": [47, 48], "commun": [5, 16, 43, 44, 48, 50], "comparis": 27, "compon": [0, 13], "configur": [0, 5], "content": [1, 2], "contin": 61, "continu": [5, 41, 43], "continuo": 52, "convert": 24, "converto": 24, "corridor": [8, 29, 39], "corridorwithobstacl": 13, "creat": 35, "critic": 52, "cross": [8, 34, 64, 67], "dagger": [9, 27, 32, 33], "default": 5, "defin": 35, "differ": 65, "direct": 35, "disclaim": 4, "discret": [5, 42, 45, 52, 54, 62], "displai": 35, "distribut": [47, 48, 50, 58], "document": 2, "dummi": 63, "efficaci": 18, "empti": 37, "end": 5, "env": 24, "enviro": 35, "environ": [4, 6, 8, 15, 23, 24, 30, 31, 32, 33, 36, 37, 65, 66], "estim": 13, "evalu": [4, 7, 35, 36, 53, 54, 55, 56, 57], "exampl": 8, "exclus": 64, "experi": 7, "export": [14, 35], "extend": 0, "extractor": 16, "final": 30, "fix": 18, "float": 46, "follow": [31, 35], "forward": 13, "from": [24, 39, 52, 61], "function": 18, "global": 52, "group": [5, 24], "groupedpolicybehavior": 13, "guid": 1, "gymansium": 24, "gymnasium": [4, 6, 23, 24], "hl": 27, "how": 0, "human": 33, "imit": [4, 9, 27, 35], "indic": [2, 11], "infer": 14, "info": 16, "instabl": 50, "instal": 3, "integr": 4, "introduct": 4, "invari": 16, "joint": 24, "learn": [4, 9, 27, 35, 36], "like": 33, "load": [12, 23, 24], "log": 7, "mani": 33, "mappo": [41, 42, 52], "masac": [41, 42, 43, 52], "meet": 63, "messag": 46, "ml": [4, 22, 63], "mlp": [16, 41, 43, 45, 46], "model": [39, 48, 50], "modul": 5, "more": 31, "multi": [4, 5, 15, 30, 62], "navground": [0, 4, 7, 13, 22, 23, 35], "navground_learn": 2, "neighbor": [53, 55, 56, 57], "null": [16, 18], "observ": 5, "obstacl": 29, "one": 33, "onli": [55, 57], "onnx": 14, "oppos": [39, 61], "opposit": 52, "order": 16, "pad": [8, 13, 64], "parallel": [4, 45, 46, 48, 51, 54, 59], "peer": 32, "perceiv": [53, 55, 56, 57], "perform": [30, 31], "period": 67, "pettingzoo": [4, 15, 24], "plot": 20, "point": 46, "polici": [4, 7, 16, 22, 23, 30, 31, 32, 35, 40, 47, 48, 50, 58, 64], "policybehavior": 13, "pose": 36, "posit": [55, 56], "ppo": [45, 54, 61], "pre": 32, "probe": 13, "random": 16, "reach": 36, "refer": 10, "regist": 17, "reinforc": [4, 27, 35], "render": 23, "reward": [8, 18, 30, 39, 46], "runtim": 65, "sa": 32, "sac": [16, 27, 32, 33, 40, 46, 48, 51, 59, 61], "save": [12, 23, 24], "scenario": [7, 13, 28, 33, 35, 36, 60, 65, 66], "sensor": [8, 28], "share": 46, "side": [39, 52, 61], "singl": [6, 24, 31, 63], "social": 18, "space": 62, "speed": [56, 57, 65, 66], "split": [16, 43, 48, 50], "stablebaseline3": 20, "start": [39, 52, 61], "state": [5, 13, 24, 52], "summari": [32, 33, 46], "tabl": 2, "target": 65, "titl": 5, "torchrl": [4, 25], "train": [4, 16, 30, 31, 32, 33, 35, 36, 40, 43, 47, 48, 50, 53, 54, 55, 56, 57, 61, 65, 66], "tutori": 38, "two": 24, "type": 19, "unidirect": 44, "uniform": 66, "uniformli": 39, "us": [4, 22, 35, 43, 48], "util": [9, 20], "vari": 65, "vector": [23, 24], "video": [7, 30], "welcom": 2, "without": [46, 53], "wrapper": [21, 23]}})