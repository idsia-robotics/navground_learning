Search.setIndex({"alltitles": {"A single group": [[8, "A-single-group"]], "Acknowledgement and disclaimer": [[2, "acknowledgement-and-disclaimer"]], "Actions": [[3, "actions"]], "Behavior Cloning": [[3, "behavior-cloning"]], "Behavior Modulation": [[3, "behavior-modulation"]], "Behaviors": [[3, "behaviors"]], "Comparision with HL": [[7, "Comparision-with-HL"]], "Configuration": [[3, "configuration"]], "Contents:": [[0, null]], "Convert to a Gymnasium Env": [[8, "Convert-to-a-Gymnasium-Env"]], "CorridorWithObstacle": [[3, "corridorwithobstacle"]], "DAgger": [[3, "dagger"]], "End-to-end": [[3, "end-to-end"]], "Environments": [[3, "environments"]], "Evaluation": [[3, "evaluation"]], "Experiments": [[3, "experiments"]], "Forward": [[3, "forward"]], "Gymnasium": [[2, "gymnasium"]], "Imitation Learning": [[2, "imitation-learning"], [3, "imitation-learning"]], "Imitation learning": [[6, "Imitation-learning"]], "Imitation learning with Behavior Cloning": [[7, "Imitation-learning-with-Behavior-Cloning"]], "Imitation learning with DAgger": [[7, "Imitation-learning-with-DAgger"]], "Indices and tables": [[0, "indices-and-tables"]], "Inference": [[3, "inference"]], "Installation": [[1, "installation"]], "Introduction": [[2, "introduction"]], "Learning": [[3, "learning"]], "Models": [[3, "models"]], "Multi-agent (Pettingzoo)": [[3, "multi-agent-pettingzoo"]], "Multi-agent RL learning": [[10, "Multi-agent-RL-learning"]], "Multi-agent system": [[3, "multi-agent-system"]], "Navground": [[2, "navground"]], "Navground Gymnasium Environment": [[2, "navground-gymnasium-environment"]], "Navground-Gymnasium integration": [[2, "navground-gymnasium-integration"], [5, "Navground-Gymnasium-integration"]], "Navground-PettingZoo integration": [[8, "Navground-PettingZoo-integration"]], "Navigate along a corridor with one obstacle: learning": [[7, "Navigate-along-a-corridor-with-one-obstacle:-learning"]], "Navigate along a corridor with one obstacle: scenario": [[4, "Navigate-along-a-corridor-with-one-obstacle:-scenario"]], "Null": [[3, "null"]], "Observations": [[3, "observations"]], "PettingZoo": [[2, "pettingzoo"]], "PettingZoo Navground Environment": [[2, "pettingzoo-navground-environment"]], "Probes": [[3, "probes"]], "RL learning": [[9, "RL-learning"]], "Recording data": [[3, "recording-data"]], "Reference": [[3, "reference"]], "Reinforcement Learning": [[2, "reinforcement-learning"]], "Reinforcement learning with SAC": [[7, "Reinforcement-learning-with-SAC"]], "Rendering": [[5, "Rendering"]], "Reward functions": [[3, "reward-functions"]], "Rollouts": [[3, "rollouts"]], "Scenarios": [[3, "scenarios"]], "Single-agent (Gymnasium)": [[3, "single-agent-gymnasium"]], "Social": [[3, "social"]], "Testing in navground": [[6, "Testing-in-navground"]], "Train ML policies in navground": [[2, "train-ml-policies-in-navground"]], "Train a policy using Imitation Learning": [[6, "Train-a-policy-using-Imitation-Learning"]], "Train a policy using RL": [[9, "Train-a-policy-using-RL"]], "Train a policy using RL, part 2: multi-agent environment": [[10, "Train-a-policy-using-RL,-part-2:-multi-agent-environment"]], "Tutorials": [[11, "tutorials"]], "Two groups": [[8, "Two-groups"]], "Use ML policies in navground": [[2, "use-ml-policies-in-navground"]], "Using a policy in Navground": [[5, "Using-a-policy-in-Navground"]], "Vectorized enviroments": [[5, "Vectorized-enviroments"]], "Welcome to navground_learning\u2019s documentation!": [[0, "welcome-to-navground-learning-s-documentation"]]}, "docnames": ["index", "installation", "introduction", "reference", "tutorials/CorridorScenario", "tutorials/Gym", "tutorials/IL", "tutorials/LearningCorridor", "tutorials/PettingZoo", "tutorials/RL", "tutorials/RL-MA", "tutorials/index"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["index.rst", "installation.rst", "introduction.rst", "reference.rst", "tutorials/CorridorScenario.ipynb", "tutorials/Gym.ipynb", "tutorials/IL.ipynb", "tutorials/LearningCorridor.ipynb", "tutorials/PettingZoo.ipynb", "tutorials/RL.ipynb", "tutorials/RL-MA.ipynb", "tutorials/index.rst"], "indexentries": {"clone() (navground_learning.behaviors.policybehavior method)": [[3, "navground_learning.behaviors.PolicyBehavior.clone", false]], "clone_behavior() (navground_learning.behaviors.policybehavior class method)": [[3, "navground_learning.behaviors.PolicyBehavior.clone_behavior", false]], "collect_runs() (navground_learning.il.bc.trainer method)": [[3, "navground_learning.il.bc.Trainer.collect_runs", false]], "controlactionconfig (class in navground_learning)": [[3, "navground_learning.ControlActionConfig", false]], "corridorwithobstacle (class in navground_learning.scenarios)": [[3, "navground_learning.scenarios.CorridorWithObstacle", false]], "deterministic (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.deterministic", false]], "dtype (navground_learning.probes.rewardprobe attribute)": [[3, "navground_learning.probes.RewardProbe.dtype", false]], "evaluate_expert() (in module navground_learning.evaluate)": [[3, "navground_learning.evaluate.evaluate_expert", false]], "evaluationscenario (class in navground_learning.scenarios)": [[3, "navground_learning.scenarios.EvaluationScenario", false]], "fix_orientation (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.fix_orientation", false]], "flat (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.flat", false]], "forwardscenario (class in navground_learning.scenarios)": [[3, "navground_learning.scenarios.ForwardScenario", false]], "get_trajectories_from_experiment() (in module navground_learning.rollout)": [[3, "navground_learning.rollout.get_trajectories_from_experiment", false]], "get_trajectories_from_run() (in module navground_learning.rollout)": [[3, "navground_learning.rollout.get_trajectories_from_run", false]], "groupconfig (class in navground_learning)": [[3, "navground_learning.GroupConfig", false]], "gymprobe (class in navground_learning.probes)": [[3, "navground_learning.probes.GymProbe", false]], "history (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.history", false]], "include_radius (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_radius", false]], "include_target_direction (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_target_direction", false]], "include_target_distance (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_target_distance", false]], "include_velocity (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_velocity", false]], "make_behavior() (navground_learning.il.bc.trainer method)": [[3, "navground_learning.il.bc.Trainer.make_behavior", false]], "make_behavior() (navground_learning.il.dagger.trainer method)": [[3, "navground_learning.il.dagger.Trainer.make_behavior", false]], "make_experiment() (in module navground_learning.evaluate)": [[3, "navground_learning.evaluate.make_experiment", false]], "make_experiment_with_env() (in module navground_learning.evaluate)": [[3, "navground_learning.evaluate.make_experiment_with_env", false]], "max_acceleration (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.max_acceleration", false]], "max_angular_acceleration (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.max_angular_acceleration", false]], "modulationactionconfig (class in navground_learning)": [[3, "navground_learning.ModulationActionConfig", false]], "navgroundenv (class in navground_learning.env)": [[3, "navground_learning.env.NavgroundEnv", false]], "nullreward() (in module navground_learning.reward)": [[3, "navground_learning.reward.NullReward", false]], "observationconfig (class in navground_learning)": [[3, "navground_learning.ObservationConfig", false]], "orderinvariantcombinedextractor (class in navground_learning.policies)": [[3, "navground_learning.policies.OrderInvariantCombinedExtractor", false]], "parallel_env() (in module navground_learning.env.pz)": [[3, "navground_learning.env.pz.parallel_env", false]], "policy (navground_learning.il.bc.trainer property)": [[3, "navground_learning.il.bc.Trainer.policy", false]], "policy (navground_learning.il.dagger.trainer property)": [[3, "navground_learning.il.dagger.Trainer.policy", false]], "policy_path (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.policy_path", false]], "policybehavior (class in navground_learning.behaviors)": [[3, "navground_learning.behaviors.PolicyBehavior", false]], "rewardprobe (class in navground_learning.probes)": [[3, "navground_learning.probes.RewardProbe", false]], "save() (navground_learning.il.bc.trainer method)": [[3, "navground_learning.il.bc.Trainer.save", false]], "save() (navground_learning.il.dagger.trainer method)": [[3, "navground_learning.il.dagger.Trainer.save", false]], "shared_parallel_env() (in module navground_learning.env.pz)": [[3, "navground_learning.env.pz.shared_parallel_env", false]], "socialreward() (in module navground_learning.reward)": [[3, "navground_learning.reward.SocialReward", false]], "space (navground_learning.controlactionconfig property)": [[3, "navground_learning.ControlActionConfig.space", false]], "train() (navground_learning.il.bc.trainer method)": [[3, "navground_learning.il.bc.Trainer.train", false]], "train() (navground_learning.il.dagger.trainer method)": [[3, "navground_learning.il.dagger.Trainer.train", false]], "trainer (class in navground_learning.il.bc)": [[3, "navground_learning.il.bc.Trainer", false]], "trainer (class in navground_learning.il.dagger)": [[3, "navground_learning.il.dagger.Trainer", false]], "use_acceleration_action (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.use_acceleration_action", false]], "use_wheels (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.use_wheels", false]], "worldconfig (class in navground_learning)": [[3, "navground_learning.WorldConfig", false]]}, "objects": {"navground_learning": [[3, 0, 1, "", "ControlActionConfig"], [3, 0, 1, "", "GroupConfig"], [3, 0, 1, "", "ModulationActionConfig"], [3, 0, 1, "", "ObservationConfig"], [3, 0, 1, "", "WorldConfig"]], "navground_learning.ControlActionConfig": [[3, 1, 1, "", "space"]], "navground_learning.behaviors": [[3, 0, 1, "", "PolicyBehavior"]], "navground_learning.behaviors.PolicyBehavior": [[3, 2, 1, "", "clone"], [3, 2, 1, "", "clone_behavior"], [3, 1, 1, "", "deterministic"], [3, 1, 1, "", "fix_orientation"], [3, 1, 1, "", "flat"], [3, 1, 1, "", "history"], [3, 1, 1, "", "include_radius"], [3, 1, 1, "", "include_target_direction"], [3, 1, 1, "", "include_target_distance"], [3, 1, 1, "", "include_velocity"], [3, 1, 1, "", "max_acceleration"], [3, 1, 1, "", "max_angular_acceleration"], [3, 1, 1, "", "policy_path"], [3, 1, 1, "", "use_acceleration_action"], [3, 1, 1, "", "use_wheels"]], "navground_learning.env": [[3, 0, 1, "", "NavgroundEnv"]], "navground_learning.env.pz": [[3, 3, 1, "", "parallel_env"], [3, 3, 1, "", "shared_parallel_env"]], "navground_learning.evaluate": [[3, 3, 1, "", "evaluate_expert"], [3, 3, 1, "", "make_experiment"], [3, 3, 1, "", "make_experiment_with_env"]], "navground_learning.il.bc": [[3, 0, 1, "", "Trainer"]], "navground_learning.il.bc.Trainer": [[3, 2, 1, "", "collect_runs"], [3, 2, 1, "", "make_behavior"], [3, 1, 1, "", "policy"], [3, 2, 1, "", "save"], [3, 2, 1, "", "train"]], "navground_learning.il.dagger": [[3, 0, 1, "", "Trainer"]], "navground_learning.il.dagger.Trainer": [[3, 2, 1, "", "make_behavior"], [3, 1, 1, "", "policy"], [3, 2, 1, "", "save"], [3, 2, 1, "", "train"]], "navground_learning.policies": [[3, 0, 1, "", "OrderInvariantCombinedExtractor"]], "navground_learning.probes": [[3, 0, 1, "", "GymProbe"], [3, 0, 1, "", "RewardProbe"]], "navground_learning.probes.RewardProbe": [[3, 4, 1, "", "dtype"]], "navground_learning.reward": [[3, 3, 1, "", "NullReward"], [3, 3, 1, "", "SocialReward"]], "navground_learning.rollout": [[3, 3, 1, "", "get_trajectories_from_experiment"], [3, 3, 1, "", "get_trajectories_from_run"]], "navground_learning.scenarios": [[3, 0, 1, "", "CorridorWithObstacle"], [3, 0, 1, "", "EvaluationScenario"], [3, 0, 1, "", "ForwardScenario"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "property", "Python property"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "objtypes": {"0": "py:class", "1": "py:property", "2": "py:method", "3": "py:function", "4": "py:attribute"}, "terms": {"": [2, 3, 4, 5, 6, 8, 9, 10], "0": [2, 3, 4, 5, 6, 7, 8, 9, 10], "00": [5, 8], "000": 4, "000000": 8, "00000000e": [5, 8], "001": 6, "00284": 6, "004": 9, "00471158": 5, "01": 2, "017": 8, "02": [5, 6, 7, 8, 9, 10], "026401288000002": 7, "0369845": 7, "04": [4, 7, 9], "04048300899996": 7, "05": [4, 7, 9], "073": 8, "075": 9, "08": [4, 7], "094": [4, 5, 6, 7, 8, 9, 10], "0f": [7, 9, 10], "1": [2, 3, 4, 5, 6, 7, 8, 9, 10], "10": [3, 4, 5, 6, 7, 8, 9, 10], "100": [2, 5, 6, 8, 10], "1000": [2, 3, 4, 5, 7, 8], "100000": [2, 7, 8], "10000000000000001": 5, "100_000": [7, 9], "100k": 7, "101070028": 2, "10201398": [5, 8], "108": 9, "11": [5, 6, 7, 8, 9, 10], "111": 6, "1121034": [5, 8], "113": 6, "12": [4, 5, 6, 7, 8, 9, 10], "120": [5, 6], "1200": 5, "120000": 8, "123": 7, "128": 7, "129": 6, "13": [5, 6, 7, 8, 9, 10], "14": [5, 6, 7, 8, 9, 10], "15": [4, 5, 6, 7, 8, 9], "153": 10, "158": 4, "16": [4, 5, 6, 7, 8], "17": [4, 5, 7, 8], "173982": 7, "18": [4, 5, 6, 7, 8], "1800": 10, "19": [4, 5, 6, 7, 8, 10], "190": 6, "193": 9, "19885384": [5, 8], "1e": 7, "2": [0, 4, 5, 6, 7, 8, 11], "20": [4, 5, 6, 7, 8, 9, 10], "200": 4, "20000": [6, 9], "2021": 2, "20867327": [5, 8], "21": [4, 5, 7], "22": [4, 5, 7, 10], "220": 9, "222": 4, "222684": 7, "22419791": [5, 8], "23": [4, 5, 7], "24": [4, 5, 7, 10], "2400": 9, "242": 8, "243": 10, "246": 5, "25": [4, 5, 6, 7, 8, 9, 10], "255": [3, 5], "256": [3, 10], "258": 10, "259": 10, "26": [4, 5, 7, 10], "264": 10, "266": 10, "27": [4, 5, 7], "272681": 7, "275": 10, "276": 10, "28": [4, 5, 7, 10], "28052899347895": 4, "28317614": [5, 8], "29": [4, 5, 7, 10], "2_000_000": 10, "2wdiff": [4, 5, 6, 7, 8, 9, 10], "3": [3, 4, 5, 6, 7, 8, 10], "30": [4, 5, 6, 7, 9, 10], "300": [4, 5, 6], "31": [5, 10], "311": 7, "314": 10, "315": 10, "32": [4, 5, 6, 7], "327": 7, "32967995": [5, 8], "33": [4, 5, 10], "331": 10, "334": 10, "335068": 7, "337": 7, "34": 5, "35": 5, "355": 10, "35694126": [5, 8], "359": 7, "36": 5, "360": 4, "37": 5, "38": [5, 10], "387": 10, "388": 10, "39": [4, 5, 7, 8, 10], "392": 10, "393": 10, "3d": 2, "3f": [5, 6, 8, 9, 10], "4": [4, 5, 6, 7, 8, 9, 10], "40": [4, 5, 7], "400": [5, 9, 10], "408": 10, "41": [5, 7], "415": 7, "41599925e": [5, 8], "42": 10, "433": 10, "433805959060551": 4, "441": 10, "442": 10, "449": 10, "468": 4, "48": 4, "496797": 7, "5": [3, 4, 5, 6, 7, 8, 9, 10], "50": 7, "500": 7, "50000": 7, "50433907": [5, 8], "512": 10, "53": 5, "553191": 8, "5531914893617018": 5, "553191489361702": 5, "56413084": [5, 8], "573": 10, "599": [5, 8], "5x": 7, "6": [4, 5, 6, 7, 8, 9, 10], "60": [5, 6, 8, 9, 10], "600": [5, 9, 10], "60000": 7, "601806": 7, "602": 10, "621": 10, "63": 7, "640": 5, "65": 4, "670": 7, "67285531": [5, 8], "68": 7, "683": 9, "7": [4, 5, 6, 7, 8, 9, 10], "717": 6, "724690000000001": 7, "75": 7, "750": [5, 7], "8": [3, 4, 5, 6, 7, 8, 9, 10], "8002": 5, "809": 10, "82594673": [5, 8], "833333333333336": 4, "84": 6, "876535": 7, "9": [5, 6, 7, 8, 9, 10], "94": 5, "949": 5, "957440417": 7, "9665543284519917": 4, "9682783": 5, "98": 7, "9853547": 5, "995": 6, "997": 5, "99745506": 5, "999": 9, "A": [3, 4, 10, 11], "As": [5, 6, 9], "At": 2, "By": 2, "For": [2, 5, 8], "If": [2, 3, 8], "In": [2, 4, 5, 6, 7, 8, 9, 10], "It": [2, 3, 7, 10], "One": 10, "The": [2, 3, 4, 5, 6, 8], "Then": [1, 6], "There": [2, 5], "These": 5, "To": [2, 5], "_": [2, 4, 5, 6, 7], "__init__": 5, "_possible_ag": 8, "_reward": 5, "abc": 3, "about": [4, 5, 7], "abov": 4, "acc": 4, "acceler": [3, 4, 8], "acknowledg": 0, "act": [2, 4, 8], "action": [2, 4, 5, 6, 7, 8, 9, 10], "action_config": [2, 3, 5, 6, 7, 8, 9, 10], "action_spac": [5, 6, 8], "actionconfig": [2, 3], "activ": 3, "activation_fn": 3, "actual": [4, 5], "actuat": [2, 5], "add": 3, "add_patch": 4, "add_record_prob": 5, "addit": [3, 5], "aec": 2, "after": [3, 4, 5, 6, 8, 9], "agent": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11], "agent_color": 7, "agent_index": [3, 6], "agent_indic": [3, 8, 10], "agent_margin": [5, 6, 8, 9, 10], "agreement": 2, "ai": [2, 6], "algorithm": [2, 3, 6, 7], "alia": 3, "aliv": 2, "all": [2, 3, 4, 5, 8, 10], "all_reward": [5, 8], "almost": [4, 9], "along": [0, 11], "alpha": [3, 4, 5, 6, 7, 9, 10], "alreadi": [3, 5], "also": [2, 5, 7, 8, 10], "alwai": 4, "among": [2, 8, 9, 10], "an": [2, 3, 4, 5, 6, 7, 8, 10], "angular": [3, 4, 5], "angular_spe": 3, "ani": [2, 3, 5], "anymor": 2, "anywai": 4, "api": [2, 5, 8], "append": [5, 8], "appli": [2, 3, 5, 7], "ar": [2, 3, 4, 5, 6, 7, 8, 10], "area": 3, "arg": 3, "argmin": 4, "argument": [3, 7], "around": 5, "arrai": [5, 8], "asarrai": [4, 5, 6, 9, 10], "ask": 6, "assign": 5, "assum": 3, "astyp": 5, "atari": 2, "audio": [4, 5, 6, 9, 10], "author": 2, "automat": 5, "autonotebook": 7, "autoreset": 5, "avail": [2, 5], "avoid": [3, 4], "ax": [4, 5, 6, 9, 10], "axi": [4, 5], "b": 3, "barrier_angl": [4, 7], "base": [2, 3, 4, 5, 8], "base_class": 8, "basecallback": 3, "basefeaturesextractor": 3, "baseline3": 1, "baselines3": [1, 2, 5], "basic": 5, "batch": 6, "batch_siz": [6, 7], "bbox_to_anchor": 7, "bc": [2, 3, 6, 7], "bc_kwarg": [3, 7], "bc_reward": 7, "bc_train_kwarg": 7, "bc_trainer": [6, 7], "been": [2, 10], "befor": [3, 6, 8, 9, 10], "begin": 4, "behavior": [2, 4, 5, 6, 8, 9, 10, 11], "behaviorclon": 6, "below": 2, "benchmark": 5, "beta": [3, 5], "better": [6, 7, 9, 10], "between": [2, 5, 8], "bin": [4, 6, 7, 9, 10], "bitwise_or": 8, "black": [5, 6, 9, 10], "blue": 7, "bodi": [3, 4], "bool": 3, "both": [9, 10], "bottom": 4, "bound": [3, 4, 5, 6, 7, 8, 9, 10], "boundari": [4, 7], "boundary_dist": 4, "box": [3, 5, 8], "break": 2, "browser": [4, 5, 6, 9, 10], "bufferdescript": 5, "build": [1, 2, 3], "built": 3, "c": [2, 4], "call": [2, 5], "callabl": [3, 7], "callback": 3, "can": [2, 4, 5, 7, 8], "cannot": [4, 7], "case": [4, 5, 7, 8], "categor": 5, "center": [2, 6], "chang": 4, "check": [2, 3, 5, 6], "circl": 4, "cit": 6, "cl4": 2, "class": [2, 3, 5], "classmethod": 3, "clean": 6, "clone": [2, 6, 11], "clone_behavior": [2, 3, 5, 6], "close": [2, 5], "cm": 4, "cnn": 3, "cnn_output_dim": 3, "coher": 5, "col": 7, "colcon": 1, "collect": [3, 5, 6, 7, 8, 9, 10], "collect_run": [3, 6, 7], "collis": 2, "color": [4, 5, 6, 7, 8, 9, 10], "colorbar": 4, "column": 7, "combin": [3, 4, 7], "combinedextractor": 3, "command": [2, 3, 4, 8], "commiss": 2, "common": [5, 6, 7, 8, 9, 10], "compar": [5, 7, 8], "comparis": 11, "compat": [2, 6], "complex": 8, "compos": [5, 10], "comput": [2, 4, 5, 8, 9], "concat_vec_envs_v1": 8, "concaten": [2, 3], "config": [3, 4, 5, 6, 8, 10], "configur": [0, 2, 5, 7, 8, 9, 10], "conform": 2, "consid": 8, "constant": [4, 5], "constraint": 4, "construct": 3, "constructor": 3, "consum": 3, "contain": [2, 5, 8], "control": [2, 3, 4, 5, 8, 9, 10], "control_period": [4, 5, 6, 7, 8, 9, 10], "controlactionconfig": [2, 3, 5, 6, 7, 8, 9, 10], "convert": [2, 11], "copi": 3, "core": [2, 4, 5, 7], "corridor": [0, 11], "corridor_with_obstacl": [4, 7], "corridor_with_obstacle_v2": 7, "corridorwithobstacl": [4, 7], "could": 6, "cover": 5, "creat": 3, "critical_safety_margin": 3, "cross": [5, 6, 8, 9, 10], "csv": [7, 9, 10], "cum_rew": 4, "current": 3, "custom": 2, "cycl": [2, 5], "d": [3, 5], "dagger": [2, 6, 11], "dagger_kwarg": 3, "dagger_reward": 7, "dagger_train": 7, "data": [0, 4, 5, 6, 7], "dataset": [3, 5, 7], "decent": 7, "decis": 2, "def": [4, 5, 6, 7, 9, 10], "default": [3, 5], "default_rng": [4, 6, 7], "default_social_margin": 3, "defin": [5, 6, 7, 8, 9, 10], "demand": 3, "demonstr": 6, "densiti": [4, 5, 6, 7, 9, 10], "depend": [1, 3, 9], "deprec": [5, 7], "descreas": 10, "describ": 3, "descript": 5, "desir": 5, "determinist": [2, 3, 5, 10], "deterministic_polici": 7, "dev": [4, 5, 7], "df": [7, 9, 10], "dict": [2, 3, 5, 8], "dict_kei": 4, "differ": [2, 5, 8, 10], "differnet": 8, "dimens": 3, "direclti": 5, "direct": [3, 4], "directli": 2, "directori": 3, "disabl": 3, "disable_logg": 5, "disable_progress_bar": 7, "disc": [4, 5, 6, 7, 8, 9, 10], "disclaim": 0, "discontinu": 2, "discuss": 4, "displai": [5, 7], "display_in_notebook": 4, "display_run": [6, 9, 10], "display_video": [4, 5, 6], "display_video_from_run": [9, 10], "display_width": [4, 5, 6, 9, 10], "distanc": [2, 3, 4], "distribut": [2, 4, 6, 9, 10], "divers": 2, "dlr": 2, "do": [2, 4, 7], "doc": [2, 5], "doe": [4, 5, 6], "doesn": [4, 5, 6, 9, 10], "dof": [3, 5], "don": [2, 5], "done": [4, 5, 8], "dtype": [3, 5, 8], "dump": [3, 5], "durat": [4, 5, 6, 7, 9, 10], "dure": [4, 7, 10], "e": [2, 3, 4, 5, 8, 10], "each": [3, 4, 8], "effect": [3, 10], "efficaci": 5, "ego_": 5, "ego_angular_spe": 4, "ego_target_direct": [4, 5, 8], "ego_target_dist": [5, 8], "ego_veloc": 4, "element": 5, "els": 10, "end": 2, "enlarg": 4, "enough": 7, "ent_loss": 6, "ent_weight": 7, "entir": 5, "entropi": 6, "enumer": [5, 7], "env": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11], "env_kwarg": 5, "env_make_kwarg": [4, 6], "env_util": 5, "enviro": [3, 8, 10, 11], "environ": [0, 5, 6, 7, 8, 11], "ep_rew_mean": [7, 9, 10], "episod": [5, 6, 9], "episode_trigg": 5, "epoch": [6, 7], "equal": [4, 5], "especiali": 7, "estim": [2, 3], "eta": [4, 5, 6, 7, 8, 9, 10], "eu": 2, "european": 2, "evalu": [2, 6, 7, 9, 10], "evaluate_expert": [3, 7, 9], "evaluate_my_polici": 2, "evaluate_polici": [6, 7, 9], "evaluationscenario": 3, "even": [4, 5, 7, 8, 10], "event": 4, "everi": 3, "everyth": 2, "exampl": 2, "exchang": 2, "exclude_info": 4, "excus": 4, "exist": 5, "exit": 3, "exp": [4, 7], "expect": [2, 3, 5, 6, 10], "experi": [4, 6, 9, 10], "experimentalrun": [3, 5], "expert": [4, 6, 7], "explod": 3, "explor": 9, "expos": [3, 5], "express": 2, "extend": 2, "extens": 2, "extractor": 3, "f": [5, 6, 7, 8, 9, 10], "fact": [2, 4], "factor": [3, 4, 5, 6, 9, 10], "factori": 3, "fail": 7, "fals": [3, 4, 5, 6, 7, 8, 9, 10], "far": 6, "farama": 2, "featur": [2, 3], "fed": 3, "fenc": 3, "few": [4, 6], "fig": [4, 5, 7], "figsiz": [4, 5, 7], "file": 3, "filter_kei": 3, "filterwarn": [6, 9, 10], "final": 4, "first": [2, 4, 5, 6, 8], "first_group": 8, "fix": 7, "fix_orient": [3, 5], "flat": [3, 4, 5, 7, 9, 10], "flatten": [3, 4, 5, 6, 9, 10], "flatten_trajectori": [4, 6], "float": [3, 5], "float64": [3, 5, 8], "focu": 8, "folder": 5, "follow": [5, 6, 7, 8], "forc": 3, "forwardscenario": 3, "foundat": 2, "frame": [4, 8], "from": [2, 3, 4, 5, 6, 7, 8, 9, 10], "fromarrai": 5, "full": 4, "fun": 5, "function": [0, 2, 6, 7, 9, 10], "fund": 2, "g": [4, 8], "game": 2, "gap": 4, "gca": [6, 9, 10], "gener": [2, 3, 5, 8, 10], "get": [2, 3, 4, 5, 7], "get_cmd_from_act": 8, "get_dir": 7, "get_elements_at": 10, "get_env": 9, "get_expert_reward": 4, "get_imag": 5, "get_record": [6, 9, 10], "get_shap": 5, "get_trajectories_from_experi": 3, "get_trajectories_from_run": 3, "get_wrapper_attr": 7, "goal": 5, "goe": 4, "gold": [4, 7], "good": [4, 7], "grai": [5, 6, 8, 9, 10], "grant": 2, "green": 7, "group": [2, 3, 4, 5, 6, 7, 9, 10, 11], "groupconfig": [3, 8], "guzzi": [5, 7], "gym": [2, 3, 4, 5, 6, 7, 8, 9, 10], "gymagentconfig": [3, 4], "gymanasium": 2, "gymansium": 5, "gymnasium": [0, 1, 4, 6, 7, 9, 10, 11], "gymprob": 3, "h": 2, "ha": [2, 3, 4, 5, 8, 10], "half": 10, "happen": 4, "has_wheel": [3, 5], "have": [2, 4, 5, 8, 9, 10], "head": 5, "height": 5, "held": 2, "helper": 2, "hexbin": 4, "high": 5, "hist": [4, 5, 6, 7, 9, 10], "histori": [3, 5], "hl": [4, 5, 6, 8, 9, 10, 11], "hl_reward": [7, 9], "hl_reward_mean": 9, "hl_reward_std_dev": 9, "horizon": [2, 4, 5, 6, 7, 8, 9, 10], "how": [2, 3, 5, 6], "howev": 2, "html5": [4, 5, 6, 9, 10], "human": [2, 3, 5, 6], "i": [2, 3, 4, 5, 6, 7, 8, 10], "id": 3, "identifi": 2, "ignor": [6, 7, 9, 10], "il": [2, 3, 6, 7], "im": 5, "imag": [2, 3, 5], "image_for_world": 3, "imit": [0, 1, 4, 5, 8, 11], "implement": [2, 6], "import": [2, 3, 4, 5, 6, 7, 8, 9, 10], "improv": 6, "imshow": 5, "includ": [2, 3], "include_angular_spe": [3, 4, 5, 7, 9, 10], "include_radiu": [3, 5], "include_target_direct": [3, 5], "include_target_dist": [3, 4, 5, 7, 8, 9, 10], "include_valid": [4, 7], "include_veloc": [3, 4, 5, 7, 9, 10], "incur": 4, "index": [0, 2, 3], "indic": [3, 8, 10], "individu": [3, 5, 8], "inf": [3, 5], "infer": 0, "info": [2, 4, 5, 8], "inherit": 5, "init": 3, "init_ag": 6, "init_world": [2, 4, 5, 6], "initi": [2, 3, 4, 5], "input": [3, 4], "insid": [2, 5], "instal": 0, "instanc": [1, 2, 5, 6, 8], "instanti": 2, "instead": [2, 3, 5, 8, 10], "instruct": 1, "int": [2, 3, 4], "int8": 5, "integr": [0, 11], "interact": 2, "interest": 6, "interfac": [2, 3], "interpret": 3, "intiti": 6, "introduct": 0, "introductori": [6, 9], "invari": 3, "ipython": 5, "item": [2, 3, 8], "iter": 2, "its": [2, 4, 5, 10], "jerom": [5, 7], "jupyt": 5, "just": [4, 5, 6], "k": [4, 5], "kei": [3, 4], "kinemat": [2, 3, 4, 5, 6, 7, 8, 9, 10], "kwarg": [3, 9, 10], "l2_loss": 6, "l2_norm": 6, "l2_weight": 7, "label": [4, 6, 7, 9, 10], "labelleft": [6, 9, 10], "lambda": [4, 5, 6, 7], "larg": 7, "larger": 3, "later": [4, 10], "layer": [3, 7], "learn": [0, 1, 4, 5, 8, 11], "least": 4, "left": 4, "legend": [6, 7, 9, 10], "len": [4, 5, 8, 10], "length": [3, 4, 7], "less": 7, "let": [4, 5, 6, 8, 9, 10], "lib": [5, 7], "librari": 2, "lidar": 8, "like": [2, 4, 5, 6, 8, 9, 10], "linear": [4, 5], "link": 2, "linspac": 7, "list": [3, 8], "littl": 4, "load": [3, 5, 8, 10], "load_scenario": [2, 3, 4, 5, 6, 7, 8, 9, 10], "load_state_estim": [4, 5, 6, 7, 8, 9, 10], "log": [3, 4, 7, 9, 10], "log_directori": 7, "log_fold": [7, 9, 10], "log_format": 7, "log_interv": [7, 10], "log_rollouts_n_episod": 7, "log_rollouts_venv": 7, "logger": [5, 7, 9, 10], "longer": 7, "look": [2, 4, 8, 9, 10], "loop": [4, 5, 8], "loss": 6, "low": 5, "lowest": 4, "m": 4, "ma": [9, 10], "ma_model": 10, "machin": [2, 5, 8], "mai": [2, 4, 8], "major": 4, "make": [2, 3, 4, 5, 6, 7, 9, 10], "make_behavior": [2, 3], "make_experi": 3, "make_experiment_with_env": [3, 6, 7, 9, 10], "make_sample_until": [4, 6], "make_vec": 5, "make_vec_env": [4, 5, 6], "make_venv": [7, 10], "manag": 4, "mani": [2, 3, 8, 10], "manual": 5, "map": [3, 5, 8], "margin": [4, 5], "markov": 2, "mask": 3, "matplotlib": [4, 5, 6, 7, 9, 10], "max": [4, 7], "max_acceler": [3, 4, 5, 7, 8, 9, 10], "max_angular_acceler": [3, 4, 5, 7, 8, 9, 10], "max_angular_spe": [3, 5], "max_dur": [3, 4, 5, 6, 7, 8, 9, 10], "max_episode_step": [2, 5], "max_i": [4, 7], "max_number_of_ag": 3, "max_radiu": [3, 4, 5, 6, 7, 8, 9, 10], "max_spe": [3, 4, 5, 6, 7, 8, 9, 10], "max_target_dist": [3, 5], "maxim": [3, 5], "mdp": 2, "mean": [4, 5, 7, 8, 9, 10], "measur": 4, "median": [4, 7], "merg": 1, "metadata": 5, "method": 3, "middl": 5, "min": [4, 7], "min_episod": [4, 6], "min_i": [4, 7], "min_radiu": [3, 4, 7], "min_timestep": [4, 6], "miss": 5, "ml": [0, 3, 7, 10], "mlp": [3, 7], "mlppolici": [2, 7, 9, 10], "mode": 3, "model": [0, 2, 7, 9], "modul": [0, 5], "modulationactionconfig": [2, 3], "more": [2, 4, 6, 7, 8, 10], "moreov": 2, "most": [2, 4, 5], "move": [4, 5, 8, 10], "mp4": 5, "multi": [0, 1, 2, 8, 11], "multiagentnavgroundenv": [2, 3], "multibinari": [5, 8], "multipl": [2, 8, 10], "must": 3, "my_sensor": 2, "my_trained_polici": 2, "myenviro": 2, "mymultiagentenviro": 2, "myscenario": 2, "mysensor": 2, "n": [5, 8], "n_env": [3, 4, 5, 6, 7], "n_epoch": [2, 6, 7], "naground": 5, "name_prefix": 5, "navground": [0, 3, 4, 7, 9, 10, 11], "navground_act": [4, 5, 8], "navground_learn": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "navground_sim": 1, "navgroundbaseenv": [2, 3], "navgroundenv": [2, 3, 5, 6, 9], "navig": [0, 2, 3, 9, 11], "ncol": [5, 7], "ndarrai": [2, 3], "nearest": [4, 5], "necessarili": 2, "need": [2, 3, 5, 6], "neglogp": 6, "neighbor": [5, 10], "neither": 2, "nest_asyncio": 5, "net_arch": [3, 7], "network": 3, "neuron": 7, "new": [2, 3, 5, 8, 10], "nn": 3, "none": [2, 3, 4, 5, 6, 7, 9, 10], "nonetheless": 2, "nor": 2, "normal": [3, 5], "normalized_imag": 3, "note": [9, 10], "notebook": [4, 5, 6, 7, 8, 9, 10], "notebook_view": 5, "noth": 2, "notna": 7, "now": [5, 8, 10], "np": [4, 5, 6, 7, 8, 9, 10], "nullreward": 3, "num_cpu": 8, "num_env": [5, 7, 8], "number": [3, 4, 5, 6, 7, 8, 9, 10], "number_of_ag": 9, "number_of_run": [4, 6, 7, 9, 10], "numpi": [2, 4, 5, 6, 7, 8, 9, 10], "o": 4, "ob": [4, 5], "object": 3, "observ": [2, 5, 6, 7, 8, 9, 10], "observart": 9, "observation_config": [2, 3, 5, 6, 7, 8, 9, 10], "observation_spac": [3, 5, 6, 8], "observationconfig": [2, 3, 5, 6, 7, 8, 9, 10], "obstacl": [0, 11], "obtacl": 4, "off": 5, "offer": 2, "offlin": 5, "older": 5, "onc": [2, 5], "one": [0, 2, 5, 6, 10, 11], "ones": 8, "onli": [2, 3, 4, 5, 6], "onlin": 5, "open": 5, "open_html": 5, "openai": 2, "opinion": 2, "opposit": 5, "optimal_angular_spe": 5, "optimal_spe": [4, 5, 6, 7, 8, 9, 10], "option": [1, 2, 3], "orang": 7, "order": 3, "order_invariant_kei": 3, "orderinvariantcombinedextractor": 3, "orient": [2, 3], "origin": [2, 3, 5, 6, 8, 9, 10], "original_indic": 10, "other": [2, 3, 4, 5, 7, 8, 9], "otherwis": 3, "our": [4, 5], "output": [2, 3, 4, 5, 8], "over": 10, "overwrit": 5, "own": [3, 4, 5], "p": 4, "p_straight": 4, "packag": [1, 2, 5, 7], "page": 0, "pair": [5, 9, 10], "panda": [7, 9, 10], "paral": 3, "parallel": [2, 3, 4, 6, 7, 10], "parallel_env": [2, 3, 8], "param": 3, "paramet": [2, 3, 5], "part": [0, 2, 8, 11], "partial": 2, "particular": [2, 8], "pass": [2, 3, 4], "path": [3, 7], "pathlib": 7, "pd": [7, 9, 10], "peer": 10, "penal": [4, 5, 7], "per": [4, 7], "perceiv": 4, "perfect": 6, "perform": [2, 6, 7, 9, 10], "pettingzoo": [0, 1, 11], "pettingzoo_env_to_vec_env_v1": 8, "physic": 2, "pi": 4, "pick": 4, "pil": 5, "pip": 1, "place": 5, "pleas": 9, "plot": [4, 5, 6, 7, 9, 10], "plot_comparison_test_run": 7, "plot_reward": [9, 10], "plot_run": 7, "plot_run_reward": 6, "plot_test_run": 7, "plt": [4, 5, 6, 7, 9, 10], "point": 4, "polici": [0, 3, 7, 8, 11], "policy_indic": 10, "policy_kwarg": 7, "policy_path": [3, 5], "policybehavior": [2, 3, 5, 6, 7, 9], "port": 5, "pose": [4, 5, 7, 9, 10], "posit": [3, 4, 5, 8], "possibl": 4, "possible_ag": 8, "post_wrapp": [4, 6], "predefin": 2, "predict": [5, 8], "prefer": 2, "prevent": 2, "previou": 6, "print": [3, 5, 6, 7, 8, 9, 10], "print_reward": 9, "pro": 2, "prob_true_act": 6, "probabl": [4, 6, 7, 9, 10], "probe": 5, "proce": 6, "process": [2, 3, 5], "produc": 3, "progress": [7, 9, 10], "progress_bar": [2, 6, 7, 9, 10], "project": 2, "properti": 3, "provid": [2, 6, 7], "push": 5, "py": [5, 7], "pyplot": [4, 5, 6, 7, 9, 10], "pyplot_help": 7, "python": 2, "python3": [5, 7], "pz": [2, 3, 8, 10], "pz_util": 10, "qualiti": 4, "quantil": 7, "queue": 3, "quit": [4, 7], "r": [5, 10], "rad": 4, "radii": 5, "radiu": [3, 4, 5, 6, 7, 8, 9, 10], "random": [2, 3, 4, 5, 6, 7, 8], "randomli": [4, 6], "randompolici": [5, 8], "rang": [2, 4, 5, 6, 7, 8, 9, 10], "rare": 4, "read": [4, 5], "read_csv": [7, 9, 10], "real": [3, 5], "realtim": 3, "realtime_factor": [3, 5], "recent": 3, "record": [0, 5], "record_config": [4, 5, 7, 9, 10], "record_video": 5, "recordconfig": 5, "recordprob": 5, "recordvideo": 5, "red": [5, 6, 7, 9, 10], "reduct": 3, "refer": [0, 9], "reflect": 2, "regist": 3, "reinforc": [1, 11], "rel": [4, 8], "relat": 3, "relev": 3, "relu": 3, "remind": 7, "remov": [3, 7], "removed_kei": 3, "render": [3, 8, 11], "render_fp": 5, "render_kwarg": [3, 5], "render_mod": [3, 5, 6, 9, 10], "replac": [2, 5], "replic": 3, "replicated_kei": 3, "repres": 8, "represent": 3, "requir": [1, 5, 9], "reset": [2, 4, 5, 8], "reset_info": 5, "reshap": 4, "resiz": 5, "resolut": 8, "resolv": 2, "respect": 5, "respons": 2, "rest": 2, "result": [2, 6], "return": [2, 3, 4, 5, 6, 8, 9, 10], "return_episode_reward": 7, "return_mean": 7, "rew": 4, "reward": [0, 2, 4, 5, 6, 7, 8, 9, 10], "reward_mean": [6, 9], "reward_std_dev": [6, 9], "rewardprob": [3, 5], "rexasi": 2, "rgb_arrai": [3, 5, 6, 9, 10], "right": 4, "rl": [0, 2, 7, 11], "rm": 2, "rng": [4, 6, 7], "ro": 5, "robot": 2, "robust": 10, "rollout": [4, 6, 7, 9, 10], "rollout_round_min_episod": 7, "rolloutinfowrapp": [4, 6], "ros2_w": 5, "ros_jazzi": [5, 7], "rotation_tau": 5, "row": 7, "rt_env": 5, "rule": 4, "run": [2, 3, 4, 5, 6, 7, 9, 10], "run_index": [6, 7, 9, 10], "sa_model": 10, "sac": [2, 9, 10, 11], "sac_reward": 7, "safe": 4, "safeti": [4, 5], "safety_margin": [3, 4, 5, 6, 7, 8, 9, 10], "sai": 8, "same": [2, 3, 4, 5, 6, 7, 8, 9, 10], "sampl": [5, 8], "samples_so_far": [6, 7], "save": [2, 3, 7, 9, 10], "sb3": [3, 8, 9], "scanner": 8, "scenario": [0, 2, 5, 6, 7, 8, 9, 10, 11], "search": [0, 7], "second": [7, 8, 9, 10], "second_group": 8, "see": [2, 3, 4, 5, 6], "seed": [2, 3, 4, 5, 6, 7, 9, 10], "seem": [4, 5, 6, 9, 10], "select": [1, 2, 3, 5, 8], "self": 5, "sens": [2, 4], "sensingst": [2, 3], "sensor": [2, 3, 4, 5, 6, 7, 8, 9, 10], "separ": 3, "sequenc": 3, "set": [2, 3, 7], "set_logg": [7, 9, 10], "set_tick_param": [6, 9, 10], "set_titl": 5, "set_xlabel": 4, "set_xlim": 4, "set_xticklabel": 4, "set_ylabel": 4, "set_ylim": 4, "set_ytick": [6, 9, 10], "set_yticklabel": 4, "setup": [4, 5, 6, 9], "sever": [2, 5], "shape": [3, 5], "share": [2, 3, 8, 10], "shared_parallel_env": [2, 3, 8, 10], "short": 5, "should": 4, "show": [5, 6], "showcas": [5, 8], "side": [4, 5, 6, 8, 9, 10], "signal": 3, "significantli": [9, 10], "sim": [2, 3, 4, 5, 6, 7, 8, 9, 10], "similar": 2, "similarli": 2, "simpl": 4, "simpledaggertrain": 3, "simpler": 2, "simpli": 5, "simplif": 2, "simplifi": [2, 3, 6], "simul": [2, 3, 5, 6, 7, 8], "sinc": 7, "singl": [2, 4, 10, 11], "site": [5, 7], "size": [3, 4, 5], "slice": [3, 8, 10], "slighti": 6, "slightli": [2, 5, 10], "small": 7, "smaller": 3, "so": 2, "social_margin": [3, 5], "social_reward": 4, "socialreward": [3, 5, 6, 7, 8, 9, 10], "sole": [3, 10], "some": [2, 5, 6], "someth": 9, "sometim": 4, "sorri": [4, 5, 6, 9, 10], "sourc": 5, "space": [2, 3, 5, 8, 9], "spawn": 2, "spec": 5, "specif": 2, "specifi": [2, 3, 5, 9], "speed": [3, 4, 5, 8], "speed_toler": [5, 6, 8, 9, 10], "src": [5, 7], "stabl": [1, 2, 5], "stable_baselines3": [2, 5, 6, 7, 8, 9, 10], "stack": [3, 8], "stai": 5, "standard": 2, "start": [4, 5, 6, 7, 9, 10], "state": [2, 3, 5, 8], "state_estim": [2, 4, 5, 6, 7, 8, 9, 10], "std": [4, 9, 10], "step": [2, 3, 4, 5, 6, 7, 8, 9, 10], "still": 2, "str": 3, "straight": [4, 5], "sub": 2, "subclass": 2, "submodul": 3, "subplot": [4, 5, 7], "suitabl": 2, "sum": [3, 4], "super": 5, "supersuit": [1, 2, 8], "support": [2, 4, 5, 6, 9, 10], "suptitl": 4, "system": 2, "t": [2, 4, 5, 6, 9, 10], "take": [4, 7], "taken": 2, "targer": 4, "target": [2, 3, 4], "target_margin": [5, 6, 8, 9, 10], "task": [2, 4, 10], "tau": [4, 5, 6, 7, 8, 9, 10], "tb_log_nam": [7, 9, 10], "te": 4, "tensor": 3, "tensorboard": [7, 9, 10], "termin": [2, 3, 5, 8], "terminate_outside_bound": [3, 10], "test": [10, 11], "test_venv": 7, "than": [3, 4, 10], "thei": 8, "them": [2, 5], "therefor": [2, 5, 8], "thi": [2, 3, 4, 5, 6, 7, 8, 9, 10], "think": 2, "those": 2, "three": 7, "through": 3, "thymio": [4, 5, 6, 7, 8, 9, 10], "tick_param": 4, "time": [2, 3, 4, 5, 7, 9, 10], "time_step": [2, 3, 4, 5, 6, 7, 8, 9, 10], "timeit": 4, "titl": [4, 5, 6, 7, 9, 10], "to_html": 5, "to_list": 10, "togeth": [2, 3, 8], "toler": [5, 6, 8, 9, 10], "too": [2, 4, 6], "took": [7, 9, 10], "tool": [2, 5], "top": 4, "torch": 3, "total": 6, "total_step": [6, 9], "total_timestep": [2, 7, 9, 10], "toward": [4, 5], "tqdm": 7, "tr": 4, "train": [0, 3, 7, 11], "trainer": [2, 3, 6, 7], "trajectori": [4, 5, 6], "trajectorywithrew": 3, "trajectoti": 4, "trane": 6, "transit": [4, 6], "travel": 4, "treat": 3, "trivial": 4, "true": [2, 3, 4, 5, 6, 7, 8, 9, 10], "truncat": [2, 3, 5, 8], "try": [4, 5, 7, 10], "tupl": [3, 5, 8], "turn": 2, "tutori": [0, 2, 5, 6, 9, 10], "twist2": [2, 8], "two": [2, 5, 7, 11], "type": [2, 3, 4, 5, 6, 7, 8, 9, 10], "typic": [2, 4], "u": [4, 5, 6, 8], "ui": [3, 4, 5, 6, 9, 10], "uint8": [3, 5, 8], "under": 3, "underli": 2, "union": 2, "until": 2, "unwrap": [5, 6, 7, 9, 10], "up": 3, "updat": [2, 4, 5], "update_static_obstacl": [4, 7], "upper": 3, "us": [0, 1, 3, 4, 8, 11], "use_acceleration_act": [3, 4, 5, 7, 8, 9, 10], "use_first_reward": 3, "use_wheel": [3, 5], "user": [5, 7], "userwarn": [5, 7], "util": [4, 6, 7], "v": 8, "v1": [5, 7], "valid": [2, 5, 8], "valu": [3, 4, 5, 7, 8, 9, 10], "variabl": [3, 7], "variat": 3, "vec_env": 10, "vecmonitor": 10, "vector": [2, 3, 6, 8, 11], "veloc": [3, 5, 8], "venv": [4, 5, 6, 7, 8, 10], "venv1": 8, "verbos": [2, 3, 6, 9, 10], "veri": [2, 4], "version": [5, 8], "via": 3, "video": [4, 5, 6, 9, 10], "video_env": 5, "video_fold": 5, "view": [2, 5], "violat": [4, 5, 7], "visibl": 4, "wa": 2, "wai": [2, 4], "wall": 4, "want": [4, 5, 8], "warn": [5, 6, 7, 9, 10], "waypoint": 5, "we": [2, 3, 4, 5, 6, 7, 8, 9, 10], "websocket": 3, "webui": 3, "well": 6, "what": 5, "wheel": 3, "wheel_axi": [4, 5, 6, 7, 8, 9, 10], "when": [3, 4, 5, 7], "where": [2, 4, 5, 8, 10], "whether": [2, 3], "which": [2, 3, 4, 5, 6, 8, 10], "while": [2, 4, 5, 8], "whole": [4, 10], "whose": 2, "width": [3, 4, 5, 7], "window": 5, "with_shap": 7, "with_world": 7, "work": 2, "world": [2, 3, 4, 5, 6, 9, 10], "worldconfig": [3, 8], "wors": 10, "worst": 7, "wrap": [2, 5], "wrapper": [2, 4, 5, 6, 7], "wrong": 4, "x": [4, 5, 7, 9, 10], "xlabel": [4, 6, 7, 9, 10], "xlim": 7, "y": [4, 5, 7, 9, 10], "yaml": [2, 3], "yaxi": [6, 9, 10], "yet": 2, "ylabel": [4, 6, 7, 9, 10], "you": [2, 7], "your": [4, 5, 6, 9, 10], "zip": [4, 5, 10], "\u00b5": 4}, "titles": ["Welcome to navground_learning\u2019s documentation!", "Installation", "Introduction", "Reference", "Navigate along a corridor with one obstacle: scenario", "Navground-Gymnasium integration", "Train a policy using Imitation Learning", "Navigate along a corridor with one obstacle: learning", "Navground-PettingZoo integration", "Train a policy using RL", "Train a policy using RL, part 2: multi-agent environment", "Tutorials"], "titleterms": {"": 0, "2": 10, "A": 8, "acknowledg": 2, "action": 3, "agent": [3, 10], "along": [4, 7], "behavior": [3, 7], "clone": [3, 7], "comparis": 7, "configur": 3, "content": 0, "convert": 8, "corridor": [4, 7], "corridorwithobstacl": 3, "dagger": [3, 7], "data": 3, "disclaim": 2, "document": 0, "end": 3, "env": 8, "enviro": 5, "environ": [2, 3, 10], "evalu": 3, "experi": 3, "forward": 3, "function": 3, "group": 8, "gymnasium": [2, 3, 5, 8], "hl": 7, "imit": [2, 3, 6, 7], "indic": 0, "infer": 3, "instal": 1, "integr": [2, 5, 8], "introduct": 2, "learn": [2, 3, 6, 7, 9, 10], "ml": 2, "model": 3, "modul": 3, "multi": [3, 10], "navground": [2, 5, 6, 8], "navground_learn": 0, "navig": [4, 7], "null": 3, "observ": 3, "obstacl": [4, 7], "one": [4, 7], "part": 10, "pettingzoo": [2, 3, 8], "polici": [2, 5, 6, 9, 10], "probe": 3, "record": 3, "refer": 3, "reinforc": [2, 7], "render": 5, "reward": 3, "rl": [9, 10], "rollout": 3, "sac": 7, "scenario": [3, 4], "singl": [3, 8], "social": 3, "system": 3, "tabl": 0, "test": 6, "train": [2, 6, 9, 10], "tutori": 11, "two": 8, "us": [2, 5, 6, 9, 10], "vector": 5, "welcom": 0}})