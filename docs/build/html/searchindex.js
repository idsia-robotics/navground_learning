Search.setIndex({"alltitles": {"A single group": [[10, "A-single-group"]], "Acknowledgement and disclaimer": [[2, "acknowledgement-and-disclaimer"]], "Actions": [[3, "actions"]], "Analysis": [[8, "Analysis"]], "Behavior Cloning": [[3, "behavior-cloning"]], "Behavior Modulation": [[3, "behavior-modulation"]], "Behaviors": [[3, "behaviors"]], "Comparision with HL": [[9, "Comparision-with-HL"]], "Configuration": [[3, "configuration"]], "Contents:": [[0, null]], "Convert to a Gymnasium Env": [[10, "Convert-to-a-Gymnasium-Env"]], "CorridorWithObstacle": [[3, "corridorwithobstacle"]], "Crossings with different speeds": [[5, "Crossings-with-different-speeds"]], "DAgger": [[3, "dagger"]], "End-to-end": [[3, "end-to-end"]], "Environments": [[3, "environments"]], "Evaluation": [[3, "evaluation"]], "Experiments": [[3, "experiments"]], "Forward": [[3, "forward"]], "Gymnasium": [[2, "gymnasium"]], "Imitation Learning": [[2, "imitation-learning"], [3, "imitation-learning"]], "Imitation learning": [[7, "Imitation-learning"]], "Imitation learning with Behavior Cloning": [[9, "Imitation-learning-with-Behavior-Cloning"]], "Imitation learning with DAgger": [[9, "Imitation-learning-with-DAgger"]], "Indices and tables": [[0, "indices-and-tables"]], "Individual target speed": [[5, "Individual-target-speed"]], "Inference": [[3, "inference"]], "Installation": [[1, "installation"]], "Introduction": [[2, "introduction"]], "Learning": [[3, "learning"]], "Models": [[3, "models"]], "Multi-agent (Pettingzoo)": [[3, "multi-agent-pettingzoo"]], "Multi-agent RL learning": [[12, "Multi-agent-RL-learning"]], "Multi-agent system": [[3, "multi-agent-system"]], "Navground": [[2, "navground"]], "Navground Gymnasium Environment": [[2, "navground-gymnasium-environment"]], "Navground-Gymnasium integration": [[2, "navground-gymnasium-integration"], [6, "Navground-Gymnasium-integration"]], "Navground-PettingZoo integration": [[10, "Navground-PettingZoo-integration"]], "Navigate along a corridor with one obstacle: learning": [[9, "Navigate-along-a-corridor-with-one-obstacle:-learning"]], "Navigate along a corridor with one obstacle: scenario": [[4, "Navigate-along-a-corridor-with-one-obstacle:-scenario"]], "Null": [[3, "null"]], "Observations": [[3, "observations"]], "PettingZoo": [[2, "pettingzoo"]], "PettingZoo Navground Environment": [[2, "pettingzoo-navground-environment"]], "Probes": [[3, "probes"]], "RL learning": [[11, "RL-learning"]], "Recording data": [[3, "recording-data"]], "Reference": [[3, "reference"]], "Reinforcement Learning": [[2, "reinforcement-learning"]], "Reinforcement learning with SAC": [[9, "Reinforcement-learning-with-SAC"]], "Rendering": [[6, "Rendering"]], "Reward functions": [[3, "reward-functions"]], "Rollouts": [[3, "rollouts"]], "Scenarios": [[3, "scenarios"]], "Single-agent (Gymnasium)": [[3, "single-agent-gymnasium"]], "Social": [[3, "social"]], "Testing in navground": [[7, "Testing-in-navground"]], "Train ML policies in navground": [[2, "train-ml-policies-in-navground"]], "Train a policy using Imitation Learning": [[7, "Train-a-policy-using-Imitation-Learning"]], "Train a policy using Imitation Learning part 2: DAgger": [[8, "Train-a-policy-using-Imitation-Learning-part-2:-DAgger"]], "Train a policy using RL": [[11, "Train-a-policy-using-RL"]], "Train a policy using RL, part 2: multi-agent environment": [[12, "Train-a-policy-using-RL,-part-2:-multi-agent-environment"]], "Training": [[8, "Training"]], "Tutorials": [[13, "tutorials"]], "Two groups": [[10, "Two-groups"]], "Uniform target speed": [[5, "Uniform-target-speed"]], "Use ML policies in navground": [[2, "use-ml-policies-in-navground"]], "Using a policy in Navground": [[6, "Using-a-policy-in-Navground"]], "Vectorized environments": [[6, "Vectorized-environments"]], "Welcome to navground_learning\u2019s documentation!": [[0, "welcome-to-navground-learning-s-documentation"]], "imitation learning with BC": [[8, "imitation-learning-with-BC"]], "imitation learning with DAgger in multi-agent environment": [[8, "imitation-learning-with-DAgger-in-multi-agent-environment"]], "imitation learning with DAgger in single-agent environment": [[8, "imitation-learning-with-DAgger-in-single-agent-environment"]]}, "docnames": ["index", "installation", "introduction", "reference", "tutorials/CorridorScenario", "tutorials/CrossingWithDifferentSpeeds", "tutorials/Gym", "tutorials/IL", "tutorials/IL-DAgger", "tutorials/LearningCorridor", "tutorials/PettingZoo", "tutorials/RL", "tutorials/RL-MA", "tutorials/index"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["index.rst", "installation.rst", "introduction.rst", "reference.rst", "tutorials/CorridorScenario.ipynb", "tutorials/CrossingWithDifferentSpeeds.ipynb", "tutorials/Gym.ipynb", "tutorials/IL.ipynb", "tutorials/IL-DAgger.ipynb", "tutorials/LearningCorridor.ipynb", "tutorials/PettingZoo.ipynb", "tutorials/RL.ipynb", "tutorials/RL-MA.ipynb", "tutorials/index.rst"], "indexentries": {"clone() (navground_learning.behaviors.policybehavior method)": [[3, "navground_learning.behaviors.PolicyBehavior.clone", false]], "clone_behavior() (navground_learning.behaviors.policybehavior class method)": [[3, "navground_learning.behaviors.PolicyBehavior.clone_behavior", false]], "collect_runs() (navground_learning.il.bc.trainer method)": [[3, "navground_learning.il.bc.Trainer.collect_runs", false]], "controlactionconfig (class in navground_learning)": [[3, "navground_learning.ControlActionConfig", false]], "corridorwithobstacle (class in navground_learning.scenarios)": [[3, "navground_learning.scenarios.CorridorWithObstacle", false]], "deterministic (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.deterministic", false]], "dtype (navground_learning.probes.rewardprobe attribute)": [[3, "navground_learning.probes.RewardProbe.dtype", false]], "evaluate_expert() (in module navground_learning.evaluate)": [[3, "navground_learning.evaluate.evaluate_expert", false]], "evaluationscenario (class in navground_learning.scenarios)": [[3, "navground_learning.scenarios.EvaluationScenario", false]], "fix_orientation (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.fix_orientation", false]], "flat (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.flat", false]], "forwardscenario (class in navground_learning.scenarios)": [[3, "navground_learning.scenarios.ForwardScenario", false]], "get_trajectories_from_experiment() (in module navground_learning.rollout)": [[3, "navground_learning.rollout.get_trajectories_from_experiment", false]], "get_trajectories_from_run() (in module navground_learning.rollout)": [[3, "navground_learning.rollout.get_trajectories_from_run", false]], "groupconfig (class in navground_learning)": [[3, "navground_learning.GroupConfig", false]], "gymprobe (class in navground_learning.probes)": [[3, "navground_learning.probes.GymProbe", false]], "history (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.history", false]], "include_radius (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_radius", false]], "include_target_angular_speed (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_target_angular_speed", false]], "include_target_direction (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_target_direction", false]], "include_target_direction_validity (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_target_direction_validity", false]], "include_target_distance (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_target_distance", false]], "include_target_distance_validity (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_target_distance_validity", false]], "include_target_speed (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_target_speed", false]], "include_velocity (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.include_velocity", false]], "make_behavior() (navground_learning.il.bc.trainer method)": [[3, "navground_learning.il.bc.Trainer.make_behavior", false]], "make_behavior() (navground_learning.il.dagger.trainer method)": [[3, "navground_learning.il.dagger.Trainer.make_behavior", false]], "make_experiment() (in module navground_learning.evaluate)": [[3, "navground_learning.evaluate.make_experiment", false]], "make_experiment_with_env() (in module navground_learning.evaluate)": [[3, "navground_learning.evaluate.make_experiment_with_env", false]], "max_acceleration (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.max_acceleration", false]], "max_angular_acceleration (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.max_angular_acceleration", false]], "modulationactionconfig (class in navground_learning)": [[3, "navground_learning.ModulationActionConfig", false]], "navgroundenv (class in navground_learning.env)": [[3, "navground_learning.env.NavgroundEnv", false]], "nullreward() (in module navground_learning.reward)": [[3, "navground_learning.reward.NullReward", false]], "observationconfig (class in navground_learning)": [[3, "navground_learning.ObservationConfig", false]], "orderinvariantcombinedextractor (class in navground_learning.policies)": [[3, "navground_learning.policies.OrderInvariantCombinedExtractor", false]], "parallel_env() (in module navground_learning.env.pz)": [[3, "navground_learning.env.pz.parallel_env", false]], "policy (navground_learning.il.bc.trainer property)": [[3, "navground_learning.il.bc.Trainer.policy", false]], "policy (navground_learning.il.dagger.trainer property)": [[3, "navground_learning.il.dagger.Trainer.policy", false]], "policy_path (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.policy_path", false]], "policybehavior (class in navground_learning.behaviors)": [[3, "navground_learning.behaviors.PolicyBehavior", false]], "rewardprobe (class in navground_learning.probes)": [[3, "navground_learning.probes.RewardProbe", false]], "save() (navground_learning.il.bc.trainer method)": [[3, "navground_learning.il.bc.Trainer.save", false]], "save() (navground_learning.il.dagger.trainer method)": [[3, "navground_learning.il.dagger.Trainer.save", false]], "shared_parallel_env() (in module navground_learning.env.pz)": [[3, "navground_learning.env.pz.shared_parallel_env", false]], "socialreward() (in module navground_learning.reward)": [[3, "navground_learning.reward.SocialReward", false]], "space (navground_learning.controlactionconfig property)": [[3, "navground_learning.ControlActionConfig.space", false]], "train() (navground_learning.il.bc.trainer method)": [[3, "navground_learning.il.bc.Trainer.train", false]], "train() (navground_learning.il.dagger.trainer method)": [[3, "navground_learning.il.dagger.Trainer.train", false]], "trainer (class in navground_learning.il.bc)": [[3, "navground_learning.il.bc.Trainer", false]], "trainer (class in navground_learning.il.dagger)": [[3, "navground_learning.il.dagger.Trainer", false]], "use_acceleration_action (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.use_acceleration_action", false]], "use_wheels (navground_learning.behaviors.policybehavior property)": [[3, "navground_learning.behaviors.PolicyBehavior.use_wheels", false]], "worldconfig (class in navground_learning)": [[3, "navground_learning.WorldConfig", false]]}, "objects": {"navground_learning": [[3, 0, 1, "", "ControlActionConfig"], [3, 0, 1, "", "GroupConfig"], [3, 0, 1, "", "ModulationActionConfig"], [3, 0, 1, "", "ObservationConfig"], [3, 0, 1, "", "WorldConfig"]], "navground_learning.ControlActionConfig": [[3, 1, 1, "", "space"]], "navground_learning.behaviors": [[3, 0, 1, "", "PolicyBehavior"]], "navground_learning.behaviors.PolicyBehavior": [[3, 2, 1, "", "clone"], [3, 2, 1, "", "clone_behavior"], [3, 1, 1, "", "deterministic"], [3, 1, 1, "", "fix_orientation"], [3, 1, 1, "", "flat"], [3, 1, 1, "", "history"], [3, 1, 1, "", "include_radius"], [3, 1, 1, "", "include_target_angular_speed"], [3, 1, 1, "", "include_target_direction"], [3, 1, 1, "", "include_target_direction_validity"], [3, 1, 1, "", "include_target_distance"], [3, 1, 1, "", "include_target_distance_validity"], [3, 1, 1, "", "include_target_speed"], [3, 1, 1, "", "include_velocity"], [3, 1, 1, "", "max_acceleration"], [3, 1, 1, "", "max_angular_acceleration"], [3, 1, 1, "", "policy_path"], [3, 1, 1, "", "use_acceleration_action"], [3, 1, 1, "", "use_wheels"]], "navground_learning.env": [[3, 0, 1, "", "NavgroundEnv"]], "navground_learning.env.pz": [[3, 3, 1, "", "parallel_env"], [3, 3, 1, "", "shared_parallel_env"]], "navground_learning.evaluate": [[3, 3, 1, "", "evaluate_expert"], [3, 3, 1, "", "make_experiment"], [3, 3, 1, "", "make_experiment_with_env"]], "navground_learning.il.bc": [[3, 0, 1, "", "Trainer"]], "navground_learning.il.bc.Trainer": [[3, 2, 1, "", "collect_runs"], [3, 2, 1, "", "make_behavior"], [3, 1, 1, "", "policy"], [3, 2, 1, "", "save"], [3, 2, 1, "", "train"]], "navground_learning.il.dagger": [[3, 0, 1, "", "Trainer"]], "navground_learning.il.dagger.Trainer": [[3, 2, 1, "", "make_behavior"], [3, 1, 1, "", "policy"], [3, 2, 1, "", "save"], [3, 2, 1, "", "train"]], "navground_learning.policies": [[3, 0, 1, "", "OrderInvariantCombinedExtractor"]], "navground_learning.probes": [[3, 0, 1, "", "GymProbe"], [3, 0, 1, "", "RewardProbe"]], "navground_learning.probes.RewardProbe": [[3, 4, 1, "", "dtype"]], "navground_learning.reward": [[3, 3, 1, "", "NullReward"], [3, 3, 1, "", "SocialReward"]], "navground_learning.rollout": [[3, 3, 1, "", "get_trajectories_from_experiment"], [3, 3, 1, "", "get_trajectories_from_run"]], "navground_learning.scenarios": [[3, 0, 1, "", "CorridorWithObstacle"], [3, 0, 1, "", "EvaluationScenario"], [3, 0, 1, "", "ForwardScenario"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "property", "Python property"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "objtypes": {"0": "py:class", "1": "py:property", "2": "py:method", "3": "py:function", "4": "py:attribute"}, "terms": {"": [2, 3, 4, 5, 6, 7, 10, 11, 12], "0": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "00": [6, 10], "000": 4, "000000": 10, "00000000e": [6, 10], "001": 7, "00284": 7, "004": 11, "00471158": 6, "01": [2, 5], "014": 8, "017": 10, "02": [5, 6, 7, 8, 9, 10, 11, 12], "026401288000002": 9, "03": 5, "0369845": 9, "04": [4, 9], "04048300899996": 9, "047": 8, "05": [4, 8, 9, 11], "06": 5, "069": 8, "070": 8, "073": 10, "075": 11, "08": [4, 9], "094": [4, 5, 6, 7, 8, 9, 10, 11, 12], "0f": [8, 9, 11, 12], "0x10560e090": [], "0x352cd9d60": 5, "0x35f8d2450": [], "0x368838410": 5, "1": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "10": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "100": [2, 5, 6, 7, 8, 10, 12], "1000": [2, 3, 4, 6, 9, 10], "100000": [2, 9, 10], "10000000000000001": 6, "100_000": [9, 11], "100k": 9, "101070028": 2, "10201398": [6, 10], "108": 11, "10ml_10hl": 12, "10saml_10hl": 12, "11": [5, 6, 7, 9, 10, 11, 12], "111": 7, "1121034": [6, 10], "113": 7, "12": [4, 5, 6, 7, 8, 9, 10, 11, 12], "120": [5, 6, 7], "1200": 6, "120000": 10, "122": [], "123": [8, 9], "128": [5, 8, 9], "129": 7, "13": [5, 6, 7, 8, 9, 10, 11, 12], "14": [5, 6, 7, 9, 10, 11, 12], "15": [4, 5, 6, 7, 8, 9, 10, 11], "150_000": 8, "153": 12, "158": 4, "16": [4, 5, 6, 7, 9, 10], "17": [4, 5, 6, 9, 10], "173982": 9, "18": [4, 6, 7, 9, 10], "1800": [8, 12], "181": [], "19": [4, 5, 6, 7, 8, 9, 10, 12], "190": 7, "193": 11, "196": 8, "19885384": [6, 10], "19ml_1hl": 12, "19saml_1hl": 12, "1_000_000": 5, "1e": [8, 9], "1ml_19hl": 12, "1saml_19hl": 12, "2": [0, 4, 5, 6, 7, 9, 10, 13], "20": [4, 5, 6, 7, 8, 9, 10, 11, 12], "200": 4, "20000": [7, 11], "2021": 2, "20867327": [6, 10], "20ml": 12, "21": [4, 5, 6, 9], "210": 8, "22": [4, 5, 6, 9, 12], "220": 11, "222": 4, "222684": 9, "22419791": [6, 10], "225": 8, "226": [5, 8], "23": [4, 5, 6, 9], "24": [4, 5, 6, 9, 12], "240": 5, "2400": [5, 8, 11], "242": 10, "243": 12, "246": 6, "25": [4, 5, 6, 7, 8, 9, 10, 11, 12], "255": [3, 6], "256": [3, 12], "258": 12, "259": 12, "26": [4, 6, 9, 12], "264": 12, "266": 12, "27": [4, 5, 6, 9], "272681": 9, "275": 12, "276": 12, "28": [4, 5, 6, 8, 9, 12], "28052899347895": 4, "28317614": [6, 10], "29": [4, 5, 6, 8, 9], "2_000_000": 12, "2f": 5, "2wdiff": [4, 5, 6, 7, 8, 9, 10, 11, 12], "3": [3, 4, 5, 6, 7, 8, 9, 10], "30": [4, 6, 7, 8, 9, 11, 12], "300": [4, 6, 7], "3000": 8, "308": 8, "31": [5, 6, 8], "311": 9, "314": 12, "315": 12, "32": [4, 5, 6, 7, 8, 9], "324": 8, "327": 9, "32967995": [6, 10], "33": [4, 6, 8, 12], "331": 12, "334": 12, "335068": 9, "337": 9, "34": 6, "35": 6, "350": 8, "355": 12, "35694126": [6, 10], "359": 9, "36": 6, "360": [4, 8, 12], "37": 6, "38": 6, "387": 12, "388": 12, "39": [4, 6, 9, 10, 12], "390": 8, "392": 12, "393": 12, "3_000_000": 5, "3d": 2, "3f": [6, 7, 8, 10, 11, 12], "4": [4, 5, 6, 7, 8, 9, 10, 11, 12], "40": [4, 6, 9], "400": [5, 6, 11, 12], "408": 12, "41": [6, 9], "415": 9, "41599925e": [6, 10], "418": 8, "42": 12, "433": 12, "433805959060551": 4, "441": 12, "442": 12, "449": 12, "46": [8, 12], "468": 4, "47": 12, "477": 8, "48": [4, 8, 12], "49": [8, 12], "494": 8, "496797": 9, "5": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "50": [3, 5, 8, 9, 12], "500": 9, "50000": 9, "500_000": 8, "50433907": [6, 10], "51": 8, "512": 12, "519": 8, "52": 8, "53": [6, 8], "54": [8, 12], "55": 8, "553191": 10, "5531914893617018": 6, "553191489361702": 6, "56": [8, 12], "56413084": [6, 10], "57": [8, 12], "573": 12, "58": 8, "599": [6, 10], "5x": 9, "6": [4, 5, 6, 7, 8, 9, 10, 11], "60": [5, 6, 7, 8, 10, 11, 12], "600": [6, 8, 11, 12], "60000": 9, "601806": 9, "602": 12, "621": 12, "63": 9, "64": 8, "640": 6, "645": 8, "65": [4, 8], "66": 8, "661": 8, "67": [], "670": 9, "67285531": [6, 10], "68": 9, "683": 11, "7": [4, 5, 6, 7, 9, 10, 11, 12], "71": 5, "717": 7, "72": [], "722": 8, "724690000000001": 9, "73": [], "75": 9, "750": [6, 9], "779": 8, "78": 5, "8": [3, 4, 5, 6, 7, 8, 9, 10, 11], "80": [], "8002": 6, "809": 12, "81": [], "82": [], "82594673": [6, 10], "83": [], "833333333333336": 4, "84": 7, "85": [], "855": 8, "87": [], "876535": 9, "9": [5, 6, 7, 9, 10, 11, 12], "91": [], "916": 8, "92": 5, "93": [], "94": 6, "949": 6, "95": 5, "957": 8, "957440417": 9, "96": 5, "9665543284519917": 4, "9682783": 6, "97": [], "98": [5, 9], "9853547": 6, "995": 7, "997": 6, "99745506": 6, "999": 11, "A": [3, 4, 12, 13], "As": [5, 6, 7, 11], "At": 2, "By": 2, "For": [2, 5, 6, 8, 10], "If": [2, 3, 10], "In": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "It": [2, 3, 5, 9, 12], "One": 12, "The": [2, 3, 4, 6, 7, 10], "Then": [1, 7], "There": [2, 6], "These": 6, "To": [2, 6], "_": [2, 4, 6, 7, 8, 9], "__call__": 5, "__init__": [5, 6], "_mod": 5, "_possible_ag": 10, "_reward": 6, "ab": 5, "abc": 3, "about": [4, 6, 9], "abov": 4, "absolut": 5, "acc": 4, "acceler": [3, 4, 10], "achiev": 5, "acknowledg": 0, "act": [2, 4, 10], "action": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "action_config": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12], "action_spac": [6, 7, 10], "actionconfig": [2, 3], "activ": 3, "activation_fn": 3, "actual": [4, 6], "actuat": [2, 6], "add": [3, 5], "add_init": 5, "add_modul": 5, "add_patch": 4, "add_record_prob": 6, "add_speed_modul": 5, "addit": [3, 6], "advantag": 8, "aec": 2, "after": [3, 4, 6, 7, 10, 11], "again": 5, "agent": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 13], "agent_color": 9, "agent_index": [3, 7], "agent_indic": [3, 5, 8, 10, 12], "agent_margin": [5, 6, 7, 8, 10, 11, 12], "agreement": 2, "ai": [2, 7], "aim": 5, "algorithm": [2, 3, 7, 8, 9], "alia": 3, "aliv": 2, "all": [2, 3, 4, 5, 6, 8, 10, 12], "all_reward": [6, 10], "almost": [4, 11], "along": [0, 13], "alpha": [3, 4, 5, 6, 7, 8, 9, 11, 12], "alreadi": [3, 6], "also": [2, 6, 9, 10, 12], "alwai": 4, "among": [2, 10, 11, 12], "an": [2, 3, 4, 5, 6, 7, 9, 10, 12], "analysi": 13, "angular": [3, 4, 5, 6], "angular_spe": [3, 5], "ani": [2, 3, 5, 6], "anymor": 2, "anywai": 4, "api": [2, 6, 10], "append": [6, 10], "appli": [2, 3, 6, 9], "ar": [2, 3, 4, 5, 6, 7, 9, 10, 12], "area": 3, "arg": 3, "argmin": 4, "argument": [3, 9], "around": 6, "arrai": [6, 10], "asarrai": [4, 5, 6, 7, 8, 11, 12], "asdict": 5, "ask": 7, "assign": 6, "assum": 3, "astyp": 6, "atari": 2, "audio": [4, 5, 6, 7, 8, 11, 12], "author": 2, "automat": 6, "autonotebook": [8, 9], "autoreset": 6, "avail": [2, 6], "avoid": [3, 4], "ax": [4, 6, 7, 8, 11, 12], "axi": [4, 5, 6], "b": 3, "barrier_angl": [4, 5, 9], "base": [2, 3, 4, 6, 10], "base_class": 10, "basecallback": 3, "basefeaturesextractor": 3, "baseline3": 1, "baselines3": [1, 2, 6], "basic": 6, "batch": 7, "batch_siz": [7, 8, 9], "bbox_to_anchor": 9, "bc": [2, 3, 7, 9, 13], "bc_kwarg": [3, 8, 9], "bc_reward": 9, "bc_train_kwarg": [8, 9], "bc_trainer": [7, 8, 9], "been": [2, 12], "befor": [3, 7, 10, 11, 12], "begin": [4, 5], "behavior": [2, 4, 5, 6, 7, 8, 10, 11, 12, 13], "behaviorclon": 7, "behaviormodul": 5, "below": 2, "benchmark": 6, "beta": [3, 5, 6], "better": [7, 9, 11, 12], "between": [2, 6, 10], "bin": [4, 5, 7, 8, 9, 11, 12], "bitwise_or": 10, "black": [6, 7, 8, 11, 12], "blue": [5, 8, 9], "bodi": [3, 4], "bool": 3, "both": [11, 12], "bottom": 4, "bound": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "boundari": [4, 9], "boundary_dist": 4, "box": [3, 6, 10], "break": 2, "browser": [4, 5, 6, 7, 8, 11, 12], "bufferdescript": 6, "build": [1, 2, 3], "built": 3, "c": [2, 4], "call": [2, 6], "callabl": [3, 5, 9], "callback": 3, "can": [2, 4, 6, 9, 10], "cannot": [4, 9], "case": [4, 5, 6, 8, 9, 10], "categor": 6, "center": [2, 7], "chang": [4, 5], "check": [2, 3, 5, 6, 7], "circl": 4, "cit": 7, "cl4": 2, "clamp": 5, "class": [2, 3, 5, 6], "classmethod": 3, "clean": 7, "clone": [2, 7, 8, 13], "clone_behavior": [2, 3, 6, 7], "close": [2, 6], "cm": 4, "cnn": 3, "cnn_output_dim": 3, "coher": 6, "col": 9, "colcon": 1, "collect": [3, 6, 7, 8, 9, 10, 11, 12], "collect_run": [3, 7, 8, 9], "collis": 2, "color": [4, 5, 6, 7, 8, 9, 10, 11, 12], "colorbar": 4, "column": 9, "combin": [3, 4, 9], "combinedextractor": 3, "come": 5, "command": [2, 3, 4, 10], "commiss": 2, "common": [5, 6, 7, 8, 9, 10, 11, 12], "compar": [5, 6, 8, 9, 10], "comparis": 13, "compat": [2, 7], "complex": 10, "compos": [6, 12], "comput": [2, 4, 6, 10, 11], "compute_safety_viol": 5, "concat_vec_envs_v1": 10, "concaten": [2, 3], "config": [3, 4, 5, 6, 7, 8, 10, 12], "configur": [0, 2, 5, 6, 8, 9, 10, 11, 12], "conform": 2, "consid": 10, "consist": 5, "constant": [4, 5, 6], "constraint": 4, "construct": 3, "constructor": 3, "consum": 3, "contain": [2, 6, 10], "contrari": 5, "control": [2, 3, 4, 6, 10, 11, 12], "control_period": [4, 5, 6, 7, 8, 9, 10, 11, 12], "controlactionconfig": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12], "convert": [2, 13], "copi": 3, "core": [2, 4, 5, 6, 9], "corridor": [0, 13], "corridor_with_obstacl": [4, 9], "corridor_with_obstacle_v2": 9, "corridorwithobstacl": [4, 9], "could": 7, "cover": 6, "creat": 3, "critical_safety_margin": [3, 5], "cross": [0, 6, 7, 8, 10, 11, 12, 13], "crossingwithdifferentspe": 5, "crossingwithsamespe": 5, "crosstoru": 5, "csv": [5, 8, 9, 11, 12], "ctreward": 5, "cum_rew": 4, "current": 3, "custom": 2, "cyan": 8, "cycl": [2, 6], "d": [3, 6], "dagger": [0, 2, 7, 13], "dagger_kwarg": 3, "dagger_ma": 8, "dagger_reward": 9, "dagger_sa": 8, "dagger_train": 9, "daggerma": 8, "daggersa": 8, "data": [0, 4, 6, 7, 9], "dataclass": 5, "dataset": [3, 6, 8, 9], "datetim": 5, "dc": 5, "decent": 9, "decis": 2, "decor": 5, "def": [4, 5, 6, 7, 8, 9, 11, 12], "default": [3, 6], "default_rng": [4, 7, 9], "default_social_margin": 3, "defin": [5, 6, 7, 9, 10, 11, 12], "demand": 3, "demonstr": 7, "densiti": [4, 5, 6, 7, 8, 9, 11, 12], "depend": [1, 3, 11], "deprec": [6, 9], "descreas": 12, "describ": 3, "descript": 6, "desir": 6, "determinist": [2, 3, 6, 12], "deterministic_polici": 9, "dev": [4, 6, 9], "df": [5, 8, 9, 11, 12], "dict": [2, 3, 5, 6, 8, 10], "dict_kei": 4, "differ": [0, 2, 6, 10, 12, 13], "differnet": 10, "dimens": 3, "direclti": 6, "direct": [3, 4, 5], "directli": 2, "directori": 3, "disabl": 3, "disable_logg": 6, "disable_progress_bar": [8, 9], "disc": [4, 5, 6, 7, 8, 9, 10, 11, 12], "disclaim": 0, "discontinu": 2, "discuss": 4, "displai": [6, 9], "display_in_notebook": 4, "display_mix": 8, "display_run": [7, 8, 11, 12], "display_shap": 5, "display_video": [4, 5, 6, 7], "display_video_from_run": [5, 8, 11, 12], "display_width": [4, 5, 6, 7, 8, 11, 12], "distanc": [2, 3, 4], "distnac": 3, "distribut": [2, 4, 7, 8, 11, 12], "divers": 2, "dlr": 2, "do": [2, 4, 5, 9], "doc": [2, 6], "doe": [4, 6, 7, 8], "doesn": [4, 5, 6, 7, 8, 11, 12], "dof": [3, 6], "don": [2, 5, 6], "done": [4, 6, 10], "dot": 5, "dt": 5, "dtype": [3, 6, 10], "dump": [3, 6], "durat": [4, 5, 6, 7, 8, 9, 11, 12], "dure": [4, 9, 12], "e": [2, 3, 4, 5, 6, 8, 10, 12], "each": [3, 4, 10], "effect": [3, 12], "efficaci": [5, 6], "ego_": 6, "ego_angular_spe": 4, "ego_target_direct": [4, 6, 10], "ego_target_dist": [6, 10], "ego_veloc": 4, "element": 6, "elif": 5, "els": [5, 8, 12], "end": 2, "enlarg": 4, "enough": 9, "ent_loss": 7, "ent_weight": [8, 9], "entir": 6, "entropi": 7, "enumer": [6, 9], "env": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13], "env_kwarg": 6, "env_make_kwarg": [4, 7], "env_util": 6, "enviro": 5, "environ": [0, 7, 9, 10, 13], "ep_rew_mean": [5, 9, 11, 12], "episod": [6, 7, 11], "episode_trigg": 6, "epoch": [7, 9], "equal": [4, 6], "especiali": 9, "estim": [2, 3], "eta": [4, 5, 6, 7, 8, 9, 10, 11, 12], "eu": 2, "european": 2, "evalu": [2, 5, 7, 8, 9, 11, 12], "evaluate_expert": [3, 5, 8, 9, 11], "evaluate_hl": [], "evaluate_my_polici": 2, "evaluate_origin": 8, "evaluate_polici": [5, 7, 8, 9, 11], "evaluationscenario": 3, "evalut": 8, "even": [4, 6, 9, 10, 12], "event": 4, "everi": 3, "everyth": 2, "exampl": [2, 5], "excess": 5, "exchang": 2, "exclude_info": 4, "excus": 4, "exist": 6, "exit": 3, "exp": [4, 5, 9], "expect": [2, 3, 6, 7, 12], "experi": [4, 5, 7, 8, 11, 12], "experimentalrun": [3, 6], "expert": [4, 7, 9], "explod": 3, "explor": 11, "expos": [3, 6], "express": 2, "extend": 2, "extens": 2, "extractor": 3, "f": [5, 6, 7, 8, 9, 10, 11, 12], "fact": [2, 4], "factor": [3, 4, 5, 6, 7, 8, 11, 12], "factori": 3, "fail": 9, "fals": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "far": 7, "farama": 2, "featur": [2, 3], "fed": 3, "fenc": 3, "few": [4, 7], "fig": [4, 6, 9], "figsiz": [4, 6, 9], "file": 3, "fill": 5, "filter_kei": 3, "filterwarn": [7, 8, 11, 12], "final": 4, "first": [2, 4, 6, 7, 10], "first_group": 10, "fix": 9, "fix_orient": [3, 6], "flat": [3, 4, 5, 6, 8, 9, 11, 12], "flatten": [3, 4, 5, 6, 7, 8, 11, 12], "flatten_trajectori": [4, 7], "float": [3, 5, 6], "float64": [3, 6, 10], "focu": 10, "folder": 6, "follow": [6, 7, 9, 10], "forc": 3, "forwardscenario": 3, "foundat": 2, "four": 5, "frame": [4, 5, 10], "from": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "fromarrai": 6, "full": 4, "fun": 6, "function": [0, 2, 7, 9, 11, 12], "fund": 2, "g": [4, 5, 10], "game": 2, "gap": 4, "gca": [7, 8, 11, 12], "gener": [2, 3, 6, 10, 12], "get": [2, 3, 4, 6, 9], "get_cmd_from_act": 10, "get_dir": [5, 8, 9], "get_elements_at": [8, 12], "get_env": 11, "get_expert_reward": 4, "get_imag": 6, "get_record": [5, 7, 8, 11, 12], "get_shap": 6, "get_target_angular_spe": 5, "get_target_direct": 5, "get_target_spe": 5, "get_tim": 5, "get_trajectories_from_experi": 3, "get_trajectories_from_run": 3, "get_wrapper_attr": 9, "goal": 6, "goe": 4, "gold": [4, 9], "good": [4, 9], "grai": [6, 7, 8, 10, 11, 12], "grant": 2, "green": [5, 8, 9], "grei": 8, "group": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13], "groupconfig": [3, 10], "gt": 5, "guzzi": [6, 9], "gym": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "gymagentconfig": [3, 4], "gymanasium": 2, "gymansium": 6, "gymnasium": [0, 1, 4, 7, 8, 9, 11, 12, 13], "gymprob": 3, "h": 2, "ha": [2, 3, 4, 6, 10, 12], "half": 12, "happen": 4, "has_wheel": [3, 6], "have": [2, 4, 5, 6, 10, 11, 12], "head": 6, "height": 6, "held": 2, "helper": 2, "hexbin": 4, "high": 6, "hist": [4, 5, 6, 7, 8, 9, 11, 12], "histori": [3, 6], "hl": [4, 5, 6, 7, 8, 10, 11, 12, 13], "hl_individual_scenario": 5, "hl_reward": [9, 11], "hl_reward_mean": 11, "hl_reward_std_dev": 11, "hl_uniform_scenario": 5, "horizon": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "how": [2, 3, 5, 6, 7, 8], "howev": 2, "html5": [4, 5, 6, 7, 8, 11, 12], "human": [2, 3, 6, 7], "i": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12], "id": 3, "identifi": 2, "ignor": [7, 8, 9, 11, 12], "il": [2, 3, 7, 8, 9], "im": 6, "imag": [2, 3, 6], "image_for_world": 3, "imit": [0, 1, 4, 6, 10, 13], "implement": [2, 7], "import": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "improv": 7, "imshow": 6, "includ": [2, 3], "include_angular_spe": [3, 4, 5, 6, 8, 9, 11, 12], "include_radiu": [3, 6], "include_target_angular_spe": 3, "include_target_direct": [3, 5, 6], "include_target_direction_valid": 3, "include_target_dist": [3, 4, 5, 6, 8, 9, 10, 11, 12], "include_target_distance_valid": 3, "include_target_spe": [3, 5], "include_valid": [4, 9], "include_veloc": [3, 4, 5, 6, 8, 9, 11, 12], "incur": 4, "ind_speed_hl": 5, "ind_speed_sac": 5, "index": [0, 2, 3], "indic": [3, 8, 10, 12], "individu": [3, 6, 10, 13], "individual_env": 5, "individual_reward": 5, "individual_speed_hl_reward": 5, "individual_speed_model": 5, "individual_speed_sac_reward": 5, "individual_venv": 5, "inf": [3, 6], "infer": 0, "info": [2, 4, 6, 10], "inherit": 6, "init": 3, "init_ag": 7, "init_world": [2, 4, 5, 6, 7], "initi": [2, 3, 4, 5, 6], "input": [3, 4], "insid": [2, 6], "instal": 0, "instanc": [1, 2, 6, 7, 10], "instanti": 2, "instead": [2, 3, 6, 8, 10, 12], "instruct": 1, "int": [2, 3, 4, 5], "int8": 6, "integr": [0, 13], "interact": 2, "interest": 7, "interfac": [2, 3], "interpret": 3, "intiti": 7, "introduc": 5, "introduct": 0, "introductori": [7, 11], "invari": 3, "ipython": 6, "item": [2, 3, 10], "iter": 2, "its": [2, 4, 6, 12], "jerom": [6, 9], "jupyt": 6, "just": [4, 5, 6, 7], "k": [4, 6], "keep": 5, "kei": [3, 4], "kept": 5, "kinemat": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "kwarg": [3, 8, 11, 12], "l2_loss": 7, "l2_norm": 7, "l2_weight": [8, 9], "label": [4, 5, 7, 8, 9, 11, 12], "labelleft": [7, 8, 11, 12], "lambda": [4, 5, 6, 7, 9], "larg": 9, "larger": 3, "later": [4, 12], "layer": [3, 9], "learn": [0, 1, 4, 5, 6, 10, 13], "least": 4, "left": 4, "legend": [5, 7, 8, 9, 11, 12], "len": [4, 6, 8, 10, 12], "length": [3, 4, 9], "less": 9, "let": [4, 5, 6, 7, 10, 11, 12], "lib": [6, 9], "librari": 2, "lidar": 10, "like": [2, 4, 5, 6, 7, 8, 10, 11, 12], "linalg": 5, "linear": [4, 5, 6], "link": 2, "linspac": 9, "list": [3, 10], "littl": 4, "load": [3, 6, 10, 12], "load_scenario": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "load_state_estim": [4, 5, 6, 7, 8, 9, 10, 11, 12], "log": [3, 4, 5, 8, 9, 11, 12], "log_directori": [8, 9], "log_fold": [8, 9, 11, 12], "log_format": [8, 9], "log_interv": [8, 9, 12], "log_rollouts_n_episod": [8, 9], "log_rollouts_venv": [8, 9], "logger": [5, 6, 8, 9, 11, 12], "longer": 9, "look": [2, 4, 5, 10, 11, 12], "loop": [4, 6, 10], "loss": 7, "low": 6, "lowest": 4, "lt": 5, "m": 4, "ma": [8, 11, 12], "ma_dagger_train": 8, "ma_env": 8, "ma_model": 12, "ma_venv": 8, "machin": [2, 6, 10], "mai": [2, 4, 10], "major": 4, "make": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12], "make_behavior": [2, 3], "make_experi": [3, 5], "make_experiment_with_env": [3, 5, 7, 8, 9, 11, 12], "make_sample_until": [4, 7], "make_vec": 6, "make_vec_env": [4, 6, 7], "make_venv": [5, 8, 9, 12], "manag": 4, "mani": [2, 3, 10, 12], "manual": [5, 6], "map": [3, 6, 10], "margin": [4, 6], "markov": 2, "mask": 3, "matplotlib": [4, 5, 6, 7, 8, 9, 11, 12], "max": [4, 5, 9], "max_acceler": [3, 4, 5, 6, 8, 9, 10, 11, 12], "max_angular_acceler": [3, 4, 5, 6, 8, 9, 10, 11, 12], "max_angular_spe": [3, 6], "max_dur": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "max_episode_step": [2, 6], "max_i": [4, 9], "max_number_of_ag": 3, "max_radiu": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "max_spe": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "max_target_dist": [3, 6], "max_viol": 5, "maxim": [3, 5, 6], "mdp": 2, "mean": [4, 5, 6, 8, 9, 10, 11, 12], "measur": [4, 5], "median": [4, 5, 9], "merg": 1, "metadata": 6, "method": 3, "middl": 6, "min": [4, 5, 9], "min_episod": [4, 7], "min_i": [4, 9], "min_radiu": [3, 4, 9], "min_timestep": [4, 7], "miss": 6, "mix": 8, "ml": [0, 3, 8, 9, 12], "mlp": [3, 9], "mlppolici": [2, 5, 9, 11, 12], "mod": 5, "mode": 3, "model": [0, 2, 5, 9, 11], "modul": [0, 5, 6], "modulationactionconfig": [2, 3], "more": [2, 4, 5, 7, 9, 10, 12], "moreov": 2, "most": [2, 4, 6], "move": [4, 5, 6, 10, 12], "mp4": [5, 6, 8, 12], "multi": [0, 1, 2, 5, 10, 13], "multiagentnavgroundenv": [2, 3], "multibinari": [6, 10], "multipl": [2, 10, 12], "must": 3, "my_sensor": 2, "my_trained_polici": 2, "myenviro": 2, "mymultiagentenviro": 2, "myscenario": 2, "mysensor": 2, "n": [6, 8, 10], "n_env": [3, 4, 6, 7, 8, 9], "n_epoch": [2, 7, 8, 9], "naground": 6, "name": 8, "name_prefix": 6, "navground": [0, 3, 4, 5, 8, 9, 11, 12, 13], "navground_act": [4, 6, 10], "navground_learn": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "navground_sim": 1, "navgroundbaseenv": [2, 3], "navgroundenv": [2, 3, 6, 7, 8, 11], "navig": [0, 2, 3, 5, 8, 11, 13], "ncol": [6, 9], "ndarrai": [2, 3, 5], "nearest": [4, 6], "necessarili": 2, "need": [2, 3, 5, 6, 7], "neglogp": 7, "neighbor": [6, 12], "neither": 2, "nest_asyncio": 6, "net_arch": [3, 5, 8, 9], "network": 3, "neuron": 9, "new": [2, 3, 5, 6, 10, 12], "nn": 3, "none": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12], "nonetheless": 2, "nor": 2, "norm": 5, "normal": [3, 6], "normalized_imag": 3, "note": [11, 12], "notebook": [4, 5, 6, 7, 8, 9, 10, 11, 12], "notebook_view": 6, "noth": 2, "notna": 9, "now": [5, 6, 10, 12], "np": [4, 5, 6, 7, 8, 9, 10, 11, 12], "nullreward": 3, "num_cpu": 10, "num_env": [6, 9, 10], "number": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "number_of_ag": [8, 11], "number_of_run": [4, 5, 7, 8, 9, 11, 12], "numpi": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "o": 4, "ob": [4, 6], "object": 3, "observ": [2, 5, 6, 7, 8, 9, 10, 11, 12], "observart": 11, "observation_config": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12], "observation_spac": [3, 6, 7, 10], "observationconfig": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12], "obstacl": [0, 13], "obtacl": 4, "off": 6, "offer": 2, "offlin": 6, "older": 6, "onc": [2, 6], "one": [0, 2, 5, 6, 7, 12, 13], "ones": 10, "onli": [2, 3, 4, 6, 7], "onlin": 6, "open": 6, "open_html": 6, "openai": 2, "opinion": 2, "opposit": 6, "optim": 5, "optimal_angular_spe": [5, 6], "optimal_spe": [4, 5, 6, 7, 8, 9, 10, 11, 12], "option": [1, 2, 3], "orang": 9, "order": [3, 5], "order_invariant_kei": 3, "orderinvariantcombinedextractor": 3, "orient": [2, 3], "origin": [2, 3, 6, 7, 8, 10, 11, 12], "original_indic": [8, 12], "other": [2, 3, 4, 5, 6, 9, 10, 11], "otherwis": 3, "our": [4, 6], "output": [2, 3, 4, 6, 10], "over": 12, "overwrit": 6, "own": [3, 4, 6], "p": 4, "p_straight": 4, "packag": [1, 2, 6, 9], "page": 0, "pair": [6, 11, 12], "panda": [5, 8, 9, 11, 12], "paral": 3, "parallel": [2, 3, 4, 7, 8, 9, 12], "parallel_env": [2, 3, 10], "param": 3, "paramet": [2, 3, 6], "part": [0, 2, 10, 13], "partial": 2, "particular": [2, 10], "pass": [2, 3, 4, 5], "path": [3, 8, 9], "pathlib": [8, 9], "pd": [5, 8, 9, 11, 12], "peer": 12, "penal": [4, 5, 6, 9], "per": [4, 9], "perceiv": 4, "perfect": 7, "perform": [2, 5, 7, 9, 11, 12], "period": 5, "pettingzoo": [0, 1, 13], "pettingzoo_env_to_vec_env_v1": 10, "physic": 2, "pi": 4, "pick": 4, "pil": 6, "pip": 1, "place": 6, "plaza": 5, "pleas": 11, "plot": [4, 5, 6, 7, 8, 9, 11, 12], "plot_comparison_test_run": 9, "plot_reward": [8, 11, 12], "plot_run": 9, "plot_run_reward": 7, "plot_test_run": 9, "plt": [4, 5, 6, 7, 8, 9, 11, 12], "point": [4, 5], "polici": [0, 3, 5, 9, 10, 13], "policy_indic": [8, 12], "policy_kwarg": [5, 9], "policy_path": [3, 6], "policybehavior": [2, 3, 6, 7, 9, 11], "port": 6, "pose": [4, 5, 6, 8, 9, 11, 12], "posit": [3, 4, 6, 10], "possibl": 4, "possible_ag": 10, "post_wrapp": [4, 7], "pre": 5, "predefin": 2, "predict": [6, 10], "prefer": 2, "prevent": 2, "previou": 7, "print": [3, 5, 6, 7, 8, 9, 10, 11, 12], "print_evalut": 8, "print_reward": 11, "pro": 2, "prob_true_act": 7, "probabl": [4, 5, 7, 8, 9, 11, 12], "probe": 6, "proce": 7, "process": [2, 3, 6], "produc": 3, "progress": [5, 8, 9, 11, 12], "progress_bar": [2, 5, 7, 8, 9, 11, 12], "project": 2, "properti": [3, 5], "provid": [2, 7, 9], "push": 6, "py": [6, 9], "pyplot": [4, 5, 6, 7, 8, 9, 11, 12], "pyplot_help": 9, "python": 2, "python3": [6, 9], "pz": [2, 3, 5, 8, 10, 12], "pz_util": [5, 12], "qualit": 5, "qualiti": 4, "quantil": 9, "queue": 3, "quit": [4, 9], "r": [5, 6, 8, 12], "rad": 4, "radii": 6, "radiu": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "random": [2, 3, 4, 6, 7, 9, 10], "randomli": [4, 5, 7], "randompolici": [6, 10], "rang": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "rare": 4, "read": [4, 6], "read_csv": [5, 8, 9, 11, 12], "readi": 5, "real": [3, 6], "realli": 5, "realtim": 3, "realtime_factor": [3, 6], "recent": 3, "record": [0, 6], "record_config": [4, 5, 6, 8, 9, 11, 12], "record_video": [5, 6], "record_video_from_run": [5, 8, 12], "recordconfig": 6, "recordprob": 6, "recordvideo": 6, "red": [5, 6, 7, 8, 9, 11, 12], "reduct": 3, "refer": [0, 11], "reflect": 2, "regist": 3, "reinforc": [1, 13], "rel": [4, 10], "relat": 3, "relative_margin": 5, "relev": 3, "relu": 3, "remind": 9, "remov": [3, 9], "removed_kei": 3, "render": [3, 10, 13], "render_fp": 6, "render_kwarg": [3, 6], "render_mod": [3, 6, 7, 11, 12], "replac": [2, 6], "replic": 3, "replicated_kei": 3, "repres": 10, "represent": 3, "requir": [1, 6, 11], "reset": [2, 4, 5, 6, 10], "reset_info": 6, "reset_num_timestep": 5, "reshap": 4, "resiz": 6, "resolut": 10, "resolv": 2, "respect": [5, 6], "respons": 2, "rest": 2, "result": [2, 5, 7], "return": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12], "return_episode_reward": [5, 9], "return_mean": [8, 9], "rew": 4, "reward": [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "reward_mean": [7, 8, 11], "reward_std_dev": [7, 8, 11], "rewardprob": [3, 6], "rexasi": 2, "rgb_arrai": [3, 6, 7, 11, 12], "right": 4, "rl": [0, 2, 5, 8, 9, 13], "rm": 2, "rng": [4, 7, 9], "ro": 6, "robot": 2, "robust": 12, "roll": [5, 8], "rollout": [4, 5, 7, 8, 9, 11, 12], "rollout_round_min_episod": [8, 9], "rolloutinfowrapp": [4, 7], "ros2_w": 6, "ros_jazzi": [6, 9], "rotation_tau": 6, "row": 9, "rt_env": 6, "rule": 4, "run": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12], "run_index": [7, 8, 9, 11, 12], "runtim": 5, "sa": 8, "sa_dagger_train": 8, "sa_env": 8, "sa_model": 12, "sa_venv": 8, "sac": [2, 5, 11, 12, 13], "sac_": 5, "sac_reward": 9, "safe": 4, "safeti": [4, 6], "safety_margin": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sai": 10, "same": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sampl": [5, 6, 10], "sampler": 5, "samples_so_far": [7, 9], "save": [2, 3, 5, 8, 9, 11, 12], "save_fold": 8, "sb3": [3, 10, 11], "scanner": 10, "scenario": [0, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13], "search": [0, 9], "second": [8, 9, 10, 11, 12], "second_group": 10, "see": [2, 3, 4, 6, 7], "seed": [2, 3, 4, 6, 7, 8, 9, 11, 12], "seem": [4, 5, 6, 7, 8, 11, 12], "select": [1, 2, 3, 6, 10], "self": [5, 6], "sens": [2, 4], "sensingst": [2, 3], "sensor": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "separ": 3, "sequenc": 3, "set": [2, 3, 5, 9], "set_logg": [5, 9, 11, 12], "set_optimal_angular_spe": 5, "set_tick_param": [7, 8, 11, 12], "set_titl": 6, "set_xlabel": 4, "set_xlim": 4, "set_xticklabel": 4, "set_ylabel": 4, "set_ylim": 4, "set_ytick": [7, 8, 11, 12], "set_yticklabel": 4, "setup": [4, 5, 6, 7, 11], "sever": [2, 6], "shape": [3, 6], "share": [2, 3, 10, 12], "shared_parallel_env": [2, 3, 5, 8, 10, 12], "short": 6, "should": [4, 5], "show": [6, 7, 8], "showcas": [6, 10], "side": [4, 5, 6, 7, 8, 10, 11, 12], "signal": 3, "significantli": [11, 12], "sim": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "similar": 2, "similarli": 2, "simpl": 4, "simpledaggertrain": 3, "simpler": [2, 5], "simpli": 6, "simplif": 2, "simplifi": [2, 3, 7], "simul": [2, 3, 6, 7, 9, 10], "sin": 5, "sinc": 9, "singl": [2, 4, 12, 13], "sinusoid": 5, "site": [6, 9], "size": [3, 4, 6], "slice": [3, 8, 10, 12], "slighti": 7, "slightli": [2, 6, 12], "sm": 5, "small": 9, "smaller": 3, "so": 2, "social_margin": [3, 6], "social_reward": 4, "socialreward": [3, 5, 6, 7, 8, 9, 10, 11, 12], "sole": [3, 12], "some": [2, 6, 7], "someth": 11, "sometim": 4, "sorri": [4, 5, 6, 7, 8, 11, 12], "sourc": 6, "space": [2, 3, 6, 10, 11], "spawn": 2, "spec": 6, "specif": 2, "specifi": [2, 3, 6, 11], "speed": [0, 3, 4, 6, 8, 10, 13], "speed_toler": [5, 6, 7, 8, 10, 11, 12], "squar": 5, "src": [6, 9], "stabl": [1, 2, 6], "stable_baselines3": [2, 5, 6, 7, 8, 9, 10, 11, 12], "stack": [3, 10], "stai": 6, "standard": 2, "start": [4, 5, 6, 7, 8, 9, 11, 12], "state": [2, 3, 6, 10], "state_estim": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12], "std": [4, 8, 11, 12], "step": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "still": 2, "str": [3, 5], "straight": [4, 6], "stream": 5, "stuck_timeout": 3, "sub": 2, "subclass": 2, "submodul": 3, "subplot": [4, 6, 9], "suitabl": 2, "sum": [3, 4, 5], "super": [5, 6], "supersuit": [1, 2, 10], "support": [2, 4, 5, 6, 7, 8, 11, 12], "suptitl": 4, "sv": 5, "svg_color": 5, "system": 2, "t": [2, 4, 5, 6, 7, 8, 11, 12], "take": [4, 8, 9], "taken": 2, "targer": [4, 5], "target": [2, 3, 4, 13], "target_angular_spe": 5, "target_margin": [6, 7, 8, 10, 11, 12], "target_spe": 5, "task": [2, 4, 12], "tau": [4, 5, 6, 7, 8, 9, 10, 11, 12], "tb_log_nam": [9, 11, 12], "te": 4, "tensor": 3, "tensorboard": [8, 9, 11, 12], "term": 5, "termin": [2, 3, 6, 10], "terminate_outside_bound": [3, 5, 8, 12], "test": [5, 12, 13], "test_env": 5, "test_mod": 5, "test_venv": 9, "than": [3, 4, 12], "thei": [5, 10], "them": [2, 6], "therefor": [2, 5, 6, 10], "thi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "think": 2, "those": 2, "three": 9, "through": 3, "thymio": [4, 5, 6, 7, 8, 9, 10, 11, 12], "tick_param": 4, "time": [2, 3, 4, 5, 6, 8, 9, 11, 12], "time_step": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "timeit": 4, "timestamp": 5, "titl": [4, 5, 6, 7, 8, 9, 11, 12], "to_html": 6, "to_list": [8, 12], "togeth": [2, 3, 10], "toler": [6, 7, 8, 10, 11, 12], "too": [2, 4, 5, 7], "took": [8, 9, 11, 12], "tool": [2, 6], "top": 4, "torch": 3, "total": 7, "total_step": [7, 8, 11], "total_timestep": [2, 5, 8, 9, 11, 12], "toward": [4, 6], "tqdm": [8, 9], "tr": 4, "train": [0, 3, 5, 9, 13], "trainer": [2, 3, 7, 8, 9], "trajectori": [4, 6, 7], "trajectorywithrew": 3, "trajectoti": 4, "trane": 7, "transit": [4, 7], "travel": 4, "treat": 3, "trivial": 4, "true": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "truncat": [2, 3, 6, 10], "try": [4, 6, 9, 12], "tupl": [3, 6, 10], "turn": 2, "tutori": [0, 2, 5, 6, 7, 11, 12], "twist2": [2, 10], "two": [2, 6, 9, 13], "type": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "typic": [2, 4], "u": [4, 5, 6, 7, 10], "ui": [3, 4, 5, 6, 7, 8, 11, 12], "uint8": [3, 6, 10], "under": 3, "underli": 2, "unif_speed_hl": 5, "unif_speed_sac": 5, "uniform": 13, "uniform_env": 5, "uniform_reward": 5, "uniform_scenario": 5, "uniform_speed_hl_reward": 5, "uniform_speed_model": 5, "uniform_speed_sac_reward": 5, "uniform_venv": 5, "union": 2, "until": 2, "unwrap": [6, 7, 8, 9, 11, 12], "up": [3, 8], "updat": [2, 4, 6], "update_static_obstacl": [4, 9], "upper": 3, "us": [0, 1, 3, 4, 10, 13], "use_acceleration_act": [3, 4, 5, 6, 8, 9, 10, 11, 12], "use_first_reward": 3, "use_wheel": [3, 6], "user": [6, 9], "userwarn": [6, 9], "usual": 5, "util": [4, 7, 8, 9], "v": 10, "v1": [6, 9], "valid": [2, 3, 6, 10], "valu": [3, 4, 5, 6, 8, 9, 10, 11, 12], "variabl": [3, 9], "variat": 3, "varyoptimalspe": 5, "vec_env": [5, 12], "vecmonitor": [5, 12], "vector": [2, 3, 7, 10, 13], "veloc": [3, 5, 6, 10], "venv": [4, 6, 7, 8, 9, 10, 12], "venv1": 10, "verbos": [2, 3, 7, 11, 12], "veri": [2, 4], "version": [6, 10], "via": 3, "video": [4, 5, 6, 7, 8, 11, 12], "video_env": 6, "video_fold": 6, "view": [2, 6], "violat": [4, 6, 9], "visibl": 4, "wa": 2, "wai": [2, 4], "wall": 4, "want": [4, 6, 10], "warn": [6, 7, 8, 9, 11, 12], "waypoint": 6, "we": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "websocket": 3, "webui": 3, "well": [5, 7], "what": [5, 6], "wheel": [3, 5], "wheel_axi": [4, 5, 6, 7, 8, 9, 10, 11, 12], "when": [3, 4, 6, 9], "where": [2, 4, 5, 6, 10, 12], "whether": [2, 3], "which": [2, 3, 4, 5, 6, 7, 10, 12], "while": [2, 4, 6, 10], "whole": [4, 12], "whose": 2, "width": [3, 4, 6, 9], "window": [5, 6, 8], "with_shap": 9, "with_world": 9, "work": [2, 5], "world": [2, 3, 4, 5, 6, 7, 8, 11, 12], "worldconfig": [3, 5, 10], "wors": 12, "worst": 9, "would": 5, "wrap": [2, 6], "wrapper": [2, 4, 6, 7, 9], "wrong": 4, "x": [4, 6, 9, 11, 12], "xlabel": [4, 5, 7, 8, 9, 11, 12], "xlim": 9, "y": [4, 5, 6, 8, 9, 11, 12], "yaml": [2, 3], "yaxi": [7, 8, 11, 12], "yellow": 5, "yet": 2, "ylabel": [4, 5, 7, 8, 9, 11, 12], "you": [2, 9], "your": [4, 5, 6, 7, 8, 11, 12], "zip": [4, 6, 8, 12], "\u00b5": 4}, "titles": ["Welcome to navground_learning\u2019s documentation!", "Installation", "Introduction", "Reference", "Navigate along a corridor with one obstacle: scenario", "Crossings with different speeds", "Navground-Gymnasium integration", "Train a policy using Imitation Learning", "Train a policy using Imitation Learning part 2: DAgger", "Navigate along a corridor with one obstacle: learning", "Navground-PettingZoo integration", "Train a policy using RL", "Train a policy using RL, part 2: multi-agent environment", "Tutorials"], "titleterms": {"": 0, "2": [8, 12], "A": 10, "acknowledg": 2, "action": 3, "agent": [3, 8, 12], "along": [4, 9], "analysi": 8, "bc": 8, "behavior": [3, 9], "clone": [3, 9], "comparis": 9, "configur": 3, "content": 0, "convert": 10, "corridor": [4, 9], "corridorwithobstacl": 3, "cross": 5, "dagger": [3, 8, 9], "data": 3, "differ": 5, "disclaim": 2, "document": 0, "end": 3, "env": 10, "enviro": [], "environ": [2, 3, 6, 8, 12], "evalu": 3, "experi": 3, "forward": 3, "function": 3, "group": 10, "gymnasium": [2, 3, 6, 10], "hl": 9, "imit": [2, 3, 7, 8, 9], "indic": 0, "individu": 5, "infer": 3, "instal": 1, "integr": [2, 6, 10], "introduct": 2, "learn": [2, 3, 7, 8, 9, 11, 12], "ml": 2, "model": 3, "modul": 3, "multi": [3, 8, 12], "navground": [2, 6, 7, 10], "navground_learn": 0, "navig": [4, 9], "null": 3, "observ": 3, "obstacl": [4, 9], "one": [4, 9], "part": [8, 12], "pettingzoo": [2, 3, 10], "polici": [2, 6, 7, 8, 11, 12], "probe": 3, "record": 3, "refer": 3, "reinforc": [2, 9], "render": 6, "reward": 3, "rl": [11, 12], "rollout": 3, "sac": 9, "scenario": [3, 4], "singl": [3, 8, 10], "social": 3, "speed": 5, "system": 3, "tabl": 0, "target": 5, "test": 7, "train": [2, 7, 8, 11, 12], "tutori": 13, "two": 10, "uniform": 5, "us": [2, 6, 7, 8, 11, 12], "vector": 6, "welcom": 0}})