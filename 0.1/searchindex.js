Search.setIndex({"alltitles": {"A single group": [[21, "A-single-group"]], "Acknowledgement and disclaimer": [[4, "acknowledgement-and-disclaimer"]], "Actions": [[5, "actions"]], "Base class": [[5, "base-class"], [5, "id1"], [9, "base-class"]], "Basics": [[22, null]], "Behavior Cloning": [[9, "behavior-cloning"], [28, "Behavior-Cloning"], [29, "Behavior-Cloning"]], "Behavior Modulation": [[5, "behavior-modulation"]], "Behaviors": [[13, "behaviors"]], "Comparision with HL": [[23, "Comparision-with-HL"]], "Configuration": [[5, null]], "Configurations": [[0, "configurations"]], "Contents:": [[1, null], [2, null]], "Convert from a Gymnasium Env": [[21, "Convert-from-a-Gymnasium-Env"]], "Convert to a Gymnasium Env": [[21, "Convert-to-a-Gymnasium-Env"]], "Corridor": [[8, "corridor"]], "Corridor with obstacle": [[25, null]], "CorridorWithObstacle": [[13, "corridorwithobstacle"]], "Creating an enviroment": [[31, "Creating-an-enviroment"]], "Crossing": [[8, "crossing"], [30, null]], "DAgger": [[9, "dagger"], [28, "DAgger"], [29, "DAgger"]], "Default": [[5, "default"]], "Defining a scenario": [[31, "Defining-a-scenario"]], "Different speeds": [[33, null]], "Efficacy": [[17, "efficacy"]], "Empty environment": [[31, null]], "End-to-end": [[5, "end-to-end"]], "Environment": [[28, "Environment"], [29, "Environment"], [33, "Environment"], [34, "Environment"]], "Evaluating the policies": [[31, "Evaluating-the-policies"]], "Evaluation": [[4, "evaluation"], [7, null]], "Examples": [[8, null]], "Experiments": [[7, "experiments"]], "Exporting": [[14, "exporting"]], "Exporting the trained policy": [[31, "Exporting-the-trained-policy"]], "Final video": [[26, "Final-video"]], "Forward": [[13, "forward"]], "Group": [[5, "group"]], "Guides": [[1, null]], "Gymnasium": [[4, "gymnasium"]], "Gymnasium Environment": [[20, null]], "How to extend": [[0, null]], "Human-like behavior": [[29, "Human-like-behavior"]], "Imitation Learning": [[4, "imitation-learning"], [9, null], [31, "Imitation-Learning"]], "Imitation Learning with Behavior Cloning": [[23, "Imitation-Learning-with-Behavior-Cloning"]], "Imitation learning with DAgger": [[23, "Imitation-learning-with-DAgger"]], "Indices": [[11, null]], "Indices and tables": [[2, "indices-and-tables"]], "Inference": [[14, "inference"]], "Info": [[16, "info"]], "Installation": [[3, null]], "Introduction": [[4, null]], "Learning": [[23, null]], "Logging": [[7, "logging"]], "More agents following the policy": [[27, "More-agents-following-the-policy"]], "Multi-agent Pettingzoo Environment": [[15, null]], "Navground": [[4, "navground"]], "Navground Components": [[0, "navground-components"], [13, null]], "Navground Gymnasium Environment": [[4, "navground-gymnasium-environment"]], "Navground policy": [[7, "navground-policy"], [20, "Navground-policy"]], "Navground-Gymnasium integration": [[4, "navground-gymnasium-integration"]], "Navground-PettingZoo integration": [[21, null]], "Null": [[16, "null"], [17, "null"]], "Observations": [[5, "observations"]], "One agent following the policy": [[27, "One-agent-following-the-policy"]], "Onnx": [[14, null]], "Ordering-invariant extractor": [[16, "ordering-invariant-extractor"]], "Parallel Multi-agent Learning": [[4, "parallel-multi-agent-learning"]], "Performance of policies trained in multi-agent environment": [[26, null]], "Performance of policies trained in single-agent environment": [[27, null]], "Periodic Crossing": [[35, null]], "PettingZoo": [[4, "pettingzoo"]], "PettingZoo Navground Environment": [[4, "pettingzoo-navground-environment"]], "Policies": [[7, "policies"], [16, null]], "Policy": [[7, "policy"]], "PolicyBehavior": [[13, "policybehavior"]], "Pre-trained SA policies": [[28, "Pre-trained-SA-policies"]], "Probes": [[13, "probes"]], "Random": [[16, "random"]], "Reference": [[10, null]], "Reinforcement Learning": [[4, "reinforcement-learning"], [31, "Reinforcement-Learning"]], "Reinforcement learning with SAC": [[23, "Reinforcement-learning-with-SAC"]], "Rendering": [[20, "Rendering"]], "Reward": [[26, "Reward"]], "Rewards functions": [[17, null]], "SAC": [[28, "SAC"], [29, "SAC"]], "Saving and Loading": [[12, null]], "Saving and loading": [[20, "Saving-and-loading"], [21, "Saving-and-loading"]], "Scenario": [[24, null], [29, "Scenario"], [33, "Scenario"], [34, "Scenario"]], "Scenarios": [[7, "scenarios"], [13, "scenarios"]], "Sensor": [[24, "Sensor"]], "Single-agent Gymnasium Environment": [[6, null]], "Social": [[17, "social"]], "Summary": [[28, "Summary"], [29, "Summary"]], "Train ML policies in navground": [[4, "train-ml-policies-in-navground"]], "Training": [[28, "Training"], [29, "Training"], [33, "Training"], [34, "Training"]], "Training agents among peers": [[28, null]], "Training one agent among many agents": [[29, null]], "Training policies": [[31, "Training-policies"]], "Tutorials": [[32, null]], "Two groups": [[21, "Two-groups"]], "Types": [[18, null]], "Uniform speeds": [[34, null]], "Use ML policies in navground": [[4, "use-ml-policies-in-navground"]], "Using a ML policy in Navground": [[19, null]], "Using the policies in navground": [[31, "Using-the-policies-in-navground"]], "Utilities": [[9, "utilities"]], "Varying target speed at runtime": [[33, "Varying-target-speed-at-runtime"]], "Vectorized environments": [[20, "Vectorized-environments"]], "Video": [[26, "Video"]], "Welcome to navground_learning\u2019s documentation!": [[2, null]], "Wrappers": [[20, "Wrappers"]]}, "docnames": ["guides/extend", "guides/index", "index", "installation", "introduction", "reference/config", "reference/env", "reference/evaluation", "reference/examples", "reference/il", "reference/index", "reference/indices", "reference/io", "reference/navground", "reference/onnx", "reference/parallel_env", "reference/policies", "reference/rewards", "reference/types", "tutorials/basics/Behavior", "tutorials/basics/Gymnasium", "tutorials/basics/PettingZoo", "tutorials/basics/index", "tutorials/corridor_with_obstacle/Learning", "tutorials/corridor_with_obstacle/Scenario", "tutorials/corridor_with_obstacle/index", "tutorials/crossing/Analysis-MA", "tutorials/crossing/Analysis-SA", "tutorials/crossing/Training-MA", "tutorials/crossing/Training-SA", "tutorials/crossing/index", "tutorials/empty/empty", "tutorials/index", "tutorials/periodic_crossing/DifferentSpeed", "tutorials/periodic_crossing/SameSpeed", "tutorials/periodic_crossing/index"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["guides/extend.rst", "guides/index.rst", "index.rst", "installation.rst", "introduction.rst", "reference/config.rst", "reference/env.rst", "reference/evaluation.rst", "reference/examples.rst", "reference/il.rst", "reference/index.rst", "reference/indices.rst", "reference/io.rst", "reference/navground.rst", "reference/onnx.rst", "reference/parallel_env.rst", "reference/policies.rst", "reference/rewards.rst", "reference/types.rst", "tutorials/basics/Behavior.ipynb", "tutorials/basics/Gymnasium.ipynb", "tutorials/basics/PettingZoo.ipynb", "tutorials/basics/index.rst", "tutorials/corridor_with_obstacle/Learning.ipynb", "tutorials/corridor_with_obstacle/Scenario.ipynb", "tutorials/corridor_with_obstacle/index.rst", "tutorials/crossing/Analysis-MA.ipynb", "tutorials/crossing/Analysis-SA.ipynb", "tutorials/crossing/Training-MA.ipynb", "tutorials/crossing/Training-SA.ipynb", "tutorials/crossing/index.rst", "tutorials/empty/empty.ipynb", "tutorials/index.rst", "tutorials/periodic_crossing/DifferentSpeed.ipynb", "tutorials/periodic_crossing/SameSpeed.ipynb", "tutorials/periodic_crossing/index.rst"], "indexentries": {"__call__() (reward method)": [[18, "navground.learning.types.Reward.__call__", false]], "accept_info() (in module navground.learning.types)": [[18, "navground.learning.types.accept_info", false]], "action (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.action", false]], "action (in module navground.learning.types)": [[18, "navground.learning.types.Action", false]], "action_space (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.action_space", false]], "action_space (onnxpolicy property)": [[14, "navground.learning.onnx.OnnxPolicy.action_space", false]], "actionconfig (class in navground.learning.config)": [[5, "navground.learning.config.ActionConfig", false]], "all() (indices class method)": [[11, "navground.learning.indices.Indices.all", false]], "anypolicy (in module navground.learning.il)": [[9, "navground.learning.il.AnyPolicy", false]], "anypolicypredictor (in module navground.learning.types)": [[18, "navground.learning.types.AnyPolicyPredictor", false]], "array (in module navground.learning.types)": [[18, "navground.learning.types.Array", false]], "as_set() (indices method)": [[11, "navground.learning.indices.Indices.as_set", false]], "asdict (groupconfig property)": [[5, "navground.learning.config.GroupConfig.asdict", false]], "asdict (indices property)": [[11, "navground.learning.indices.Indices.asdict", false]], "asdict (multiagentnavgroundenv property)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.asdict", false]], "asdict (navgroundenv property)": [[6, "navground.learning.env.NavgroundEnv.asdict", false]], "baseenv (in module navground.learning.env)": [[6, "navground.learning.env.BaseEnv", false]], "baseilalgorithm (class in navground.learning.il)": [[9, "navground.learning.il.BaseILAlgorithm", false]], "baseparallelenv (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.BaseParallelEnv", false]], "bc (class in navground.learning.il)": [[9, "navground.learning.il.BC", false]], "bounds (in module navground.learning.types)": [[18, "navground.learning.types.Bounds", false]], "clone() (policybehavior method)": [[13, "navground.learning.behaviors.PolicyBehavior.clone", false]], "clone_behavior() (policybehavior class method)": [[13, "navground.learning.behaviors.PolicyBehavior.clone_behavior", false]], "collect_runs() (bc method)": [[9, "navground.learning.il.BC.collect_runs", false]], "color (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.color", false]], "config_eval_log() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.config_eval_log", false]], "configure() (actionconfig method)": [[5, "navground.learning.config.ActionConfig.configure", false]], "configure() (observationconfig method)": [[5, "navground.learning.config.ObservationConfig.configure", false]], "controlactionconfig (class in navground.learning.config)": [[5, "navground.learning.config.ControlActionConfig", false]], "corridorwithobstacle (class in navground.learning.scenarios)": [[13, "navground.learning.scenarios.CorridorWithObstacle", false]], "dagger (class in navground.learning.il)": [[9, "navground.learning.il.DAgger", false]], "defaultobservationconfig (class in navground.learning.config)": [[5, "navground.learning.config.DefaultObservationConfig", false]], "deterministic (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.deterministic", false]], "deterministic (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.deterministic", false]], "dtype (rewardprobe attribute)": [[13, "navground.learning.probes.RewardProbe.dtype", false]], "efficacyreward (class in navground.learning.rewards)": [[17, "navground.learning.rewards.EfficacyReward", false]], "env (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.env", false]], "episodestart (in module navground.learning.types)": [[18, "navground.learning.types.EpisodeStart", false]], "evaluate() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate", false]], "evaluate_policies() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate_policies", false]], "evaluate_policy() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate_policy", false]], "evaluate_with_experiment() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate_with_experiment", false]], "evaluate_with_experiment_and_env() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.evaluate_with_experiment_and_env", false]], "export() (in module navground.learning.onnx)": [[14, "navground.learning.onnx.export", false]], "export_behavior() (in module navground.learning.io)": [[12, "navground.learning.io.export_behavior", false]], "export_policy_as_behavior() (in module navground.learning.io)": [[12, "navground.learning.io.export_policy_as_behavior", false]], "fix_orientation (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.fix_orientation", false]], "fix_orientation (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.fix_orientation", false]], "flat (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.flat", false]], "flat (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.flat", false]], "forwardscenario (class in navground.learning.scenarios)": [[13, "navground.learning.scenarios.ForwardScenario", false]], "from_dict() (indices class method)": [[11, "navground.learning.indices.Indices.from_dict", false]], "from_dict() (multiagentnavgroundenv class method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.from_dict", false]], "from_dict() (navgroundenv class method)": [[6, "navground.learning.env.NavgroundEnv.from_dict", false]], "generate_trajectories() (in module navground.learning.il.rollout)": [[9, "navground.learning.il.rollout.generate_trajectories", false]], "get_action() (actionconfig method)": [[5, "navground.learning.config.ActionConfig.get_action", false]], "get_cmd_from_action() (actionconfig method)": [[5, "navground.learning.config.ActionConfig.get_cmd_from_action", false]], "get_env() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.get_env", false]], "get_env() (in module navground.learning.examples.corridor_with_obstacle)": [[8, "navground.learning.examples.corridor_with_obstacle.get_env", false]], "get_env() (in module navground.learning.examples.cross)": [[8, "navground.learning.examples.cross.get_env", false]], "get_policy() (multiagentnavgroundenv method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.get_policy", false]], "groupconfig (class in navground.learning.config)": [[5, "navground.learning.config.GroupConfig", false]], "gymprobe (class in navground.learning.probes)": [[13, "navground.learning.probes.GymProbe", false]], "has_wheels (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.has_wheels", false]], "history (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.history", false]], "history (observationconfig property)": [[5, "navground.learning.config.ObservationConfig.history", false]], "history (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.history", false]], "include_angular_speed (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_angular_speed", false]], "include_radius (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_radius", false]], "include_radius (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_radius", false]], "include_target_angular_speed (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_angular_speed", false]], "include_target_angular_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_angular_speed", false]], "include_target_direction (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_direction", false]], "include_target_direction (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_direction", false]], "include_target_direction_validity (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_direction_validity", false]], "include_target_direction_validity (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_direction_validity", false]], "include_target_distance (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_distance", false]], "include_target_distance (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_distance", false]], "include_target_distance_validity (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_distance_validity", false]], "include_target_distance_validity (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_distance_validity", false]], "include_target_speed (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_target_speed", false]], "include_target_speed (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_target_speed", false]], "include_velocity (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.include_velocity", false]], "include_velocity (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.include_velocity", false]], "indices (class in navground.learning.indices)": [[11, "navground.learning.indices.Indices", false]], "indices (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.indices", false]], "indiceslike (in module navground.learning.indices)": [[18, "navground.learning.indices.IndicesLike", false]], "info (in module navground.learning.types)": [[18, "navground.learning.types.Info", false]], "infopolicy (class in navground.learning.policies.info_predictor)": [[16, "navground.learning.policies.info_predictor.InfoPolicy", false]], "init_args (multiagentnavgroundenv property)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.init_args", false]], "init_args (navgroundenv property)": [[6, "navground.learning.env.NavgroundEnv.init_args", false]], "init_world() (corridorwithobstacle method)": [[13, "navground.learning.scenarios.CorridorWithObstacle.init_world", false]], "init_world() (forwardscenario method)": [[13, "navground.learning.scenarios.ForwardScenario.init_world", false]], "initpolicybehavior (class in navground.learning.evaluation)": [[7, "navground.learning.evaluation.InitPolicyBehavior", false]], "intersect() (indices method)": [[11, "navground.learning.indices.Indices.intersect", false]], "is_configured() (actionconfig method)": [[5, "navground.learning.config.ActionConfig.is_configured", false]], "is_configured() (observationconfig method)": [[5, "navground.learning.config.ObservationConfig.is_configured", false]], "learn() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.learn", false]], "length (corridorwithobstacle property)": [[13, "navground.learning.scenarios.CorridorWithObstacle.length", false]], "load() (baseilalgorithm class method)": [[9, "navground.learning.il.BaseILAlgorithm.load", false]], "load_behavior() (in module navground.learning.io)": [[12, "navground.learning.io.load_behavior", false]], "load_env() (in module navground.learning.io)": [[12, "navground.learning.io.load_env", false]], "logger (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.logger", false]], "lowest (indices property)": [[11, "navground.learning.indices.Indices.lowest", false]], "make_experiment() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.make_experiment", false]], "make_experiment_with_env() (in module navground.learning.evaluation)": [[7, "navground.learning.evaluation.make_experiment_with_env", false]], "make_order_invariant_flatten_extractor() (in module navground.learning.policies.order_invariant)": [[16, "navground.learning.policies.order_invariant.make_order_invariant_flatten_extractor", false]], "make_shared_parallel_env_with_env() (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.make_shared_parallel_env_with_env", false]], "make_vec_from_env() (in module navground.learning.il)": [[9, "navground.learning.il.make_vec_from_env", false]], "make_vec_from_penv() (in module navground.learning.il)": [[9, "navground.learning.il.make_vec_from_penv", false]], "make_vec_from_penv() (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.make_vec_from_penv", false]], "max_acceleration (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.max_acceleration", false]], "max_acceleration (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.max_acceleration", false]], "max_angular_acceleration (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.max_angular_acceleration", false]], "max_angular_acceleration (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.max_angular_acceleration", false]], "max_radius (corridorwithobstacle property)": [[13, "navground.learning.scenarios.CorridorWithObstacle.max_radius", false]], "max_radius (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.max_radius", false]], "max_target_distance (defaultobservationconfig attribute)": [[5, "navground.learning.config.DefaultObservationConfig.max_target_distance", false]], "merge_groups_configs() (in module navground.learning.config)": [[5, "navground.learning.config.merge_groups_configs", false]], "min_radius (corridorwithobstacle property)": [[13, "navground.learning.scenarios.CorridorWithObstacle.min_radius", false]], "modulationactionconfig (class in navground.learning.config)": [[5, "navground.learning.config.ModulationActionConfig", false]], "module": [[5, "module-navground.learning.config", false], [6, "module-navground.learning.env", false], [7, "module-navground.learning.evaluation", false], [8, "module-navground.learning.examples", false], [8, "module-navground.learning.examples.corridor_with_obstacle", false], [8, "module-navground.learning.examples.cross", false], [9, "module-navground.learning.il", false], [10, "module-navground.learning", false], [11, "module-navground.learning.indices", false], [12, "module-navground.learning.io", false], [13, "module-navground.learning.behaviors", false], [13, "module-navground.learning.probes", false], [13, "module-navground.learning.scenarios", false], [14, "module-navground.learning.onnx", false], [15, "module-navground.learning.parallel_env", false], [16, "module-navground.learning.policies", false], [18, "module-navground.learning.types", false]], "multiagentnavgroundenv (class in navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv", false]], "navground.learning": [[10, "module-navground.learning", false]], "navground.learning.behaviors": [[13, "module-navground.learning.behaviors", false]], "navground.learning.config": [[5, "module-navground.learning.config", false]], "navground.learning.env": [[6, "module-navground.learning.env", false]], "navground.learning.evaluation": [[7, "module-navground.learning.evaluation", false]], "navground.learning.examples": [[8, "module-navground.learning.examples", false]], "navground.learning.examples.corridor_with_obstacle": [[8, "module-navground.learning.examples.corridor_with_obstacle", false]], "navground.learning.examples.cross": [[8, "module-navground.learning.examples.cross", false]], "navground.learning.il": [[9, "module-navground.learning.il", false]], "navground.learning.indices": [[11, "module-navground.learning.indices", false]], "navground.learning.io": [[12, "module-navground.learning.io", false]], "navground.learning.onnx": [[14, "module-navground.learning.onnx", false]], "navground.learning.parallel_env": [[15, "module-navground.learning.parallel_env", false]], "navground.learning.policies": [[16, "module-navground.learning.policies", false]], "navground.learning.probes": [[13, "module-navground.learning.probes", false]], "navground.learning.scenarios": [[13, "module-navground.learning.scenarios", false]], "navground.learning.types": [[18, "module-navground.learning.types", false]], "navgroundenv (class in navground.learning.env)": [[6, "navground.learning.env.NavgroundEnv", false]], "nullpolicy (class in navground.learning.policies.null_policy)": [[16, "navground.learning.policies.null_policy.NullPolicy", false]], "nullpredictor (class in navground.learning.policies.null_predictor)": [[16, "navground.learning.policies.null_predictor.NullPredictor", false]], "nullreward (class in navground.learning.rewards)": [[17, "navground.learning.rewards.NullReward", false]], "observation (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.observation", false]], "observation (in module navground.learning.types)": [[18, "navground.learning.types.Observation", false]], "observation_space (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.observation_space", false]], "observation_space (onnxpolicy property)": [[14, "navground.learning.onnx.OnnxPolicy.observation_space", false]], "observationconfig (class in navground.learning.config)": [[5, "navground.learning.config.ObservationConfig", false]], "onnxpolicy (class in navground.learning.onnx)": [[14, "navground.learning.onnx.OnnxPolicy", false]], "orderinvariantcombinedextractor (class in navground.learning.policies.order_invariant)": [[16, "navground.learning.policies.order_invariant.OrderInvariantCombinedExtractor", false]], "orderinvariantflattenextractor (class in navground.learning.policies.order_invariant)": [[16, "navground.learning.policies.order_invariant.OrderInvariantFlattenExtractor", false]], "parallel_env() (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.parallel_env", false]], "params (modulationactionconfig attribute)": [[5, "navground.learning.config.ModulationActionConfig.params", false]], "pathlike (in module navground.learning.types)": [[18, "navground.learning.types.PathLike", false]], "policy (baseilalgorithm property)": [[9, "navground.learning.il.BaseILAlgorithm.policy", false]], "policy (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.policy", false]], "policy (navgroundenv property)": [[6, "navground.learning.env.NavgroundEnv.policy", false]], "policy_path (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.policy_path", false]], "policybehavior (class in navground.learning.behaviors)": [[13, "navground.learning.behaviors.PolicyBehavior", false]], "policycallable (in module navground.learning.il)": [[9, "navground.learning.il.PolicyCallable", false]], "policycallablewithinfo (in module navground.learning.il)": [[9, "navground.learning.il.PolicyCallableWithInfo", false]], "policypredictor (class in navground.learning.types)": [[18, "navground.learning.types.PolicyPredictor", false]], "policypredictorwithinfo (class in navground.learning.types)": [[18, "navground.learning.types.PolicyPredictorWithInfo", false]], "predict() (onnxpolicy method)": [[14, "navground.learning.onnx.OnnxPolicy.predict", false]], "predict() (policypredictor method)": [[18, "navground.learning.types.PolicyPredictor.predict", false]], "predict() (policypredictorwithinfo method)": [[18, "navground.learning.types.PolicyPredictorWithInfo.predict", false]], "randompolicy (class in navground.learning.policies.random_policy)": [[16, "navground.learning.policies.random_policy.RandomPolicy", false]], "randompredictor (class in navground.learning.policies.random_predictor)": [[16, "navground.learning.policies.random_predictor.RandomPredictor", false]], "reduction (in module navground.learning.policies)": [[16, "navground.learning.policies.Reduction", false]], "reset() (multiagentnavgroundenv method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.reset", false]], "reset() (navgroundenv method)": [[6, "navground.learning.env.NavgroundEnv.reset", false]], "reward (class in navground.learning.types)": [[18, "navground.learning.types.Reward", false]], "reward (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.reward", false]], "rewardprobe (class in navground.learning.probes)": [[13, "navground.learning.probes.RewardProbe", false]], "save() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.save", false]], "save_env() (in module navground.learning.io)": [[12, "navground.learning.io.save_env", false]], "scenario (multiagentnavgroundenv property)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.scenario", false]], "scenario (navgroundenv property)": [[6, "navground.learning.env.NavgroundEnv.scenario", false]], "sensor (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.sensor", false]], "set_env() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.set_env", false]], "set_logger() (baseilalgorithm method)": [[9, "navground.learning.il.BaseILAlgorithm.set_logger", false]], "setup_tqdm() (in module navground.learning.il)": [[9, "navground.learning.il.setup_tqdm", false]], "shared_parallel_env() (in module navground.learning.parallel_env)": [[15, "navground.learning.parallel_env.shared_parallel_env", false]], "socialreward (class in navground.learning.rewards)": [[17, "navground.learning.rewards.SocialReward", false]], "space (actionconfig property)": [[5, "navground.learning.config.ActionConfig.space", false]], "space (controlactionconfig property)": [[5, "navground.learning.config.ControlActionConfig.space", false]], "space (modulationactionconfig property)": [[5, "navground.learning.config.ModulationActionConfig.space", false]], "state (in module navground.learning.types)": [[18, "navground.learning.types.State", false]], "step() (multiagentnavgroundenv method)": [[15, "navground.learning.parallel_env.MultiAgentNavgroundEnv.step", false]], "step() (navgroundenv method)": [[6, "navground.learning.env.NavgroundEnv.step", false]], "sub_dict() (indices method)": [[11, "navground.learning.indices.Indices.sub_dict", false]], "sub_sequence() (indices method)": [[11, "navground.learning.indices.Indices.sub_sequence", false]], "t (in module navground.learning.indices)": [[11, "navground.learning.indices.T", false]], "tag (groupconfig attribute)": [[5, "navground.learning.config.GroupConfig.tag", false]], "trajectoryplotconfig (class in navground.learning.evaluation)": [[7, "navground.learning.evaluation.TrajectoryPlotConfig", false]], "use_acceleration_action (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.use_acceleration_action", false]], "use_acceleration_action (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.use_acceleration_action", false]], "use_wheels (controlactionconfig attribute)": [[5, "navground.learning.config.ControlActionConfig.use_wheels", false]], "use_wheels (policybehavior property)": [[13, "navground.learning.behaviors.PolicyBehavior.use_wheels", false]], "videoconfig (class in navground.learning.evaluation)": [[7, "navground.learning.evaluation.VideoConfig", false]], "width (corridorwithobstacle property)": [[13, "navground.learning.scenarios.CorridorWithObstacle.width", false]], "with_env() (gymprobe class method)": [[13, "navground.learning.probes.GymProbe.with_env", false]], "with_env() (initpolicybehavior class method)": [[7, "navground.learning.evaluation.InitPolicyBehavior.with_env", false]], "with_reward() (rewardprobe class method)": [[13, "navground.learning.probes.RewardProbe.with_reward", false]]}, "objects": {"navground": [[10, 0, 0, "-", "learning"]], "navground.learning": [[13, 0, 0, "-", "behaviors"], [5, 0, 0, "-", "config"], [6, 0, 0, "-", "env"], [7, 0, 0, "-", "evaluation"], [8, 0, 0, "-", "examples"], [9, 0, 0, "-", "il"], [11, 0, 0, "-", "indices"], [12, 0, 0, "-", "io"], [14, 0, 0, "-", "onnx"], [15, 0, 0, "-", "parallel_env"], [16, 0, 0, "-", "policies"], [13, 0, 0, "-", "probes"], [13, 0, 0, "-", "scenarios"], [18, 0, 0, "-", "types"]], "navground.learning.behaviors": [[13, 1, 1, "", "PolicyBehavior"]], "navground.learning.behaviors.PolicyBehavior": [[13, 2, 1, "", "clone"], [13, 2, 1, "", "clone_behavior"], [13, 3, 1, "", "deterministic"], [13, 3, 1, "", "fix_orientation"], [13, 3, 1, "", "flat"], [13, 3, 1, "", "history"], [13, 3, 1, "", "include_radius"], [13, 3, 1, "", "include_target_angular_speed"], [13, 3, 1, "", "include_target_direction"], [13, 3, 1, "", "include_target_direction_validity"], [13, 3, 1, "", "include_target_distance"], [13, 3, 1, "", "include_target_distance_validity"], [13, 3, 1, "", "include_target_speed"], [13, 3, 1, "", "include_velocity"], [13, 3, 1, "", "max_acceleration"], [13, 3, 1, "", "max_angular_acceleration"], [13, 3, 1, "", "policy_path"], [13, 3, 1, "", "use_acceleration_action"], [13, 3, 1, "", "use_wheels"]], "navground.learning.config": [[5, 1, 1, "", "ActionConfig"], [5, 1, 1, "", "ControlActionConfig"], [5, 1, 1, "", "DefaultObservationConfig"], [5, 1, 1, "", "GroupConfig"], [5, 1, 1, "", "ModulationActionConfig"], [5, 1, 1, "", "ObservationConfig"], [5, 5, 1, "", "merge_groups_configs"]], "navground.learning.config.ActionConfig": [[5, 2, 1, "", "configure"], [5, 2, 1, "", "get_action"], [5, 2, 1, "", "get_cmd_from_action"], [5, 2, 1, "", "is_configured"], [5, 3, 1, "", "space"]], "navground.learning.config.ControlActionConfig": [[5, 4, 1, "", "fix_orientation"], [5, 4, 1, "", "has_wheels"], [5, 4, 1, "", "max_acceleration"], [5, 4, 1, "", "max_angular_acceleration"], [5, 3, 1, "", "space"], [5, 4, 1, "", "use_acceleration_action"], [5, 4, 1, "", "use_wheels"]], "navground.learning.config.DefaultObservationConfig": [[5, 4, 1, "", "flat"], [5, 4, 1, "", "history"], [5, 4, 1, "", "include_angular_speed"], [5, 4, 1, "", "include_radius"], [5, 4, 1, "", "include_target_angular_speed"], [5, 4, 1, "", "include_target_direction"], [5, 4, 1, "", "include_target_direction_validity"], [5, 4, 1, "", "include_target_distance"], [5, 4, 1, "", "include_target_distance_validity"], [5, 4, 1, "", "include_target_speed"], [5, 4, 1, "", "include_velocity"], [5, 4, 1, "", "max_radius"], [5, 4, 1, "", "max_target_distance"]], "navground.learning.config.GroupConfig": [[5, 4, 1, "", "action"], [5, 3, 1, "", "asdict"], [5, 4, 1, "", "color"], [5, 4, 1, "", "deterministic"], [5, 4, 1, "", "indices"], [5, 4, 1, "", "observation"], [5, 4, 1, "", "policy"], [5, 4, 1, "", "reward"], [5, 4, 1, "", "sensor"], [5, 4, 1, "", "tag"]], "navground.learning.config.ModulationActionConfig": [[5, 4, 1, "", "params"], [5, 3, 1, "", "space"]], "navground.learning.config.ObservationConfig": [[5, 2, 1, "", "configure"], [5, 3, 1, "", "history"], [5, 2, 1, "", "is_configured"]], "navground.learning.env": [[6, 6, 1, "", "BaseEnv"], [6, 1, 1, "", "NavgroundEnv"]], "navground.learning.env.NavgroundEnv": [[6, 3, 1, "", "asdict"], [6, 2, 1, "", "from_dict"], [6, 3, 1, "", "init_args"], [6, 3, 1, "", "policy"], [6, 2, 1, "", "reset"], [6, 3, 1, "", "scenario"], [6, 2, 1, "", "step"]], "navground.learning.evaluation": [[7, 1, 1, "", "InitPolicyBehavior"], [7, 1, 1, "", "TrajectoryPlotConfig"], [7, 1, 1, "", "VideoConfig"], [7, 5, 1, "", "config_eval_log"], [7, 5, 1, "", "evaluate"], [7, 5, 1, "", "evaluate_policies"], [7, 5, 1, "", "evaluate_policy"], [7, 5, 1, "", "evaluate_with_experiment"], [7, 5, 1, "", "evaluate_with_experiment_and_env"], [7, 5, 1, "", "make_experiment"], [7, 5, 1, "", "make_experiment_with_env"]], "navground.learning.evaluation.InitPolicyBehavior": [[7, 2, 1, "", "with_env"]], "navground.learning.examples": [[8, 0, 0, "-", "corridor_with_obstacle"], [8, 0, 0, "-", "cross"]], "navground.learning.examples.corridor_with_obstacle": [[8, 5, 1, "", "get_env"]], "navground.learning.examples.cross": [[8, 5, 1, "", "get_env"]], "navground.learning.il": [[9, 6, 1, "", "AnyPolicy"], [9, 1, 1, "", "BC"], [9, 1, 1, "", "BaseILAlgorithm"], [9, 1, 1, "", "DAgger"], [9, 6, 1, "", "PolicyCallable"], [9, 6, 1, "", "PolicyCallableWithInfo"], [9, 5, 1, "", "make_vec_from_env"], [9, 5, 1, "", "make_vec_from_penv"], [9, 5, 1, "", "setup_tqdm"]], "navground.learning.il.BC": [[9, 2, 1, "", "collect_runs"]], "navground.learning.il.BaseILAlgorithm": [[9, 3, 1, "", "action_space"], [9, 3, 1, "", "env"], [9, 2, 1, "", "get_env"], [9, 2, 1, "", "learn"], [9, 2, 1, "", "load"], [9, 3, 1, "", "logger"], [9, 3, 1, "", "observation_space"], [9, 3, 1, "", "policy"], [9, 2, 1, "", "save"], [9, 2, 1, "", "set_env"], [9, 2, 1, "", "set_logger"]], "navground.learning.il.rollout": [[9, 5, 1, "", "generate_trajectories"]], "navground.learning.indices": [[11, 1, 1, "", "Indices"], [18, 6, 1, "", "IndicesLike"], [11, 6, 1, "", "T"]], "navground.learning.indices.Indices": [[11, 2, 1, "", "all"], [11, 2, 1, "", "as_set"], [11, 3, 1, "", "asdict"], [11, 2, 1, "", "from_dict"], [11, 2, 1, "", "intersect"], [11, 3, 1, "", "lowest"], [11, 2, 1, "", "sub_dict"], [11, 2, 1, "", "sub_sequence"]], "navground.learning.io": [[12, 5, 1, "", "export_behavior"], [12, 5, 1, "", "export_policy_as_behavior"], [12, 5, 1, "", "load_behavior"], [12, 5, 1, "", "load_env"], [12, 5, 1, "", "save_env"]], "navground.learning.onnx": [[14, 1, 1, "", "OnnxPolicy"], [14, 5, 1, "", "export"]], "navground.learning.onnx.OnnxPolicy": [[14, 3, 1, "", "action_space"], [14, 3, 1, "", "observation_space"], [14, 2, 1, "", "predict"]], "navground.learning.parallel_env": [[15, 6, 1, "", "BaseParallelEnv"], [15, 1, 1, "", "MultiAgentNavgroundEnv"], [15, 5, 1, "", "make_shared_parallel_env_with_env"], [15, 5, 1, "", "make_vec_from_penv"], [15, 5, 1, "", "parallel_env"], [15, 5, 1, "", "shared_parallel_env"]], "navground.learning.parallel_env.MultiAgentNavgroundEnv": [[15, 3, 1, "", "asdict"], [15, 2, 1, "", "from_dict"], [15, 2, 1, "", "get_policy"], [15, 3, 1, "", "init_args"], [15, 2, 1, "", "reset"], [15, 3, 1, "", "scenario"], [15, 2, 1, "", "step"]], "navground.learning.policies": [[16, 6, 1, "", "Reduction"]], "navground.learning.policies.info_predictor": [[16, 1, 1, "", "InfoPolicy"]], "navground.learning.policies.null_policy": [[16, 1, 1, "", "NullPolicy"]], "navground.learning.policies.null_predictor": [[16, 1, 1, "", "NullPredictor"]], "navground.learning.policies.order_invariant": [[16, 1, 1, "", "OrderInvariantCombinedExtractor"], [16, 1, 1, "", "OrderInvariantFlattenExtractor"], [16, 5, 1, "", "make_order_invariant_flatten_extractor"]], "navground.learning.policies.random_policy": [[16, 1, 1, "", "RandomPolicy"]], "navground.learning.policies.random_predictor": [[16, 1, 1, "", "RandomPredictor"]], "navground.learning.probes": [[13, 1, 1, "", "GymProbe"], [13, 1, 1, "", "RewardProbe"]], "navground.learning.probes.GymProbe": [[13, 2, 1, "", "with_env"]], "navground.learning.probes.RewardProbe": [[13, 4, 1, "", "dtype"], [13, 2, 1, "", "with_reward"]], "navground.learning.rewards": [[17, 1, 1, "", "EfficacyReward"], [17, 1, 1, "", "NullReward"], [17, 1, 1, "", "SocialReward"]], "navground.learning.scenarios": [[13, 1, 1, "", "CorridorWithObstacle"], [13, 1, 1, "", "ForwardScenario"]], "navground.learning.scenarios.CorridorWithObstacle": [[13, 2, 1, "", "init_world"], [13, 3, 1, "", "length"], [13, 3, 1, "", "max_radius"], [13, 3, 1, "", "min_radius"], [13, 3, 1, "", "width"]], "navground.learning.scenarios.ForwardScenario": [[13, 2, 1, "", "init_world"]], "navground.learning.types": [[18, 6, 1, "", "Action"], [18, 6, 1, "", "AnyPolicyPredictor"], [18, 6, 1, "", "Array"], [18, 6, 1, "", "Bounds"], [18, 6, 1, "", "EpisodeStart"], [18, 6, 1, "", "Info"], [18, 6, 1, "", "Observation"], [18, 6, 1, "", "PathLike"], [18, 1, 1, "", "PolicyPredictor"], [18, 1, 1, "", "PolicyPredictorWithInfo"], [18, 1, 1, "", "Reward"], [18, 6, 1, "", "State"], [18, 5, 1, "", "accept_info"]], "navground.learning.types.PolicyPredictor": [[18, 2, 1, "", "predict"]], "navground.learning.types.PolicyPredictorWithInfo": [[18, 2, 1, "", "predict"]], "navground.learning.types.Reward": [[18, 2, 1, "", "__call__"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "type", "Python type alias"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function", "6": "py:type"}, "terms": {"": [4, 5, 6, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34], "0": [4, 6, 7, 8, 9, 11, 13, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35], "00": [20, 21, 23, 24, 29], "000": [24, 31], "000000": 21, "0000000e": [20, 21], "000946": 20, "007": 28, "00738173": [20, 21], "01": [4, 28], "01894906": [20, 21], "0199999996": 20, "02": [19, 20, 23, 24, 29, 30, 33, 34, 35], "023": 34, "03": 33, "034": [33, 34], "03823532": 20, "04": [23, 24, 29], "040": 34, "041": 28, "044": 29, "045": 34, "05": [24, 25, 29, 30], "054": 29, "056": 34, "06": [28, 33], "062": 33, "064": 28, "077": 29, "078": 34, "08": [20, 21, 24, 25, 29], "08671234": 31, "088": 21, "0939999968": 20, "094": [19, 20, 24, 25, 29, 30, 33, 34, 35], "097": 33, "0f": [23, 28, 29], "0x116b05b60": 9, "0x1336b32f0": 34, "0x13eb875c0": 31, "0x13f0d2b70": 31, "0x372f5d4c0": 28, "0x37a6eb290": 28, "1": [4, 5, 6, 7, 8, 9, 11, 13, 15, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35], "10": [3, 7, 13, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35], "100": [4, 7, 20, 21, 26, 27, 28, 29, 31, 33, 34], "1000": [4, 20, 21, 23, 24, 28, 29, 31], "10000": [4, 23], "100000": 21, "100000001": 20, "10000000149011612": 20, "100_000": [23, 29], "100k": 23, "101": [7, 19, 28, 29], "101070028": 4, "104335": 31, "10_000": [4, 23], "11": [19, 20, 21, 24, 27, 28, 29, 31, 33], "110": 7, "117": 21, "119999997": 20, "11999999731779099": 20, "12": [3, 7, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35], "120": [33, 34], "1200": [19, 33, 34], "120000": 21, "123": [23, 26], "125": 29, "128": [23, 28, 29, 33, 34], "13": [3, 20, 24, 27, 28, 29, 31, 33], "135": 34, "136": 34, "14": [20, 23, 24, 28, 31, 33], "15": [20, 21, 23, 24, 26, 27, 28, 29, 31], "15306982": [20, 21], "158": 24, "16": [20, 21, 23, 24, 28, 29, 31], "166": 28, "169": [24, 29], "17": [20, 21, 23, 24, 27, 28, 29, 31, 34], "170": [24, 27], "18": [20, 21, 23, 24, 27, 28, 29, 31], "180": 27, "1800": 26, "19": [19, 20, 21, 23, 24, 26, 27, 28, 29, 31], "190": 28, "194": 29, "1_000": 31, "1_000_000": 34, "1e": [23, 28, 29], "1h": 34, "2": [7, 11, 13, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35], "20": [8, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 34], "200": [7, 24, 28], "2000": [28, 29], "20000": 31, "202": 7, "2021": 4, "2025803": 20, "20_000": 31, "20k": 28, "21": [20, 21, 23, 24, 28, 29, 31], "211": 33, "22": [20, 21, 23, 24, 27, 28, 29, 31], "224": 29, "225": 28, "227": 28, "228": [27, 28], "23": [20, 21, 23, 24, 27, 28, 29, 31], "232": 27, "234": 27, "237": 20, "24": [20, 21, 23, 28, 29, 31], "243": 21, "246": 28, "249": 20, "25": [19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34], "250": 28, "255": [16, 20, 26, 27], "256": [16, 28, 29], "26": [20, 21, 23, 24, 26, 31, 34], "27": [20, 21, 23, 31], "28": [20, 21, 23, 26, 28, 31], "281": 28, "2831855": 21, "289": 20, "29": [20, 21, 23, 26, 29], "293": 29, "2f": [23, 24, 27, 28, 29], "2wdiff": [19, 20, 24, 25, 29, 30, 31, 33, 34, 35], "3": [3, 7, 11, 16, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "30": [7, 20, 23, 24, 26, 27, 29, 33, 34], "300": [7, 20, 24, 26, 27, 29, 31], "3000": 31, "305": 7, "30817246": [20, 21], "30k": 28, "31": [20, 33], "310": 27, "313": 7, "32": [9, 20, 23, 33], "32967997": [20, 21], "33": [20, 23], "335": 27, "34": [20, 23], "347": 29, "3484901": [20, 21], "349": 23, "35": [20, 23, 29], "352": 23, "357": 23, "36": [20, 23, 24], "360": [24, 31], "37": [20, 23, 31], "371": 23, "378": 24, "38": [20, 23], "386": 23, "38925827": [20, 21], "39": [20, 21, 23, 24, 31], "3_000_000": 33, "3d": 4, "3f": [20, 21, 33, 34], "4": [7, 11, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34], "40": [8, 20, 23, 24], "400": [19, 20, 26, 33, 34], "400k": [28, 29], "40k": 28, "41": 20, "415": 28, "42": [20, 28], "43": [20, 26], "44": 20, "45": 20, "46368217": [20, 21], "4778133": [20, 21], "48": [26, 28], "4916103": 31, "499": 29, "5": [4, 7, 11, 13, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35], "50": [23, 26, 27], "500": 23, "50000": 23, "5088892": [20, 21], "50k": 29, "51": 27, "51834273": 31, "52": 23, "54": 31, "553191": 21, "5531914234161377": 20, "56": 31, "57": 31, "5725663e": [20, 21], "599": 20, "5m": 33, "5x": 23, "6": [7, 11, 13, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34], "60": [19, 20, 21, 26, 27, 29, 31, 33], "600": [20, 21, 26, 27, 28, 29], "60000": 23, "614": 28, "62434775": [20, 21], "63": 29, "64": [23, 31], "640": 20, "641": 28, "65": [28, 29], "663": 28, "6674728": [20, 21], "673": 23, "68": 23, "7": [7, 19, 20, 21, 23, 24, 27, 28, 29, 31, 33, 34], "700k": 34, "71": [23, 24], "75": [23, 31], "750": [20, 23], "750_000": 28, "77": 23, "79": 31, "8": [16, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "8002": 20, "81": 31, "83333396911621": 24, "86": 23, "87": 23, "88": 23, "88362646": 31, "9": [19, 20, 21, 23, 24, 27, 28, 31, 33, 34], "90": [7, 26, 27], "900": 27, "91": 23, "912": 20, "936": 28, "95": [23, 24], "96512122": 20, "98": 23, "984": 20, "A": [5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 22, 24, 28, 32], "As": [4, 19, 20, 27, 28, 31, 34], "At": 4, "By": 4, "For": [5, 7, 11, 19, 20, 21, 28, 29, 30, 31], "If": [3, 4, 5, 6, 7, 9, 12, 14, 15, 16, 17, 21, 29], "In": [0, 4, 9, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "It": [4, 6, 7, 9, 14, 15, 17, 23, 27, 28, 29], "Its": 34, "On": 0, "One": [20, 26, 30, 32], "The": [0, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 31, 33, 34], "Then": [6, 15, 31, 32], "There": [0, 4, 20], "To": [4, 20, 21, 23, 31], "_": [4, 20, 23, 24, 26, 27, 31], "__call__": [10, 18, 33], "__class__": 31, "__init__": 33, "__name__": [26, 27, 28, 31], "_possible_ag": 21, "_prepar": 31, "a_env": 20, "ab": 33, "abl": [5, 6, 11, 15, 16, 27], "about": [20, 23, 24, 26, 27, 28, 29, 33, 34], "abov": [20, 24, 27, 28], "abstract": [5, 18], "acc": 24, "acceler": [5, 8, 21, 24], "accept": [7, 9, 18, 20], "accept_info": [10, 18], "achiev": 33, "acknowledg": 2, "act": [4, 21], "action": [0, 4, 6, 8, 9, 10, 13, 14, 15, 16, 18, 20, 21, 23, 24, 28, 29, 31, 33, 34], "action_config": [4, 13, 19, 20, 21, 23, 24, 29, 31, 33, 34], "action_spac": [9, 14, 16, 20, 21, 28, 31], "actionconfig": [0, 4, 5, 6, 15], "activ": [16, 27], "activation_fn": 16, "actual": [20, 24], "actuat": [4, 6, 15, 20, 31], "ad": [5, 6, 7, 9, 13, 15], "add": [0, 7, 9, 16, 17, 20, 23, 28, 33], "add_init": [7, 27], "add_modul": 33, "add_prob": 24, "add_record_prob": [13, 19, 27], "add_safety_to_agent_margin": 20, "addit": [5, 7, 16, 20, 31], "aec": 4, "after": [6, 15, 16, 20, 21, 24, 31], "again": 20, "agent": [2, 5, 7, 8, 10, 12, 13, 17, 18, 19, 20, 21, 23, 24, 25, 30, 31, 32, 33, 34, 35], "agent_index": [6, 13], "agent_indic": 21, "agent_kwarg": [23, 24], "agent_margin": [19, 20, 29, 30, 33, 34, 35], "aggress": 26, "agreement": 4, "ai": 4, "aim": 34, "algo": [26, 27], "algorithm": [4, 9, 23, 28, 29, 30, 32, 33, 34], "alia": 13, "aliv": 4, "all": [3, 4, 5, 6, 7, 8, 10, 11, 13, 15, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 33, 34, 35], "all_reward": [20, 21], "almost": [24, 26, 27, 28], "along": [8, 13, 24, 25, 31], "alpha": [17, 19, 20, 21, 23, 24, 26, 27, 31, 33, 34], "alreadi": [5, 16, 20, 27, 28, 29, 31, 33], "also": [4, 5, 7, 14, 20, 21, 23, 25, 29, 31, 33, 34], "altern": [19, 31], "although": [27, 29], "althought": 26, "altough": [28, 31], "alwai": [16, 17, 24, 27, 28], "among": [4, 21, 26, 27, 30, 32], "an": [4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 27, 29, 32, 33], "analys": 28, "analysi": [26, 27], "andd": 14, "angl": 31, "angular": [5, 20, 24, 31, 33], "angular_spe": [5, 31, 33], "ani": [4, 5, 6, 7, 8, 9, 11, 15, 16, 18, 19, 27, 31], "anoth": [5, 11, 27, 29, 35], "another_world": 7, "anypolici": [9, 10], "anypolicypredictor": [5, 7, 10, 13, 18], "anyth": 18, "anywai": 24, "apart": 33, "api": [4, 9, 20, 21, 28], "append": [20, 21, 26, 27, 31], "appli": [4, 5, 6, 7, 9, 15, 16, 20, 23, 26, 27, 28], "ar": [0, 4, 5, 7, 8, 9, 11, 15, 16, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "architectur": 23, "area": [6, 15], "arg": [9, 15, 16, 18], "argmin": 24, "argument": [6, 7, 8, 9, 15, 18], "around": [20, 27], "arrai": [10, 18, 20, 21, 27, 28, 31], "as_set": [10, 11], "asarrai": [19, 24, 26, 27, 31, 33, 34], "asdict": [5, 6, 10, 11, 15, 21], "ask": 20, "assertionerror": 16, "assign": [4, 5, 17, 19, 20, 26, 31, 33], "associ": 16, "assum": 16, "astyp": 20, "atari": 4, "attribut": [5, 9], "audio": [19, 20, 24, 26, 27, 29, 31, 33, 34], "author": 4, "auto": [9, 20], "automat": 20, "autoreset": 20, "avail": [4, 11, 19], "averag": [7, 20, 26, 27, 29, 33, 34], "avoid": [16, 24, 25, 27, 28, 29, 31], "awai": 20, "ax": [20, 24, 26, 27, 31], "ax1": [24, 26, 27], "ax2": [24, 26, 27], "axi": [13, 19, 20, 24, 31, 33, 34], "b": 5, "back": [8, 29], "bar": [28, 29], "barrier_angl": [24, 25, 33, 34], "base": [4, 6, 10, 13, 15, 16, 24], "base_class": [9, 21], "basealgorithm": [9, 12], "baseenv": [6, 7, 10, 12, 13, 15], "baseilalgorithm": [7, 9, 10, 12], "baselin": [4, 28], "baseline3": 3, "baselines3": [4, 20, 28], "baseparallelenv": [7, 10, 12, 13, 15], "basepolici": [9, 12, 14, 16], "basic": [2, 4, 20, 31, 32], "batch": 14, "batch_siz": [23, 28, 29], "bbox_to_anchor": 23, "bc": [4, 9, 10, 23, 26, 27, 28, 29, 31], "bc_cmd": 31, "bc_efficaci": 31, "bc_feasible_cmd": 31, "bc_kwarg": [9, 23, 28, 29], "bc_reward": 23, "bc_train_kwarg": [23, 28, 29], "becaus": [3, 23, 31], "becom": [20, 28], "been": [4, 20, 27, 31], "befor": [6, 15, 16, 20, 21, 26, 31], "begin": [7, 18, 24, 33], "behavior": [0, 4, 6, 7, 10, 12, 17, 19, 20, 21, 24, 25, 26, 27, 30, 31, 32, 33, 34], "behaviormodul": 33, "being": [7, 31], "belong": [5, 18], "below": [4, 26, 27, 28, 29, 33, 34], "benchmark": [20, 27], "best": 32, "beta": [17, 20, 21, 33], "better": [23, 27, 28, 29], "between": [4, 5, 8, 13, 17, 20, 21, 29, 31, 32], "bin": [23, 24, 26, 27, 33, 34], "bit": [26, 27], "bitwise_or": 21, "black": [19, 26, 27], "block": 27, "blue": [23, 26, 27, 31, 33, 34], "bodi": [5, 24], "bool": [5, 6, 7, 8, 9, 13, 14, 15, 16, 18, 20], "both": [5, 11], "bottom": [18, 24], "bound": [5, 6, 7, 10, 11, 15, 16, 18, 19, 20, 24, 25, 28, 29, 30, 33, 34], "boundari": [6, 7, 15, 24, 25], "boundary_dist": 24, "bounding_box": 31, "box": [5, 14, 16, 20, 21, 28, 31], "break": 4, "bring": 28, "browser": [19, 20, 24, 26, 27, 29, 31, 33, 34], "bufferdescript": 20, "build": [4, 16], "c": 4, "call": [4, 6, 14, 15, 20], "callabl": [7, 9, 13, 16, 18, 33], "callback": 7, "can": [0, 4, 5, 11, 13, 18, 19, 20, 21, 24, 28, 29, 31, 32], "cannot": [12, 24], "case": [20, 21, 23, 24, 27, 28, 31], "catch_warn": 20, "categor": 20, "cc": [26, 27], "cell": [13, 23, 28], "center": 4, "challeng": 30, "chang": [24, 28, 33], "check": [4, 16, 18, 20, 21, 27, 28, 29, 31, 34], "circular": 13, "citat": 17, "cl": 28, "cl4": 4, "class": [4, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 20, 33], "classmethod": [6, 7, 9, 11, 13, 15], "clip": [26, 27], "clone": [4, 10, 13, 25, 31, 32], "clone_behavior": [4, 13, 19], "close": [4, 20], "cm": 24, "cmd": 31, "cnn": 16, "cnn_output_dim": 16, "coat": 18, "code": 20, "coher": [20, 21], "col": [23, 26, 27], "collect": [5, 7, 9, 13, 15, 16, 20, 21, 23, 28, 29, 34], "collect_run": [9, 23, 28, 29, 31], "collis": [4, 7, 26, 27, 28], "color": [5, 6, 7, 15, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34], "colorbar": 24, "column": [7, 23, 24], "com": 3, "combin": [0, 16, 24, 25], "combinedextractor": 16, "come": 35, "command": [0, 4, 5, 6, 15, 21, 24, 31], "commiss": 4, "common": [4, 7, 9, 11, 16, 18, 20, 21, 23, 28, 29, 31, 33, 34], "compar": [20, 21, 23, 26, 27, 28, 29, 31], "comparis": [25, 32], "comparison": [27, 32], "compat": [4, 9], "complet": [5, 6, 15, 28], "complex": [21, 32], "compon": [2, 4, 10, 31], "compos": [4, 20], "compositevideoclip": [26, 27], "comput": [4, 5, 6, 7, 9, 15, 18, 20, 21, 24, 26, 27, 28, 29, 31, 33], "compute_cmd": 31, "concat_vec_envs_v1": [9, 15, 21], "concaten": [4, 9, 15, 16, 24], "concret": 4, "config": [4, 5, 7, 13, 23, 24, 28, 29, 33, 34], "config_eval_log": [7, 10], "configur": [2, 4, 6, 7, 9, 10, 13, 15, 19, 21, 23, 28, 29, 31, 33, 34], "conform": [4, 6, 15, 16, 20], "confugur": 31, "consid": [6, 15, 21, 27], "consist": 33, "constant": [6, 13, 15, 24, 25, 33], "constrain": 31, "constraint": 24, "constructor": [8, 9], "consum": [5, 9], "contain": [4, 5, 18, 20, 21, 31], "continu": [26, 27], "contrari": [33, 34], "control": [4, 5, 15, 20, 21, 24, 28, 29, 31], "control_period": [19, 20, 24, 25, 29, 30, 31, 33, 34, 35], "controlactionconfig": [4, 5, 6, 13, 15, 19, 20, 21, 23, 24, 29, 31, 33, 34], "conveni": 15, "convent": 14, "convers": [5, 11], "convert": [4, 5, 6, 15, 18, 22, 32], "cooper": 27, "copi": [7, 9, 11, 13, 27], "core": [4, 5, 13, 17, 19, 24, 27, 31, 33], "correspond": [17, 18], "corridor": [2, 10, 13, 23, 24, 32], "corridorwithobstacl": [10, 24, 25], "cost": 29, "could": [4, 12, 20, 23, 26, 28, 31], "cover": [11, 20, 27], "covert": [11, 21], "creat": [8, 9, 13, 15, 16, 28, 29, 32], "criteria": 9, "critic": 17, "critical_safety_margin": [17, 20, 21], "cross": [2, 10, 19, 20, 29, 32, 34], "crosstoru": [33, 34, 35], "csv": [23, 26, 27, 28, 29, 33, 34], "cum_reward": 20, "cumul": [7, 20, 31], "current": [5, 23, 28, 29], "custom": [4, 9], "cycl": [4, 20], "d": [13, 26, 27], "d_": [23, 28, 29, 33, 34], "dagger": [4, 10, 25, 26, 27, 32], "dagger_kwarg": 9, "dagger_reward": 23, "darkviolet": 26, "dash": [26, 27, 28], "data": [5, 7, 9, 13, 19, 20, 26, 27], "dataclass": 33, "datafram": [26, 27, 28, 29, 33, 34], "dataset": [9, 13, 24], "datetim": [23, 28, 29, 31, 33, 34], "dc": 33, "decent": [23, 27], "decis": 4, "decor": 33, "decreas": [26, 27], "deeper": 29, "def": [20, 23, 26, 27, 31, 33], "default": [6, 7, 9, 10, 13, 15, 16, 17, 20, 21], "default_rng": 29, "default_social_margin": [17, 20, 21], "defaultobservationconfig": [4, 5, 6, 13, 15, 19, 20, 21, 23, 24, 29, 31, 33, 34], "defer": 5, "defin": [0, 5, 18, 20, 21, 23, 25, 28, 32], "degrad": 27, "demand": [6, 15], "densiti": [19, 23, 24, 26, 27, 33, 34], "depend": [5, 7, 16], "descreas": 33, "describ": [5, 6, 15, 16, 18, 31], "descript": 20, "description_of_the_return_valu": 9, "design": [4, 7, 28], "desir": 4, "detect": 25, "determinist": [4, 5, 7, 9, 13, 14, 18, 20, 31], "deterministic_polici": 9, "dev": [7, 24, 28, 29, 31, 33, 34], "develop": 3, "deviat": 7, "df": [23, 28, 29, 33, 34], "dict": [4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18, 20, 21, 23, 26, 27, 28, 29, 31], "dict_spac": 16, "dictionari": [5, 6, 9, 11, 15, 16, 18, 20, 28], "dictionart": 11, "differ": [0, 4, 7, 18, 20, 21, 23, 26, 27, 28, 29, 30, 32, 35], "different_speed_env": 33, "different_speed_reward": 33, "differentspe": 33, "differnet": 21, "dimens": 16, "dir": 31, "direcli": [28, 31], "direclti": 20, "direct": [5, 13, 20, 24, 31, 34], "directli": [4, 19, 28], "directori": [9, 12, 23], "disabl": [9, 16], "disable_logg": 20, "disc": [19, 20, 24, 25, 29, 30, 33, 34, 35], "disclaim": 2, "discontinu": 4, "discuss": [20, 24], "displai": [5, 6, 15, 19, 20, 23, 26, 27, 28, 29, 33, 34], "display_in_notebook": [24, 26, 27], "display_shap": 33, "display_video": [19, 20, 24, 29, 31, 33, 34], "display_video_from_run": [26, 33, 34], "display_width": [19, 20, 24, 26, 29, 31, 33, 34], "distanc": [4, 5, 24, 34], "distinguish": 18, "distribut": [4, 19, 24, 26, 27, 33, 34], "divers": 4, "divid": 7, "dlr": 4, "do": [3, 4, 9, 19, 24, 28, 32], "doc": 4, "document": 0, "doe": [5, 20, 24, 28, 31], "doesn": [19, 20, 24, 26, 27, 29, 31, 33, 34], "dof": [5, 20, 21], "don": [20, 28, 34], "done": [20, 21, 28], "dot": [26, 27, 28], "dot_radiu": [23, 24], "dropna": 28, "dry": [6, 15], "dt": [23, 28, 29, 33, 34], "dtype": [5, 8, 13, 15, 16, 20, 21, 24, 26, 27, 31], "due": 31, "dummi": [16, 17, 27, 31], "dummybehavior": 27, "dump": [5, 6, 15], "durat": [6, 8, 15, 19, 20, 23, 24, 26, 27, 28, 29, 31, 33, 34], "dure": [5, 13, 23, 24, 27, 28, 29], "dynam": 14, "dynamic_batch_s": 14, "e": [4, 5, 18, 19, 20, 21, 24, 27, 28, 29, 33, 34], "each": [0, 7, 16, 20, 21, 23, 24, 27, 28, 29, 31], "earlier": 31, "easier": 27, "effect": 5, "efficaci": [7, 10, 26, 31, 33], "efficacyreward": [10, 17, 31], "effici": 26, "effort": 27, "ego": [4, 5, 24], "ego_": 20, "ego_angular_spe": 24, "ego_target_direct": [20, 21, 24], "ego_target_dist": [20, 21], "ego_veloc": 24, "either": [5, 31], "element": [7, 20], "elif": 19, "els": [7, 8, 9, 11, 19, 26, 27], "emb": [4, 19], "empti": [2, 7, 25, 32], "en": 28, "enabl": [7, 14], "end": [4, 10, 13], "enlarg": 24, "enough": [23, 28, 29, 31], "ent_weight": [23, 28, 29], "entir": 20, "entri": 5, "enumer": [20, 23, 26, 27, 31], "env": [4, 5, 6, 7, 8, 9, 12, 13, 15, 20, 22, 23, 24, 27, 28, 29, 31, 32], "env1": [20, 21], "env_id": 9, "env_kwarg": [20, 23, 31], "env_make_kwarg": 9, "env_util": [20, 23, 31], "enviro": [9, 20, 21, 28, 32], "enviromen": 28, "environ": [0, 2, 5, 7, 8, 9, 10, 12, 13, 18, 21, 22, 23, 25, 30, 32, 35], "environen": 28, "ep_rew_mean": [23, 28, 29, 33, 34], "episod": [7, 8, 14, 18, 20, 27, 29, 33, 34], "episode_count": 20, "episode_mean_reward": 20, "episode_start": [14, 18, 20], "episode_trigg": 20, "episodestart": [9, 10, 14, 18, 20], "epoch": 23, "equal": [17, 19, 24], "equival": [28, 31], "especiali": 23, "estim": [4, 5, 6, 15, 29], "eta": [19, 20, 24, 25, 29, 30, 33, 34], "eu": 4, "european": 4, "evalu": [2, 5, 10, 11, 13, 14, 23, 24, 26, 27, 28, 29, 32, 33, 34], "evaluate_my_polici": 4, "evaluate_polici": [4, 7, 10, 23, 28, 29, 31, 33, 34], "evaluate_with_experi": [7, 10], "evaluate_with_experiment_and_env": [7, 10, 23, 24], "evalute_polici": 31, "even": [20, 21, 23, 24, 26, 27, 29], "event": 24, "everi": [6, 15], "everyth": 4, "eviron": 27, "exampl": [2, 4, 7, 10, 11, 26], "excess": 33, "excus": 24, "execut": [4, 23], "exit": [6, 7, 15], "exp": [23, 24, 26, 27, 33, 34], "expect": [4, 16, 20, 27, 28, 29, 31], "expens": 28, "experi": [4, 10, 13, 24, 27, 31], "experimentalrun": [13, 19], "expert": [9, 23, 28, 29, 31], "expert_cmd": 31, "expert_efficaci": 31, "expert_reward_mean": 31, "expert_reward_std_dev": 31, "explain": [20, 28], "explicitli": 20, "explictli": 20, "explod": 16, "explor": 25, "export": [4, 10, 12, 19, 20, 26, 27, 32], "export_behavior": [10, 12], "export_policy_as_behavior": [4, 10, 12, 31], "expos": [5, 8, 9, 14, 15, 20, 28], "express": 4, "extend": [1, 2, 4, 7, 9], "extens": 4, "extract": [0, 11, 16, 20], "extractor": 10, "f": [4, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "fact": [4, 24, 32], "factor": [6, 7, 15, 19, 20, 24, 26, 27, 29, 33, 34], "factori": [5, 13, 17], "fail": 23, "fair": 27, "fals": [5, 6, 7, 8, 9, 13, 15, 16, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 33, 34], "familiar": 25, "far": [26, 27], "farama": 4, "faster": [28, 31], "feasibl": 31, "featur": [4, 16], "fed": 16, "fenc": [6, 15], "few": 24, "field": [20, 21], "fig": [20, 23, 24, 26, 27, 31], "figsiz": [19, 20, 23, 24, 26, 27, 28, 29, 31, 33, 34], "figur": [19, 23, 24, 33, 34], "figure_format": [23, 24, 28, 29, 33, 34], "file": [4, 12, 13, 20, 21, 31], "filenam": 20, "filesystem": 18, "fill": 33, "filter": 31, "filter_kei": 16, "filter_slic": 16, "filterwarn": [20, 23, 24, 28, 29, 31, 33, 34], "final": [6, 15, 24, 29, 30, 32], "fine": 31, "finish": [13, 20], "firebrick": [23, 24, 25], "first": [4, 5, 9, 21, 24, 25, 29, 32, 34, 35], "first_group": 21, "five": 4, "fix": [5, 23, 28], "fix_orient": [5, 13, 20, 21], "flat": [5, 8, 13, 16, 20, 21, 23, 24, 29, 31, 33, 34], "flatten": [5, 16, 19, 24, 26, 27, 33, 34], "float": [5, 6, 7, 8, 13, 15, 17, 18, 20, 33], "float32": [20, 21, 24, 28, 31], "float64": [13, 18, 24], "focu": 21, "follow": [20, 21, 23, 26, 28, 30, 31, 32], "forc": 5, "forth": [8, 29], "forward": 10, "forwardscenario": 13, "foundat": 4, "four": 35, "fov": 21, "fp": [7, 26, 27], "fraction": 27, "frame": [21, 24], "from": [0, 3, 4, 5, 6, 7, 9, 11, 13, 15, 16, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35], "from_dict": [6, 10, 11, 15], "fromarrai": 20, "full": [24, 26, 27, 28], "fun": [20, 26], "func": 18, "function": [0, 2, 4, 5, 6, 7, 9, 10, 13, 15, 16, 18, 20, 23, 28], "functool": 27, "fund": 4, "g": [4, 5, 18, 20, 21, 24], "game": 4, "gamma": 33, "gap": 24, "gather": 20, "gener": [4, 5, 6, 9, 11, 15, 18, 20, 21, 27], "generate_trajectori": [9, 10], "gentrajterminationfn": 9, "get": [4, 5, 6, 9, 11, 15, 18, 20, 25, 27, 29], "get_act": 5, "get_cmd": 31, "get_cmd_from_act": [5, 21], "get_dir": [23, 28, 29, 33, 34], "get_env": [8, 9, 10], "get_feasible_cmd": 31, "get_groups_reward": [26, 27], "get_imag": 20, "get_polici": [10, 15, 33, 34], "get_record": [24, 26, 27, 33, 34], "get_target_angular_spe": 33, "get_target_spe": 33, "get_tim": 33, "git": 3, "github": 3, "given": 12, "go": [20, 23, 27, 28, 29], "goal": [20, 32], "goe": 24, "good": [23, 24], "grai": [19, 20, 29, 30], "grant": 4, "graph": 7, "greedi": 27, "green": [23, 26, 27, 31, 33, 34], "grei": 27, "group": [4, 7, 10, 13, 15, 16, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "groupbi": [26, 27], "groupconfig": [5, 7, 10, 13, 15, 21, 23, 24, 26, 27, 33], "groups_config": 27, "grp_1_ep_1": 7, "grp_1_ep_2": 7, "grp_2_ep_1": 7, "grp_2_ep_2": 7, "gt": [24, 28, 31, 34], "guid": [0, 2], "gym": [4, 5, 6, 9, 16, 20, 21, 23, 24, 29, 31], "gymanasium": 4, "gymansium": 20, "gymnasium": [0, 2, 5, 8, 10, 19, 22, 23, 24, 28, 29, 31, 32], "gymprob": [10, 13, 24], "h": [4, 23, 26, 27, 28, 29, 33, 34], "ha": [4, 5, 6, 9, 15, 16, 17, 18, 20, 21, 24, 26, 27, 31], "half": 28, "handl": 18, "happen": [24, 28, 31], "has_wheel": [5, 20, 21], "have": [4, 14, 17, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 34, 35], "height": [20, 27], "held": 4, "helper": [4, 16, 23, 26, 28], "here": [18, 27, 32], "hexbin": 24, "hidden": 18, "hierarchicallogg": 9, "high": 20, "higher": [26, 27, 28], "hist": [19, 23, 24, 26, 27, 33, 34], "histogram": [26, 27], "histori": [5, 13, 20, 21], "hl": [19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34], "hl_group": [26, 27], "hl_mean": 27, "hl_r": 27, "hl_reward": [23, 26, 27, 33, 34], "hl_std": 27, "hline": 28, "horizon": [4, 19, 20, 24, 25, 29, 30, 33, 34], "horizont": 13, "hour": 29, "how": [1, 2, 4, 5, 9, 13, 19, 20, 29, 32, 34], "howev": 4, "hparam": 7, "html5": [19, 20, 24, 26, 27, 29, 31, 33, 34], "http": [3, 28], "human": [4, 6, 15, 20, 30, 32], "hyper": 32, "i": [3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34], "i1": 24, "i2": 24, "id": [6, 17], "identifi": [4, 5], "idsia": 3, "ignor": [14, 20, 23, 24, 28, 29, 31, 33, 34], "il": [4, 9, 23, 26, 27, 28, 29, 31], "im": 20, "imag": [4, 16, 18, 20], "image_for_world": [6, 15], "imageclip": [26, 27], "img": [26, 27], "imit": [0, 2, 10, 13, 25, 27, 28, 29, 32], "immers": 27, "impact": [5, 26, 27, 28, 29], "implement": [4, 9, 14], "implicli": 20, "import": [3, 4, 6, 7, 15, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "imshow": 20, "in_box": [23, 24], "includ": [0, 4, 5, 6, 15, 18, 33, 34], "include_angular_spe": [5, 20, 21, 23, 24, 29, 33, 34], "include_radiu": [5, 13, 20, 21], "include_target_angular_spe": [5, 13, 20, 21], "include_target_direct": [5, 13, 19, 20, 21, 23, 24, 29, 31, 33, 34], "include_target_direction_valid": [5, 13, 20, 21], "include_target_dist": [5, 13, 19, 20, 21, 29], "include_target_distance_valid": [5, 13, 20, 21], "include_target_spe": [5, 13, 20, 21, 33], "include_valid": [20, 24, 25], "include_veloc": [5, 13, 20, 21, 23, 24, 29, 33, 34], "increas": [19, 26], "increasingli": 32, "incur": 24, "index": [2, 4, 6, 11, 12, 15, 28, 29, 33, 34], "indic": [5, 7, 10, 15, 16, 18, 20, 21, 26, 27, 29], "indiceslik": [7, 10, 11, 15, 18], "individu": [6, 15, 18, 20, 21, 33, 35], "inf": [5, 20, 21], "infer": [10, 16, 20, 27, 31], "inferencesess": 14, "info": [4, 6, 9, 10, 15, 18, 20, 21, 31], "info_predictor": 9, "infopolici": [6, 9, 10, 15, 16], "inform": [4, 5, 16, 18, 20, 31], "inherit": [5, 20], "init": [9, 13], "init_arg": [6, 10, 15], "init_polici": 33, "init_speed_modul": 33, "init_world": [13, 24, 34], "initi": [4, 6, 7, 11, 13, 15, 23, 24, 29, 33], "initpolicybehavior": [7, 10, 26, 33], "inlinebackend": [23, 24, 28, 29, 33, 34], "input": [14, 16, 18, 24, 25], "insid": [4, 20, 31], "inspir": 17, "instal": [2, 28, 29], "instanc": [4, 5, 6, 15, 19, 20, 21], "instanti": 4, "instead": [4, 5, 7, 19, 21, 28, 32], "int": [4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 24, 26, 27, 33], "integ": [11, 28], "integr": [2, 20, 22, 32], "interact": 4, "interest": [25, 27], "interestingli": [26, 27], "interfac": [4, 7, 9], "intern": [0, 7, 13], "interpret": [5, 6, 15, 31], "intersect": [5, 10, 11], "introduct": [2, 28], "intuit": 27, "invari": 10, "io": [4, 12, 20, 21, 24, 26, 27, 28, 29, 31, 33, 34], "ipython": 20, "is_configur": 5, "item": [4, 11, 16, 21, 26, 27], "iter": 4, "its": [4, 20, 24, 28], "j": [26, 27], "jam": 27, "job": 20, "json": [5, 6, 11, 15], "jupyt": 20, "just": [5, 8, 9, 20, 21, 24, 27, 28, 31, 34], "k": [19, 28], "keep": [5, 26, 27, 28, 31], "kei": [6, 11, 13, 15, 16, 28], "kept": 33, "kinemat": [4, 5, 13, 19, 20, 24, 25, 29, 30, 31, 33, 34, 35], "known": 5, "kwarg": [8, 9, 15, 16, 18, 23, 31], "l": 31, "l2_weight": [23, 28, 29], "label": [19, 23, 24, 26, 27, 31, 33, 34], "lambda": [20, 23, 26, 27, 33], "languag": 20, "larg": [4, 23, 31], "larger": [5, 6, 15, 27], "last": [18, 27], "later": [20, 24, 29, 31], "latest": 3, "layer": [16, 23, 28, 29], "layout": 16, "lead": [26, 27, 28], "learn": [0, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35], "least": [5, 24], "leav": 28, "left": [18, 24], "legend": [19, 23, 26, 27, 31, 33, 34], "len": [20, 21, 24], "length": [7, 11, 13, 20, 24, 25], "length_ep_1": 7, "length_ep_2": 7, "length_queu": 20, "less": [23, 26, 27, 28, 29], "let": [5, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33], "level": 20, "librari": 4, "lidar": 21, "like": [3, 4, 7, 9, 13, 19, 20, 21, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35], "limit": 31, "linalg": 33, "line": [26, 27, 28], "linear": [17, 20, 24, 31, 33], "linecollect": 28, "linestyl": 28, "link": 4, "linspac": [23, 26, 27, 31, 33, 34], "list": [5, 7, 11, 15, 16, 18, 21], "liter": [7, 11, 15, 18], "littl": [24, 27], "load": [0, 2, 4, 6, 9, 10, 13, 14, 15, 19, 22, 23, 26, 27, 28, 31, 32], "load_behavior": [10, 12], "load_env": [10, 12, 20, 21, 26, 27, 28], "load_experi": 31, "load_ext": [28, 29], "load_from_zip_fil": 9, "load_plugin": 4, "load_scenario": [6, 7, 15, 19, 20, 21, 23, 24, 29, 31, 33, 34], "load_state_estim": [19, 20, 21, 23, 24, 29, 33, 34], "log": [10, 23, 24, 28, 29, 33, 34], "log_graph": 7, "log_interv": [23, 28, 29, 33, 34], "log_rollouts_n_episod": [23, 28, 29], "log_rollouts_venv": [23, 28, 29], "logdir": [28, 29], "logger": [7, 9, 23, 26, 27, 28, 29, 33, 34], "long": 13, "longer": [23, 27], "look": [4, 21, 24, 25, 26, 27, 29, 30, 32, 34, 35], "loop": [20, 21, 24, 31], "lot": [26, 27], "low": 20, "lower": [17, 26, 27, 33, 34], "lowest": [10, 11, 24], "lt": [24, 28, 31, 34], "m": [23, 24, 28, 29, 33, 34], "ma_env": [26, 27], "machin": [4, 21], "mai": [4, 5, 21, 24, 31], "main": [0, 3, 7], "maintain": [9, 27], "major": 24, "make": [4, 6, 7, 20, 23, 24, 26, 27, 29, 30, 31, 33], "make_experi": [7, 10], "make_experiment_with_env": [7, 10, 23, 26, 27, 33, 34], "make_order_invariant_flatten_extractor": [10, 16], "make_shared_parallel_env_with_env": [10, 15, 21, 27, 28], "make_vec": 20, "make_vec_env": [9, 20, 23, 31], "make_vec_from_env": [9, 10, 29], "make_vec_from_penv": [4, 9, 10, 15, 28, 33, 34], "make_video": [26, 27], "make_video_from_run": [26, 27], "make_world": [4, 7, 19, 20, 29, 31, 33], "manag": 24, "mani": [4, 9, 21, 30, 32], "manual": [4, 20], "map": [6, 9, 11, 15, 20, 21, 31], "margin": [13, 17, 20, 24], "marker": [28, 29], "markov": 4, "markovvectorenv": 9, "mask": [16, 18], "master": 28, "matplotlib": [19, 20, 23, 24, 26, 27, 28, 29, 31, 33, 34], "max": [23, 24, 26, 27, 28], "max_acceler": [5, 13, 20, 21, 23, 24, 29, 33, 34], "max_angular_acceler": [5, 13, 20, 21, 23, 24, 29, 33, 34], "max_angular_spe": [5, 20, 21, 31], "max_dur": [6, 15, 20, 21, 23, 24, 29, 31, 33, 34], "max_episode_step": [4, 20], "max_i": [24, 25, 31], "max_id": 20, "max_numb": 5, "max_number_of_ag": 15, "max_number_of_obstacl": 13, "max_obstacle_radiu": 13, "max_radiu": [5, 13, 19, 20, 21, 24, 25, 29, 30, 33, 34, 35], "max_reward": 31, "max_spe": [5, 19, 20, 21, 24, 25, 29, 30, 31, 33, 34, 35], "max_target_dist": [5, 20, 21], "max_x": 31, "maxim": [5, 6, 11, 13, 15, 17, 20, 31, 33], "maximum": [5, 13], "mdp": 4, "mean": [7, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "measur": [24, 26, 27, 29], "median": [23, 24], "merg": 7, "merge_groups_config": [5, 7, 10], "met": 29, "metadata": [6, 15, 20], "metric": 4, "microsecond": 31, "middl": [8, 20, 29], "mimic": 7, "min": [23, 24], "min_i": [24, 25, 31], "min_number_of_obstacl": 13, "min_obstacle_radiu": 13, "min_radiu": [13, 24, 25], "min_x": 31, "minim": [13, 24], "minimum": 13, "mix": 28, "ml": [2, 5, 13, 20, 22, 27, 28, 32], "mlp": [16, 23], "mlppolici": [4, 23, 28, 29, 31, 33, 34], "mode": [6, 15], "model": [4, 7, 9, 12, 13, 14, 18, 23, 25, 26, 27, 28, 29, 31, 33, 34], "model1": 7, "model2": 7, "model3": 7, "modifi": [9, 19], "modul": [2, 10, 16, 33], "modulationactionconfig": [4, 5], "more": [4, 5, 15, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32], "moreov": 4, "most": [20, 24], "move": [17, 20, 21, 24, 26, 27, 28, 29, 31, 35], "moviepi": [26, 27], "mp4": 20, "mpy": [26, 27], "much": [26, 27, 28], "multi": [2, 7, 8, 10, 20, 21, 28, 29, 30, 32], "multi_ag": 8, "multiagentnavgroundenv": [4, 10, 12, 15], "multipl": [4, 15, 21, 28], "must": [6, 18, 28], "myenviro": 4, "mymultiagentenviro": 4, "mypolici": 18, "myscenario": 4, "n": [4, 20, 21, 26, 27, 31], "n_env": [20, 23], "n_epoch": [4, 23, 28, 29, 31], "n_eval_episod": [7, 23, 24, 28, 29, 31, 33, 34], "naground": 19, "name": [0, 5, 18, 20, 26, 27, 28, 31], "name_prefix": 20, "navground": [2, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34], "navground_act": [6, 15, 20, 21], "navground_learn": [3, 31], "navgroundenv": [4, 6, 10, 12, 15, 20], "navig": [4, 9, 13, 17, 20, 23, 25, 28, 29, 30, 31, 32, 33, 34, 35], "ncol": [20, 23, 24, 26, 27, 31], "ndarrai": [4, 8, 15, 18], "nearest": [20, 24, 31], "necessarili": 4, "need": [4, 5, 15, 20], "neighbor": [17, 20, 28], "neightbor": 27, "neither": 4, "nest_asyncio": 20, "net_arch": [9, 16, 23, 28, 29, 31, 33, 34], "network": [16, 23, 28, 29], "neural": [28, 29], "neuron": [23, 28, 29], "new": [0, 4, 5, 6, 9, 13, 15, 20, 21], "next": [18, 20, 23, 26, 27, 28, 29], "nn": 16, "no_tick": 24, "noisi": 31, "non": 16, "none": [4, 5, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 26, 27, 31, 33], "nonetheless": 28, "nor": 4, "norm": 33, "normal": [16, 18, 20, 31], "normalized_imag": 16, "note": [23, 27, 28, 31], "notebook": [19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35], "notebook_view": 20, "noth": 4, "notna": 23, "now": [4, 19, 21, 23, 27, 28, 29, 31, 33, 34], "np": [9, 18, 19, 20, 21, 23, 24, 26, 27, 29, 31, 33, 34], "nrow": [26, 27], "null": [10, 20, 21], "nullifi": 31, "nullpolici": [10, 16], "nullpredictor": [10, 16], "nullreward": [10, 17], "num": [26, 27], "num_cpu": 21, "num_env": [9, 15, 20, 21, 28, 29], "number": [4, 5, 6, 7, 9, 13, 15, 16, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35], "number_of_episod": [26, 27], "number_of_process": [26, 27], "number_of_run": [23, 24, 26, 27, 33, 34], "numpi": [4, 18, 19, 20, 21, 23, 24, 26, 27, 29, 31, 33, 34], "o": 18, "ob": [20, 31], "object": [13, 20], "observ": [0, 4, 6, 8, 9, 10, 13, 14, 15, 16, 18, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "observa": 27, "observation_config": [4, 13, 19, 20, 21, 23, 24, 29, 31, 33, 34], "observation_spac": [9, 14, 16, 20, 21, 31], "observationconfig": [0, 4, 5, 6, 15], "obstacl": [2, 8, 13, 20, 23, 24, 27, 31, 32], "obtacl": [24, 25], "off": 20, "offer": 4, "offlin": 20, "offpolicyalgorithm": 7, "older": 20, "onc": [4, 20, 31], "one": [4, 5, 6, 7, 8, 12, 13, 14, 15, 20, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33], "ones": 21, "onli": [4, 5, 6, 13, 15, 16, 20, 23, 24], "onlin": 20, "onnx": [2, 4, 7, 10, 12, 16, 19, 20, 26, 27, 28, 31], "onnxpolici": [10, 14, 19, 31], "onnxruntim": 14, "open": [4, 19, 20, 21, 23, 24, 29], "open_html": 20, "openai": 4, "opinion": 4, "opposit": [5, 19, 20], "optim": [17, 20, 28, 32, 33], "optimal_angular_spe": 33, "optimal_spe": [19, 20, 24, 25, 29, 30, 33, 34], "option": [4, 5, 6, 7, 9, 15, 16, 18], "orang": [23, 31], "order": [10, 33], "order_invariant_kei": 16, "order_invariant_slic": 16, "orderinvariantcombinedextractor": [10, 16], "orderinvariantflattenextractor": [10, 16], "orgin": 9, "orient": [4, 5, 31], "origin": [4, 9, 11, 16, 20, 21, 28], "other": [4, 11, 15, 19, 20, 21, 24, 26, 27, 28, 29], "other_group": 5, "otherwis": [5, 16], "our": [20, 24, 26, 27, 32], "out": [9, 21], "outlier": [26, 27], "output": [4, 5, 13, 14, 16, 20, 21, 24, 25, 31], "over": [4, 7, 26, 27, 29], "overlap": 5, "overli": 26, "overwrit": [19, 20, 24, 28, 29], "own": [5, 6, 15, 17, 20, 24], "p": [26, 27, 28], "p_straight": 24, "packag": [3, 4, 9], "page": 2, "pair": 20, "panda": [23, 26, 27, 28, 29, 33, 34], "parallel": [7, 8, 9, 15, 20, 21, 28, 30], "parallel_env": [4, 9, 10, 15, 21, 26, 27, 28, 33, 34], "parallelenv": [5, 8, 9, 15], "param": 5, "paramet": [4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 32, 34], "part": [4, 9, 11, 18, 21], "parti": 3, "partial": [4, 27], "particular": [0, 4, 9, 21, 30], "pass": [4, 6, 7, 8, 9, 15, 24], "patch": 9, "path": [9, 12, 14, 18, 20, 26, 27, 31], "pathlik": [5, 7, 10, 12, 13, 14, 18], "pcg64": 9, "pd": [23, 26, 27, 28, 29, 33, 34], "peer": [4, 27, 30, 32], "penal": [20, 24, 33], "penalti": 17, "penv": [4, 21, 28, 33, 34], "per": [5, 23, 24, 28, 31], "perceiv": 24, "perfom": [27, 28], "perform": [4, 14, 20, 23, 28, 29, 30, 31, 32, 33, 34], "period": [2, 13, 32, 34], "periodic_i": 13, "periodic_x": 13, "pettingzoo": [0, 2, 5, 7, 8, 9, 10, 19, 22, 28, 32], "pettingzoo_env_to_vec_env_v1": [15, 21], "physic": 4, "pi": [24, 31], "pick": 24, "pil": 20, "pip": 3, "pipelin": 31, "pl": 9, "place": 20, "plai": [26, 31], "plaza": 35, "plot": [7, 19, 23, 24, 26, 27, 28, 29, 31, 33, 34], "plot_comparison_test_run": 23, "plot_config": 7, "plot_run": [23, 24], "plot_test_run": 23, "plt": [19, 20, 23, 24, 26, 27, 28, 29, 31, 33, 34], "po": [26, 27], "point": [4, 8, 24, 34], "polic": [26, 27], "polici": [0, 2, 5, 6, 9, 10, 12, 13, 14, 15, 18, 21, 22, 23, 29, 30, 32, 33, 34, 35], "policy_color": [26, 27], "policy_group": [26, 27], "policy_kwarg": [9, 23, 28, 29, 31, 33, 34], "policy_mean": 27, "policy_path": [4, 13, 19, 31], "policy_r": 27, "policy_reward": [26, 27], "policy_std": 27, "policybehavior": [4, 10, 12, 19, 31], "policycal": [9, 10], "policycallablewithinfo": [9, 10], "policypredictor": [10, 14, 16, 18, 20], "policypredictorwithinfo": [7, 10, 16, 18, 20], "popul": 27, "port": 20, "pose": [19, 23, 24, 26, 27, 33, 34], "posit": [6, 13, 15, 16, 20, 21, 24], "possibl": [11, 12, 24, 32], "possible_ag": [21, 28], "possibli": [4, 5, 7, 20], "practic": 4, "pre": [23, 30, 32, 33], "precis": [26, 27, 28, 29, 33, 34], "predefin": 4, "predict": [10, 14, 18, 20, 21, 31, 34], "predictor": [16, 18], "prefer": [3, 31], "prevent": 4, "previou": [21, 23, 27, 28, 33], "previous": 12, "print": [20, 21, 23, 24, 27, 28, 29, 31, 33, 34], "pro": 4, "probabl": [19, 23, 24, 33, 34], "probe": [7, 10, 19, 24, 27], "problemat": 27, "process": [4, 6, 9, 15, 16, 20, 26, 27], "processor": 4, "produc": [5, 6, 15, 31], "progress": [9, 23, 28, 29, 33, 34], "progress_bar": [23, 28, 29, 31, 33, 34], "project": 4, "properti": [5, 6, 9, 11, 13, 14, 15], "protocol": [14, 18, 20], "provid": [0, 4, 5, 7, 12, 15, 21, 23], "psac": 4, "psac_ma": 4, "py": 9, "pypi": 3, "pyplot": [19, 20, 23, 24, 26, 27, 28, 29, 31, 33, 34], "pyplot_help": [23, 24], "python": [3, 4, 19], "python3": 3, "pytorch": [3, 14, 31], "pz": 4, "qualiti": 24, "quantifi": 27, "quantil": 23, "queue": 5, "quit": [23, 24], "r": [11, 19], "r_env": 20, "rad": 24, "radii": 20, "radiu": [5, 13, 19, 20, 21, 24, 25, 29, 30, 31, 33, 34, 35], "rais": [11, 12, 15, 16], "random": [4, 9, 10, 13, 19, 20, 21, 23, 28, 29, 31], "random_polici": 20, "random_predictor": 21, "randomli": 24, "randompolici": [10, 16, 20], "randompredictor": [10, 16, 21], "rang": [4, 19, 20, 21, 24, 25, 29, 30, 33, 34, 35], "rare": 24, "ratio": 26, "rd_kwarg": [26, 27], "reach": [13, 28], "read": [0, 4, 9, 11, 19, 20, 21, 23, 24, 29], "read_csv": [23, 28, 29, 33, 34], "readi": 29, "readthedoc": 28, "real": [6, 15, 20], "realiti": 4, "realli": [27, 33], "realtim": [6, 15], "realtime_factor": [6, 15, 20], "recent": 5, "record": [4, 7, 13, 19, 20, 23, 24, 27, 28, 29], "record_config": [19, 23, 24, 26, 27, 33, 34], "record_efficaci": [4, 31], "record_pos": 4, "record_reward": [7, 26, 27, 33], "recordconfig": 19, "recordepisodestatist": 20, "recordvideo": 20, "recreat": 20, "rectangular": 18, "recurr": 18, "red": [7, 19, 26, 27, 33, 34], "redo": 29, "reduct": [10, 16], "refer": [2, 5, 12, 20], "reflect": 4, "region": 18, "regist": [0, 6, 13], "reinforc": [25, 29, 32, 35], "reject": 9, "rel": [5, 21, 24, 31], "relat": [6, 12, 15], "relative_margin": [33, 34], "releas": 3, "relev": 5, "reload": [19, 20, 27, 31], "relu": 16, "remain": [4, 28, 31], "remov": 16, "removed_kei": 16, "removed_slic": 16, "render": [6, 7, 15, 21], "render_fp": 20, "render_kwarg": [6, 15, 20], "render_mod": [6, 15, 20], "replac": [4, 20], "replic": [13, 16, 26], "replicated_kei": 16, "replicated_slic": 16, "repres": [20, 21], "represent": [5, 6, 7, 11, 12, 15, 20, 21], "reproduc": 27, "request": 5, "requir": [9, 20, 27, 28, 31], "rescal": [28, 29], "reset": [4, 6, 10, 15, 18, 20, 21], "reset_info": 20, "reset_num_timestep": [33, 34], "resiz": 20, "resolut": 21, "resolv": 4, "respect": [14, 20, 31, 33], "respons": [4, 28], "rest": [4, 26, 27, 29], "resus": 28, "retriev": [9, 12], "return": [4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 31, 33], "return_episode_reward": [7, 23, 24], "return_mean": [23, 28, 29], "return_queu": 20, "reward": [0, 2, 4, 5, 6, 7, 10, 13, 15, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34], "reward_agent_1_ep_1": 7, "reward_agent_2_ep_1": 7, "reward_agent_n_ep_m": 7, "reward_ep_1": 7, "reward_ep_2": 7, "reward_mean": 31, "reward_std_dev": 31, "reward_threshold": 7, "rewardprob": [7, 10, 13, 19, 27], "rewards_1_19": 27, "rewards_env": 27, "rewards_ma": 28, "rewards_ma_env": 26, "rewards_sa": 29, "rewardwithspeed": 33, "rexasi": 4, "rgb_arrai": [6, 15, 20], "right": [18, 24], "rightward": 31, "rigor": 32, "rl": [4, 23, 27, 28, 34], "rm": 4, "rng": [9, 29], "rnn": 18, "robot": [3, 4, 31], "roll": [33, 34], "rollout": [4, 9, 13, 23, 28, 29, 33, 34], "rollout_round_min_episod": [23, 28, 29], "rollout_round_min_timestep": 4, "rollout_without_info": 9, "rolloutinfowrapp": 9, "rotat": [26, 27], "row": [23, 26], "rt_env": 20, "rule": 24, "run": [4, 6, 7, 9, 13, 14, 15, 19, 20, 23, 24, 26, 27, 28, 29, 31, 33, 34], "run_index": [23, 26, 27, 33], "run_mp": [26, 27], "run_onc": 26, "runtim": [32, 35], "sa": [30, 32], "sa_env": 21, "sac": [4, 25, 26, 27, 31, 32, 33, 34], "sac_cmd": 31, "sac_efficaci": 31, "sac_feasible_cmd": 31, "sac_reward": [23, 33, 34], "safe": [24, 26], "safe_dump": 21, "safer": 26, "safeti": [7, 17, 20, 24, 26, 27], "safety_margin": [17, 19, 20, 21, 23, 24, 25, 29, 30, 33, 34], "safety_viol": 7, "sai": 21, "same": [4, 7, 9, 13, 15, 16, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35], "same_speed_env": 34, "same_speed_reward": 34, "samespe": 34, "sampl": [6, 9, 14, 15, 20, 21, 28, 31, 33], "sample_until": 9, "sampler": [31, 33], "samples_so_far": [23, 28, 29], "save": [0, 2, 4, 9, 10, 14, 19, 22, 23, 28, 29, 31, 32, 33, 34], "save_env": [10, 12, 20, 21, 24, 28, 29, 33, 34], "save_to_zip_fil": 9, "save_util": 9, "sb3": [16, 21], "scalar": 18, "scale": 20, "scanner": 21, "scenario": [0, 4, 6, 10, 15, 19, 20, 21, 23, 25, 27, 28, 30, 32, 35], "scenario_with_polici": 19, "search": 2, "second": [5, 21, 23, 25, 26, 27, 28, 29, 31], "second_group": 21, "see": [4, 6, 13, 15, 19, 24, 27, 28], "seed": [4, 6, 7, 9, 13, 15, 19, 20, 23, 24, 26, 27, 31, 33], "seem": [19, 20, 24, 26, 27, 29, 31, 33, 34], "seen": [20, 27], "select": [4, 6, 7, 11, 12, 15, 16, 20, 21], "self": [6, 9, 13, 15, 18, 20, 33], "sens": [0, 4, 5, 24, 31], "sensing_spac": 5, "sensingst": [4, 13], "sensor": [0, 4, 5, 6, 12, 15, 19, 20, 21, 23, 25, 28, 29, 30, 31, 32, 33, 34, 35], "separ": [13, 16], "sequenc": [7, 9, 11, 16, 31], "seri": [25, 27, 28], "set": [5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 20, 29, 33], "set_env": 9, "set_first_agent_to_dummi": 27, "set_init": 33, "set_logg": [9, 23, 28, 29, 33, 34], "set_nam": [28, 29, 33, 34], "set_opt": [26, 27, 28, 29, 33, 34], "set_optimal_angular_spe": 33, "set_titl": [20, 24, 26, 27, 31], "set_xlabel": [24, 26, 27, 31], "set_xlim": [26, 27], "set_ylabel": [24, 26, 27], "set_ylim": [26, 27], "setup": [20, 24], "setup_tqdm": [9, 10, 23, 28, 29, 31], "sever": [4, 20], "shape": [13, 16, 19, 20, 24, 27], "share": [4, 15, 20, 21, 23, 34, 35], "shared_parallel_env": [4, 10, 15, 21, 33, 34], "short": 20, "shorten": 20, "shorter": 28, "should": [3, 5, 14, 20, 24], "show": [19, 20, 32, 33], "showcas": [20, 21, 31], "side": [0, 19, 20, 24, 29, 30, 33, 34, 35], "sigl": [4, 28], "signal": [6, 15], "signific": 28, "significalti": 28, "significanlti": 28, "significantli": [28, 29], "sim": [4, 5, 6, 7, 13, 15, 19, 20, 21, 23, 24, 26, 27, 29, 31, 33, 34], "similar": [4, 7, 9, 16, 18, 20, 26, 27, 28, 29, 31], "similarli": [4, 9, 19, 27, 31, 34], "similat": 7, "simpl": [13, 24, 25, 31, 33], "simpledaggertrain": 9, "simpler": 4, "simplest": 29, "simpli": 20, "simplif": 4, "simplifi": [4, 9], "simul": [4, 5, 6, 8, 13, 15, 18, 19, 20, 21, 23, 27, 28, 29, 33, 34], "sin": 33, "singl": [2, 4, 5, 7, 8, 10, 13, 14, 15, 20, 22, 24, 25, 26, 28, 30, 31, 32], "sinusoid": 33, "size": [5, 7, 14, 16, 20, 24, 26, 27], "skip": [23, 26, 28], "slice": [7, 11, 15, 16, 18, 21, 26, 27], "slide": 11, "slighti": 7, "slightli": [4, 20], "smaller": 6, "smooth": 34, "so": [0, 5, 17, 20, 27], "social": [10, 20, 21], "social_margin": [17, 20, 21], "socialreward": [10, 17, 19, 20, 21, 23, 24, 29, 33, 34], "sole": 15, "solid": [26, 27], "some": [4, 7, 28], "sometim": 24, "sorri": [19, 20, 24, 26, 27, 29, 31, 33, 34], "space": [4, 5, 6, 8, 9, 14, 15, 16, 20, 21, 23, 25, 31], "spawn": 4, "spec": [20, 23, 31], "special": 20, "specif": [0, 4, 14, 20], "specifi": [4, 5, 7, 13, 15, 28], "speed": [5, 6, 15, 17, 20, 21, 24, 25, 27, 31, 32, 35], "speed_toler": [19, 20, 29, 30, 33, 34, 35], "split": 26, "squar": 35, "squash_output": 16, "stabl": [3, 4, 20, 28], "stable_baselines3": [4, 7, 9, 16, 18, 20, 21, 23, 26, 27, 28, 29, 31, 33, 34], "stablebaseline3": [7, 15, 20, 28], "stack": [5, 21, 28, 31], "stai": 20, "stamp": [23, 28, 29, 33, 34], "stand": 28, "standard": [4, 7], "start": [13, 14, 20, 21, 23, 24, 26, 27, 28, 29, 31], "start_angl": 21, "state": [0, 4, 5, 6, 9, 10, 13, 14, 15, 18, 20, 21], "state_estim": [4, 19, 20, 24, 25, 27, 29, 30, 33, 34], "stateestim": 12, "static": 8, "statist": [7, 20, 28], "std": [7, 24, 27, 28, 29, 31, 33, 34], "stddev": [28, 29, 33, 34], "step": [4, 5, 6, 7, 8, 10, 13, 15, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "still": [4, 9, 28], "stop": 21, "store": [7, 13, 28], "stori": [26, 27], "str": [4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 18], "straight": [20, 24, 26, 27], "stream": 35, "strftime": [23, 28, 29, 33, 34], "stricli": 27, "stuck": [5, 6, 9, 15, 26, 27], "stuck_timeout": [6, 15, 20], "sub": [4, 7, 9, 11], "sub_dict": [10, 11], "sub_sequ": [10, 11], "subclass": [0, 4, 15], "submodul": 16, "subplot": [20, 23, 24, 26, 27, 31], "successfulli": [28, 29, 34], "suffix": 14, "sugar": 18, "suitabl": 4, "sum": [16, 17, 24, 26, 27], "summari": [30, 32, 34], "super": 33, "supersuit": [4, 9, 15, 21], "support": [3, 4, 9, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "suptitl": [24, 27], "surpris": [20, 27], "svg": [23, 24, 28, 29, 33, 34], "svg_color": 33, "switch": 29, "system": [4, 29], "t": [10, 11, 19, 20, 24, 26, 27, 28, 29, 31, 33, 34], "tag": [5, 6, 15], "take": [23, 24, 28, 29, 30], "taken": 4, "targer": 24, "target": [4, 5, 13, 17, 20, 24, 26, 27, 31, 32, 34, 35], "target_angular_spe": 33, "target_margin": [19, 20, 29, 30], "target_spe": 33, "task": [4, 6, 15, 24, 27, 28, 31], "tau": [19, 20, 24, 25, 29, 30, 33, 34], "tb_log_nam": [23, 28, 29], "teal": 26, "tell": [26, 27], "tensor": 16, "tensorboard": [23, 28, 29, 33, 34], "term": 33, "termin": [4, 6, 7, 15, 20, 21], "terminate_outside_bound": [6, 7, 15, 20], "test": [7, 18, 27, 33], "test_env": [23, 31], "test_scenario": 33, "test_venv": [28, 29], "tha": 33, "than": [5, 6, 24, 25, 26, 27, 28, 29, 34], "thei": [4, 5, 7, 12, 15, 21, 27, 28, 31, 34, 35], "them": [4, 7, 20, 27, 28, 31, 32], "themselv": 27, "theoret": [28, 29], "therefor": [4, 9, 20, 21, 27, 28, 31, 34], "thi": [4, 5, 6, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34, 35], "think": 4, "third": 3, "those": 4, "thought": 9, "three": [7, 23, 27, 28, 29], "through": [16, 20], "thymio": [19, 20, 24, 25, 29, 30, 31, 33, 34, 35], "time": [4, 5, 6, 7, 8, 15, 18, 20, 23, 24, 26, 27, 28, 29, 33, 34], "time_step": [4, 5, 6, 7, 8, 15, 18, 19, 20, 21, 23, 24, 27, 29, 31, 33, 34], "timedelta": 31, "timeit": [24, 31], "tini": 9, "titl": [19, 23, 24, 33, 34], "to_csv": [26, 27, 28, 29, 33, 34], "to_html": 20, "todo": 17, "togeh": 26, "toget": [26, 27], "togeth": [4, 9, 12, 16, 21, 23], "toler": [19, 20, 29, 30], "too": [24, 27], "took": [23, 28, 29], "tool": [4, 19], "top": [18, 24], "torch": 16, "torch_lay": 16, "total": [21, 26, 27], "total_timestep": [4, 23, 28, 29, 31, 33, 34], "toward": [13, 17, 20, 24, 31], "tqdm": 9, "train": [0, 2, 5, 7, 9, 23, 25, 30, 32, 35], "train_venv": [33, 34], "trainer": 9, "training_venv": [28, 29], "trajectori": [4, 7, 9, 19, 24], "trajectoryaccumul": 13, "trajectoryplotconfig": [7, 10], "trajectorywithrew": 9, "trajectoti": 24, "transform": 4, "translat": 0, "travel": [8, 13, 24, 25, 27], "treat": [5, 6, 15], "treward": 31, "tri": 29, "trivial": 24, "true": [4, 5, 7, 8, 13, 14, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34], "truncat": [4, 6, 15, 20, 21], "try": [20, 23, 24, 27, 29, 30], "tupl": [6, 7, 9, 11, 12, 14, 15, 18, 20, 21], "turn": 4, "tutori": [2, 4, 29, 34, 35], "twist": 31, "twist2": [4, 5, 21, 31], "two": [0, 4, 5, 7, 13, 20, 22, 23, 25, 27, 28, 29, 32, 34, 35], "type": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 24, 25, 28, 29, 30, 31, 33, 34, 35], "type_alias": 18, "typeerror": [12, 15], "typevar": 11, "typic": [4, 24], "u": [13, 19, 20, 21, 24, 27, 28, 29, 33], "ui": [6, 15, 19, 20, 24, 26, 27, 29, 31, 33, 34], "uint8": [16, 20, 21, 26, 27], "uncom": [23, 28], "under": 6, "underli": 4, "understand": [20, 27], "uniform": [31, 32, 33, 35], "union": [4, 11], "unit": 31, "unsaf": 27, "unspecifi": 28, "until": [4, 9], "untrain": 29, "unwrap": [12, 15, 20, 23, 27, 28, 31], "up": [6, 15, 27], "updat": [4, 6, 15, 24], "update_dri": [6, 15], "update_static_obstacl": [24, 25], "upper": [5, 28, 29], "us": [5, 6, 7, 9, 11, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35], "use_acceleration_act": [5, 8, 13, 20, 21, 23, 24, 29, 33, 34], "use_masked_tensor": 16, "use_nearest_point": 20, "use_wheel": [5, 13, 20, 21], "user": 3, "usual": [31, 33, 34], "util": [5, 10, 15, 23, 28, 29], "v": [7, 21, 26, 27], "valid": [5, 20, 21], "valu": [5, 6, 7, 11, 15, 16, 20, 21, 23, 24, 26, 27, 31, 33, 34], "value_1": 28, "value_2": 28, "valueerror": 11, "vari": [32, 35], "variabl": 15, "variat": 16, "varyoptimalspe": 33, "vec_env": [28, 33, 34], "vecenv": [7, 9, 15], "vecmonitor": [28, 33, 34], "vector": [4, 9, 15, 21, 28, 31], "veloc": [5, 8, 20, 21, 31, 33], "venv": [4, 9, 20, 21, 28, 33, 34], "venv1": 21, "verbos": [28, 29, 31], "veri": [4, 24, 27, 31], "version": [9, 20, 21, 31], "vertic": 18, "via": [6, 15], "video": [7, 19, 20, 24, 27, 29, 30, 31, 32, 33, 34], "video_config": 7, "video_env": 20, "video_fold": 20, "videoconfig": [7, 10], "view": [4, 20, 28], "violat": [7, 17, 20, 24, 26, 27], "visibl": 24, "visual": [28, 29, 33], "wa": 4, "wai": [0, 4, 8, 9, 20, 24, 29], "wait": [6, 15], "wall": [13, 24, 25], "want": [7, 9, 13, 20, 21, 24, 25, 26, 27, 28, 32], "warn": [5, 7, 20, 23, 24, 28, 29, 31, 33, 34], "waypoint": [20, 29], "we": [0, 3, 4, 5, 7, 9, 15, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "websocket": [6, 15], "webui": [6, 15], "weight": [17, 26, 33], "well": [20, 27, 28, 33, 34], "what": 28, "wheel": [5, 31, 33], "wheel_axi": [19, 20, 24, 25, 29, 30, 31, 33, 34, 35], "when": [4, 6, 7, 13, 15, 16, 20, 23, 24, 26, 27, 28, 35], "where": [4, 5, 7, 8, 9, 12, 14, 18, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35], "whether": [4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 18], "which": [4, 5, 6, 7, 9, 13, 15, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 31, 33], "while": [4, 9, 17, 20, 21, 26, 28, 29, 31, 33], "whole": [24, 26, 27, 31], "whose": [4, 7, 9], "why": 20, "width": [7, 13, 19, 20, 24, 25, 26, 27, 29], "window": [20, 33, 34], "with_ag": [23, 24], "with_env": [7, 13, 24], "with_reward": [13, 19], "with_safety_margin": [23, 24], "with_world": 23, "work": 4, "world": [4, 5, 6, 7, 13, 15, 18, 19, 20, 24, 27, 29, 31, 33, 34, 35], "world_kwarg": [23, 24], "worst": 23, "would": [6, 15, 31], "wrap": [4, 9, 19, 20], "wrapper": 4, "write": 13, "writefil": [19, 20, 24], "wrong": 24, "x": [11, 13, 15, 19, 20, 23, 24, 26, 27, 28, 29, 33, 34], "xlabel": [19, 23, 24, 33, 34], "xlim": [23, 24], "y": [13, 19, 23, 24, 26, 27, 28, 29, 33, 34], "yaml": [0, 4, 5, 6, 7, 12, 15, 19, 20, 21, 23, 24, 26, 27, 28, 29, 31, 33, 34], "yellow": [33, 34], "yet": [3, 4, 28, 31], "ylabel": [19, 23, 24, 33, 34], "ylim": [24, 28, 29], "you": [3, 4, 28, 29], "your": [19, 20, 24, 26, 27, 29, 31, 33, 34], "zero": [6, 15, 16, 17], "zip": [20, 23, 26, 27, 28, 29, 31], "\u03bc": [24, 31]}, "titles": ["How to extend", "Guides", "Welcome to navground_learning\u2019s documentation!", "Installation", "Introduction", "Configuration", "Single-agent Gymnasium Environment", "Evaluation", "Examples", "Imitation Learning", "Reference", "Indices", "Saving and Loading", "Navground Components", "Onnx", "Multi-agent Pettingzoo Environment", "Policies", "Rewards functions", "Types", "Using a ML policy in Navground", "Gymnasium Environment", "Navground-PettingZoo integration", "Basics", "Learning", "Scenario", "Corridor with obstacle", "Performance of policies trained in multi-agent environment", "Performance of policies trained in single-agent environment", "Training agents among peers", "Training one agent among many agents", "Crossing", "Empty environment", "Tutorials", "Different speeds", "Uniform speeds", "Periodic Crossing"], "titleterms": {"": 2, "A": 21, "One": 27, "acknowledg": 4, "action": 5, "agent": [4, 6, 15, 26, 27, 28, 29], "among": [28, 29], "an": 31, "base": [5, 9], "basic": 22, "behavior": [5, 9, 13, 23, 28, 29], "class": [5, 9], "clone": [9, 23, 28, 29], "comparis": 23, "compon": [0, 13], "configur": [0, 5], "content": [1, 2], "convert": 21, "corridor": [8, 25], "corridorwithobstacl": 13, "creat": 31, "cross": [8, 30, 35], "dagger": [9, 23, 28, 29], "default": 5, "defin": 31, "differ": 33, "disclaim": 4, "document": 2, "efficaci": 17, "empti": 31, "end": 5, "env": 21, "enviro": 31, "environ": [4, 6, 15, 20, 26, 27, 28, 29, 31, 33, 34], "evalu": [4, 7, 31], "exampl": 8, "experi": 7, "export": [14, 31], "extend": 0, "extractor": 16, "final": 26, "follow": 27, "forward": 13, "from": 21, "function": 17, "group": [5, 21], "guid": 1, "gymnasium": [4, 6, 20, 21], "hl": 23, "how": 0, "human": 29, "imit": [4, 9, 23, 31], "indic": [2, 11], "infer": 14, "info": 16, "instal": 3, "integr": [4, 21], "introduct": 4, "invari": 16, "learn": [4, 9, 23, 31], "like": 29, "load": [12, 20, 21], "log": 7, "mani": 29, "ml": [4, 19], "modul": 5, "more": 27, "multi": [4, 15, 26], "navground": [0, 4, 7, 13, 19, 20, 21, 31], "navground_learn": 2, "null": [16, 17], "observ": 5, "obstacl": 25, "one": 29, "onnx": 14, "order": 16, "parallel": 4, "peer": 28, "perform": [26, 27], "period": 35, "pettingzoo": [4, 15, 21], "polici": [4, 7, 16, 19, 20, 26, 27, 28, 31], "policybehavior": 13, "pre": 28, "probe": 13, "random": 16, "refer": 10, "reinforc": [4, 23, 31], "render": 20, "reward": [17, 26], "runtim": 33, "sa": 28, "sac": [23, 28, 29], "save": [12, 20, 21], "scenario": [7, 13, 24, 29, 31, 33, 34], "sensor": 24, "singl": [6, 21, 27], "social": 17, "speed": [33, 34], "summari": [28, 29], "tabl": 2, "target": 33, "train": [4, 26, 27, 28, 29, 31, 33, 34], "tutori": 32, "two": 21, "type": 18, "uniform": 34, "us": [4, 19, 31], "util": 9, "vari": 33, "vector": 20, "video": 26, "welcom": 2, "wrapper": 20}})